{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cdd59e4",
   "metadata": {},
   "source": [
    "Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e585ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de2e847",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path(r\"C:\\Computer Science\\AIMLDL\\log-anomaly-detection\")\n",
    "DATA_PATH = PROJECT_ROOT / \"dataset\" / \"structured_data\"\n",
    "OUTPUT_PATH = PROJECT_ROOT / \"dataset\" / \"labeled_data\"\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281caa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_SOURCES = [\n",
    "    'Android_2k', 'Apache_2k', 'BGL_2k', 'Hadoop_2k', 'HDFS_2k', \n",
    "    'HealthApp_2k', 'HPC_2k', 'Linux_2k', 'Mac_2k', 'OpenSSH_2k',\n",
    "    'OpenStack_2k', 'Proxifier_2k', 'Spark_2k', 'Thunderbird_2k',\n",
    "    'Windows_2k', 'Zookeeper_2k'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f9d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    0: \"normal\",\n",
    "    1: \"security_anomaly\", \n",
    "    2: \"system_failure\",\n",
    "    3: \"performance_issue\",\n",
    "    4: \"network_anomaly\", \n",
    "    5: \"config_error\",\n",
    "    6: \"hardware_issue\",\n",
    "    7: \"unknown_anomaly\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74fceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_PATTERNS = {\n",
    "    'security': ['authentication failure', 'invalid user', 'break-in attempt', \n",
    "                'failed password', 'unauthorized', 'access denied'],\n",
    "    'system': ['error', 'critical', 'fatal', 'exception', 'crash', 'abort'],\n",
    "    'network': ['timeout', 'connection refused', 'host unreachable'],\n",
    "    'performance': ['slow', 'overload', 'resource exhausted', 'quota exceeded'],\n",
    "    'hardware': ['hardware error', 'disk error', 'i/o error', 'device error']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f9eaf7",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c8dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    datasets = {}\n",
    "    for source in LOG_SOURCES:\n",
    "        try:\n",
    "            file_path = DATA_PATH / f\"{source}.log_structured.csv\"\n",
    "            df = pd.read_csv(file_path)\n",
    "            datasets[source] = df\n",
    "            print(f\"✓ Loaded {source}: {len(df):,} logs\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed {source}: {e}\")\n",
    "    \n",
    "    total = sum(len(df) for df in datasets.values())\n",
    "    print(f\"\\nLoaded {len(datasets)} sources, {total:,} total logs\")\n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0637aaf",
   "metadata": {},
   "source": [
    "Analyze Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31287bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_templates(datasets):\n",
    "    stats = {}\n",
    "    for source, df in datasets.items():\n",
    "        if 'EventTemplate' not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        templates = df['EventTemplate'].value_counts()\n",
    "        stats[source] = {\n",
    "            'total_logs': len(df),\n",
    "            'unique_templates': len(templates),\n",
    "            'efficiency': len(df) / len(templates),\n",
    "            'top_templates': templates.head(5)\n",
    "        }\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d69c37",
   "metadata": {},
   "source": [
    "Find Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118d6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_anomalies(datasets):\n",
    "    results = {}\n",
    "    \n",
    "    for source, df in datasets.items():\n",
    "        if 'Content' not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        content_lower = df['Content'].str.lower()\n",
    "        anomaly_counts = {}\n",
    "        \n",
    "        for category, keywords in ANOMALY_PATTERNS.items():\n",
    "            pattern = '|'.join(re.escape(kw) for kw in keywords)\n",
    "            matches = content_lower.str.contains(pattern, na=False, regex=True)\n",
    "            anomaly_counts[category] = matches.sum()\n",
    "        \n",
    "        total_anomalies = sum(anomaly_counts.values())\n",
    "        results[source] = {\n",
    "            'total_logs': len(df),\n",
    "            'anomalies': total_anomalies,\n",
    "            'anomaly_rate': (total_anomalies / len(df)) * 100,\n",
    "            'categories': anomaly_counts\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cf302",
   "metadata": {},
   "source": [
    "Rank Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22387a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_sources(template_stats, anomaly_stats):\n",
    "    rankings = []\n",
    "    \n",
    "    for source in template_stats.keys():\n",
    "        if source not in anomaly_stats:\n",
    "            continue\n",
    "            \n",
    "        t_stats = template_stats[source] \n",
    "        a_stats = anomaly_stats[source]\n",
    "        \n",
    "        anomaly_score = a_stats['anomaly_rate']\n",
    "        template_score = 100 - (t_stats['unique_templates'] / 10)  # Fewer templates = better\n",
    "        efficiency_score = t_stats['efficiency'] / 10\n",
    "        \n",
    "        priority = (anomaly_score * 0.4 + template_score * 0.3 + efficiency_score * 0.3)\n",
    "        \n",
    "        rankings.append({\n",
    "            'source': source,\n",
    "            'priority_score': priority,\n",
    "            'anomaly_rate': a_stats['anomaly_rate'],\n",
    "            'templates': t_stats['unique_templates'],\n",
    "            'efficiency': t_stats['efficiency']\n",
    "        })\n",
    "    \n",
    "    return sorted(rankings, key=lambda x: x['priority_score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c8113",
   "metadata": {},
   "source": [
    "Prepare Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0434fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_templates(df, source_name):\n",
    "    \"\"\"Fixed version of prep_templates\"\"\"\n",
    "    if 'EventTemplate' not in df.columns or 'Content' not in df.columns:\n",
    "        print(f\"Missing required columns in {source_name}\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        return []\n",
    "    \n",
    "    templates = df['EventTemplate'].value_counts()\n",
    "    labeling_data = []\n",
    "    \n",
    "    print(f\"Processing {len(templates)} unique templates...\")\n",
    "    \n",
    "    for template, count in templates.items():\n",
    "        # Get sample content - make sure we get actual strings\n",
    "        matching_rows = df[df['EventTemplate'] == template]\n",
    "        samples = matching_rows['Content'].head(3).tolist()\n",
    "        \n",
    "        # Debug: check what we got\n",
    "        if len(samples) == 0:\n",
    "            samples = ['No samples found']\n",
    "        \n",
    "        # Verify samples are strings\n",
    "        samples = [str(s) if s is not None else 'Empty content' for s in samples]\n",
    "        \n",
    "        # Auto-suggest label\n",
    "        suggested_label = 0\n",
    "        confidence = \"low\"\n",
    "        \n",
    "        # Check all sample content together\n",
    "        content_text = ' '.join(samples).lower()\n",
    "        \n",
    "        # Check for anomaly patterns\n",
    "        for category, keywords in ANOMALY_PATTERNS.items():\n",
    "            if any(kw in content_text for kw in keywords):\n",
    "                if category == 'security':\n",
    "                    suggested_label = 1\n",
    "                elif category == 'system': \n",
    "                    suggested_label = 2\n",
    "                elif category == 'performance':\n",
    "                    suggested_label = 3\n",
    "                elif category == 'network':\n",
    "                    suggested_label = 4\n",
    "                elif category == 'hardware':\n",
    "                    suggested_label = 6\n",
    "                confidence = \"high\"\n",
    "                break\n",
    "        \n",
    "        labeling_data.append({\n",
    "            'template': template,\n",
    "            'count': count,\n",
    "            'percentage': (count / len(df)) * 100,\n",
    "            'samples': samples,  # This should now be proper strings\n",
    "            'suggested': suggested_label,\n",
    "            'confidence': confidence,\n",
    "            'label': None,\n",
    "            'notes': ''\n",
    "        })\n",
    "    \n",
    "    return sorted(labeling_data, key=lambda x: x['count'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b80f3f",
   "metadata": {},
   "source": [
    "Auto-label High Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8716737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_label(labeling_data):\n",
    "    auto_count = 0\n",
    "    for item in labeling_data:\n",
    "        if item['confidence'] == 'high' and item['label'] is None:\n",
    "            item['label'] = item['suggested']\n",
    "            item['notes'] = 'Auto-labeled (high confidence)'\n",
    "            auto_count += 1\n",
    "    \n",
    "    print(f\"Auto-labeled {auto_count} templates\")\n",
    "    return auto_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eafcb8a",
   "metadata": {},
   "source": [
    "Interactive Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac30db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_batch(labeling_data, source_name, start=0, count=5):\n",
    "    \"\"\"Fixed version with proper source name handling\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEMPLATE LABELING\")\n",
    "    print(\"Labels:\", \", \".join(f\"{k}:{v}\" for k, v in LABELS.items()))\n",
    "    print(\"Commands: 0-7 (label), 'skip', 'quit', 'save'\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    end = min(start + count, len(labeling_data))\n",
    "    labeled = 0\n",
    "    \n",
    "    for i in range(start, end):\n",
    "        item = labeling_data[i]\n",
    "        \n",
    "        print(f\"\\n[{i+1}/{len(labeling_data)}] Template\")\n",
    "        print(f\"Frequency: {item['count']:,} logs ({item['percentage']:.1f}%)\")\n",
    "        print(f\"Template: {item['template']}\")\n",
    "        print(\"Sample logs:\")\n",
    "        \n",
    "        samples = item.get('samples', [])\n",
    "        if samples:\n",
    "            for j, sample in enumerate(samples[:3], 1):\n",
    "                if isinstance(sample, str) and len(sample.strip()) > 0:\n",
    "                    display_sample = sample[:150] + \"...\" if len(sample) > 150 else sample\n",
    "                    print(f\"  {j}. {display_sample}\")\n",
    "                else:\n",
    "                    print(f\"  {j}. [No content available]\")\n",
    "        else:\n",
    "            print(\"  [No samples available]\")\n",
    "            \n",
    "        print(f\"Suggested: {item['suggested']} ({LABELS[item['suggested']]}) - {item['confidence']}\")\n",
    "        \n",
    "        while True:\n",
    "            response = input(f\"\\nLabel (suggested {item['suggested']}): \").strip().lower()\n",
    "            \n",
    "            if response == 'quit':\n",
    "                return i, labeled\n",
    "            elif response == 'skip':\n",
    "                break\n",
    "            elif response == 'save':\n",
    "                save_progress(labeling_data, source_name)  # Fixed\n",
    "                continue\n",
    "            elif response.isdigit() and 0 <= int(response) <= 7:\n",
    "                item['label'] = int(response) \n",
    "                notes = input(\"Notes (optional): \").strip()\n",
    "                if notes:\n",
    "                    item['notes'] = notes\n",
    "                labeled += 1\n",
    "                break\n",
    "            else:\n",
    "                print(\"Enter 0-7, 'skip', 'save', or 'quit'\")\n",
    "    \n",
    "    print(f\"\\nLabeled {labeled} templates in this batch\")\n",
    "    return end, labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c9ff8d",
   "metadata": {},
   "source": [
    "Quick Label Multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c216b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_label(labeling_data, indices, labels):\n",
    "    for idx, label in zip(indices, labels):\n",
    "        if 0 <= idx < len(labeling_data) and 0 <= label <= 7:\n",
    "            labeling_data[idx]['label'] = label\n",
    "            labeling_data[idx]['notes'] = 'Quick label'\n",
    "            print(f\"Labeled template {idx}: {LABELS[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531b3ca",
   "metadata": {},
   "source": [
    "Save Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e2d29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_progress(labeling_data, source_name):\n",
    "    data_to_save = []\n",
    "    for item in labeling_data:\n",
    "        item_copy = item.copy()\n",
    "        item_copy['samples'] = json.dumps(item['samples'])\n",
    "        data_to_save.append(item_copy)\n",
    "    \n",
    "    df = pd.DataFrame(data_to_save)\n",
    "    df.to_csv(OUTPUT_PATH / f\"{source_name}_progress.csv\", index=False)\n",
    "    \n",
    "    labeled = sum(1 for item in labeling_data if item['label'] is not None)\n",
    "    print(f\"Saved progress: {labeled}/{len(labeling_data)} templates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d2db4f",
   "metadata": {},
   "source": [
    "Load Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17cdb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_progress(source_name):\n",
    "    file_path = OUTPUT_PATH / f\"{source_name}_progress.csv\"\n",
    "    if file_path.exists():\n",
    "        df = pd.read_csv(file_path)\n",
    "        data = df.to_dict('records')\n",
    "        \n",
    "        for item in data:\n",
    "            if 'samples' in item and isinstance(item['samples'], str):\n",
    "                try:\n",
    "                    item['samples'] = json.loads(item['samples'])\n",
    "                except:\n",
    "                    item['samples'] = ['Error loading samples']\n",
    "        \n",
    "        labeled = sum(1 for item in data if pd.notna(item.get('label')))\n",
    "        print(f\"Loaded progress: {labeled}/{len(data)} templates\")\n",
    "        return data\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad3b125",
   "metadata": {},
   "source": [
    "Show Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ebb4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_progress(labeling_data):\n",
    "    total = len(labeling_data)\n",
    "    labeled = sum(1 for item in labeling_data if item['label'] is not None)\n",
    "    \n",
    "    print(f\"\\nProgress: {labeled}/{total} templates ({labeled/total*100:.1f}%)\")\n",
    "    \n",
    "    if labeled > 0:\n",
    "        dist = defaultdict(int)\n",
    "        for item in labeling_data:\n",
    "            if item['label'] is not None and not pd.isna(item['label']):\n",
    "                dist[int(item['label'])] += item['count']\n",
    "        \n",
    "        print(\"Label distribution:\")\n",
    "        for label in sorted(dist.keys()):\n",
    "            count = dist[label]\n",
    "            if label in LABELS:\n",
    "                print(f\"  {label} ({LABELS[label]}): {count:,} logs\")\n",
    "            else:\n",
    "                print(f\"  {label} (unknown): {count:,} logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44c4c9",
   "metadata": {},
   "source": [
    "Export Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "984bdce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_final(df, labeling_data, source_name):\n",
    "    template_labels = {item['template']: item['label'] \n",
    "                      for item in labeling_data if item['label'] is not None}\n",
    "    \n",
    "    result_df = df.copy()\n",
    "    result_df['AnomalyLabel'] = result_df['EventTemplate'].map(template_labels).fillna(-1).astype(int)\n",
    "    result_df['AnomalyLabelName'] = result_df['AnomalyLabel'].map(lambda x: LABELS.get(x, 'unlabeled'))\n",
    "    \n",
    "    output_file = OUTPUT_PATH / f\"{source_name}_labeled.csv\"\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    total = len(result_df)\n",
    "    labeled_count = (result_df['AnomalyLabel'] >= 0).sum()\n",
    "    anomaly_count = (result_df['AnomalyLabel'] > 0).sum()\n",
    "    \n",
    "    print(f\"\\nFinal dataset: {output_file}\")\n",
    "    print(f\"Total logs: {total:,}\")\n",
    "    print(f\"Labeled: {labeled_count:,} ({labeled_count/total*100:.1f}%)\")\n",
    "    print(f\"Anomalies: {anomaly_count:,} ({anomaly_count/labeled_count*100:.1f}% of labeled)\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7be67da",
   "metadata": {},
   "source": [
    "Main Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ed758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_workflow():\n",
    "    print(\"LOG ANOMALY LABELING WORKFLOW\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"1. Loading datasets...\")\n",
    "    datasets = load_data()\n",
    "    \n",
    "    print(\"\\n2. Analyzing templates...\")\n",
    "    template_stats = analyze_templates(datasets)\n",
    "    \n",
    "    print(\"\\n3. Finding anomalies...\")\n",
    "    anomaly_stats = find_anomalies(datasets)\n",
    "    \n",
    "    print(\"\\n4. Ranking sources...\")\n",
    "    rankings = rank_sources(template_stats, anomaly_stats)\n",
    "    \n",
    "    print(\"\\nTop 3 sources for labeling:\")\n",
    "    for i, rank in enumerate(rankings[:3], 1):\n",
    "        print(f\"{i}. {rank['source']} (score: {rank['priority_score']:.1f})\")\n",
    "        print(f\"   Anomaly rate: {rank['anomaly_rate']:.1f}%\")\n",
    "        print(f\"   Templates: {rank['templates']}\")\n",
    "    \n",
    "    best_source = rankings[0]['source']\n",
    "    print(f\"\\n5. Preparing {best_source} for labeling...\")\n",
    "    \n",
    "    labeling_data = load_progress(best_source)\n",
    "    if labeling_data is None:\n",
    "        labeling_data = prep_templates(datasets[best_source], best_source)\n",
    "        auto_label(labeling_data)\n",
    "    \n",
    "    show_progress(labeling_data)\n",
    "    \n",
    "    print(f\"\\n6. Ready for labeling!\")\n",
    "    print(\"Next steps:\")\n",
    "    print(f\"- label_batch(labeling_data) - Interactive labeling\")\n",
    "    print(f\"- quick_label(labeling_data, [0,1,2], [0,1,2]) - Quick labeling\")\n",
    "    print(f\"- show_progress(labeling_data) - Check progress\")\n",
    "    print(f\"- export_final(datasets['{best_source}'], labeling_data, '{best_source}') - Export final dataset\")\n",
    "    \n",
    "    return datasets, labeling_data, best_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34089edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = None\n",
    "labeling_data = None \n",
    "best_source = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ae6f8",
   "metadata": {},
   "source": [
    "Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a577359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quality(labeling_data):\n",
    "    labeled = [item for item in labeling_data if item['label'] is not None]\n",
    "    \n",
    "    if not labeled:\n",
    "        print(\"No labeled data to check\")\n",
    "        return {}\n",
    "    \n",
    "    total_templates = len(labeling_data)\n",
    "    labeled_count = len(labeled)\n",
    "    total_logs = sum(item['count'] for item in labeling_data)\n",
    "    labeled_logs = sum(item['count'] for item in labeled)\n",
    "    \n",
    "    template_coverage = (labeled_count / total_templates) * 100\n",
    "    log_coverage = (labeled_logs / total_logs) * 100\n",
    "    \n",
    "    print(f\"Coverage Report:\")\n",
    "    print(f\"Templates: {labeled_count}/{total_templates} ({template_coverage:.1f}%)\")\n",
    "    print(f\"Logs: {labeled_logs:,}/{total_logs:,} ({log_coverage:.1f}%)\")\n",
    "    \n",
    "    label_counts = defaultdict(int)\n",
    "    log_counts = defaultdict(int)\n",
    "    \n",
    "    for item in labeled:\n",
    "        label = item['label']\n",
    "        label_counts[label] += 1\n",
    "        log_counts[label] += item['count']\n",
    "    \n",
    "    print(f\"\\nLabel Distribution:\")\n",
    "    for label in sorted(label_counts.keys()):\n",
    "        templates = label_counts[label]\n",
    "        logs = log_counts[label]\n",
    "        print(f\"{label} ({LABELS[label]}): {templates} templates, {logs:,} logs\")\n",
    "    \n",
    "    return {\n",
    "        'template_coverage': template_coverage,\n",
    "        'log_coverage': log_coverage,\n",
    "        'label_counts': dict(label_counts),\n",
    "        'log_counts': dict(log_counts)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f566a295",
   "metadata": {},
   "source": [
    "Find Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e35bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_issues(labeling_data):\n",
    "    issues = []\n",
    "    \n",
    "    for i, item in enumerate(labeling_data):\n",
    "        if item['label'] is None:\n",
    "            continue\n",
    "        \n",
    "        template = item['template'].lower()\n",
    "        content = ' '.join(item['samples']).lower()\n",
    "        label = item['label']\n",
    "        \n",
    "        if label == 1:\n",
    "            security_words = ['auth', 'login', 'password', 'user', 'invalid', 'fail']\n",
    "            if not any(word in content for word in security_words):\n",
    "                issues.append(f\"Template {i}: Security label without security keywords\")\n",
    "        \n",
    "        elif label == 0:\n",
    "            error_words = ['error', 'fail', 'critical', 'exception']\n",
    "            if any(word in content for word in error_words):\n",
    "                issues.append(f\"Template {i}: Normal label with error keywords\")\n",
    "        \n",
    "        elif label > 0 and item['percentage'] > 10:\n",
    "            issues.append(f\"Template {i}: High-frequency anomaly ({item['percentage']:.1f}%)\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"Found {len(issues)} potential issues:\")\n",
    "        for issue in issues[:10]:\n",
    "            print(f\"  {issue}\")\n",
    "    else:\n",
    "        print(\"No issues found - labeling looks good!\")\n",
    "    \n",
    "    return issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e11dd",
   "metadata": {},
   "source": [
    "Group Similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdb61045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_similar(labeling_data):\n",
    "    unlabeled = [item for item in labeling_data if item['label'] is None]\n",
    "    \n",
    "    groups = {\n",
    "        'connection': [],\n",
    "        'auth': [],\n",
    "        'error': [],\n",
    "        'timeout': [],\n",
    "        'success': []\n",
    "    }\n",
    "    \n",
    "    for item in unlabeled:\n",
    "        text = (item['template'] + ' ' + ' '.join(item['samples'])).lower()\n",
    "        \n",
    "        if 'connect' in text or 'connection' in text:\n",
    "            groups['connection'].append(item)\n",
    "        elif 'auth' in text or 'login' in text or 'user' in text:\n",
    "            groups['auth'].append(item)\n",
    "        elif 'error' in text or 'fail' in text or 'critical' in text:\n",
    "            groups['error'].append(item)\n",
    "        elif 'timeout' in text:\n",
    "            groups['timeout'].append(item)\n",
    "        elif 'success' in text or 'ok' in text or 'complete' in text:\n",
    "            groups['success'].append(item)\n",
    "    \n",
    "    print(f\"Similar template groups:\")\n",
    "    for name, items in groups.items():\n",
    "        if items:\n",
    "            total_logs = sum(item['count'] for item in items)\n",
    "            print(f\"{name}: {len(items)} templates, {total_logs:,} logs\")\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be4a7d",
   "metadata": {},
   "source": [
    "Smart Suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f739c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_suggest(labeling_data):\n",
    "    labeled = [item for item in labeling_data if item['label'] is not None]\n",
    "    \n",
    "    label_words = defaultdict(set)\n",
    "    for item in labeled:\n",
    "        text = item['template'].lower() + ' ' + ' '.join(item['samples']).lower()\n",
    "        words = set(text.split())\n",
    "        label_words[item['label']].update(words)\n",
    "    \n",
    "    updated = 0\n",
    "    for item in labeling_data:\n",
    "        if item['label'] is not None:\n",
    "            continue\n",
    "        \n",
    "        text = item['template'].lower() + ' ' + ' '.join(item['samples']).lower()\n",
    "        words = set(text.split())\n",
    "        \n",
    "        best_label = 0\n",
    "        best_score = 0\n",
    "        \n",
    "        for label_id, pattern_words in label_words.items():\n",
    "            overlap = len(words.intersection(pattern_words))\n",
    "            score = overlap / len(pattern_words) if pattern_words else 0\n",
    "            \n",
    "            if score > best_score and score > 0.2:\n",
    "                best_score = score\n",
    "                best_label = label_id\n",
    "        \n",
    "        if best_label != item['suggested']:\n",
    "            item['suggested'] = best_label\n",
    "            item['confidence'] = \"medium\" if best_score > 0.4 else \"low\"\n",
    "            updated += 1\n",
    "    \n",
    "    print(f\"Updated {updated} suggestions based on learned patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a5822",
   "metadata": {},
   "source": [
    "Save Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50a6f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_report(labeling_data, source_name):\n",
    "    report_file = OUTPUT_PATH / f\"{source_name}_report.txt\"\n",
    "    \n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(f\"LABELING REPORT: {source_name}\\n\")\n",
    "        f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\\n\")\n",
    "        \n",
    "        total = len(labeling_data)\n",
    "        labeled = sum(1 for item in labeling_data if item['label'] is not None)\n",
    "        total_logs = sum(item['count'] for item in labeling_data)\n",
    "        labeled_logs = sum(item['count'] for item in labeling_data if item['label'] is not None)\n",
    "        \n",
    "        f.write(f\"Templates: {labeled}/{total} ({labeled/total*100:.1f}%)\\n\")\n",
    "        f.write(f\"Logs: {labeled_logs:,}/{total_logs:,} ({labeled_logs/total_logs*100:.1f}%)\\n\\n\")\n",
    "        \n",
    "        label_dist = defaultdict(int)\n",
    "        for item in labeling_data:\n",
    "            if item['label'] is not None:\n",
    "                label_dist[item['label']] += item['count']\n",
    "        \n",
    "        f.write(\"Label Distribution:\\n\")\n",
    "        for label in sorted(label_dist.keys()):\n",
    "            count = label_dist[label]\n",
    "            f.write(f\"{label} ({LABELS[label]}): {count:,} logs\\n\")\n",
    "    \n",
    "    print(f\"Report saved: {report_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d6ef8",
   "metadata": {},
   "source": [
    "Find Next Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d140f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_source(datasets, labeling_data, current_source):\n",
    "    patterns = defaultdict(set)\n",
    "    for item in labeling_data:\n",
    "        if item['label'] is not None:\n",
    "            words = item['template'].lower().split()\n",
    "            patterns[item['label']].update(words)\n",
    "    \n",
    "    remaining = [src for src in LOG_SOURCES if src != current_source]\n",
    "    scores = []\n",
    "    \n",
    "    for source in remaining:\n",
    "        try:\n",
    "            df = datasets[source]\n",
    "            if 'EventTemplate' not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            templates = df['EventTemplate'].head(100)\n",
    "            matches = 0\n",
    "            \n",
    "            for template in templates:\n",
    "                template_words = set(template.lower().split())\n",
    "                for pattern_words in patterns.values():\n",
    "                    if len(template_words.intersection(pattern_words)) > 0:\n",
    "                        matches += 1\n",
    "                        break\n",
    "            \n",
    "            score = matches / len(templates) if templates is not None and len(templates) > 0 else 0\n",
    "            scores.append((source, score, len(df)))\n",
    "            \n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"Next source recommendations:\")\n",
    "    for i, (source, score, logs) in enumerate(scores[:3], 1):\n",
    "        print(f\"{i}. {source} (similarity: {score:.1f}, logs: {logs:,})\")\n",
    "    \n",
    "    return scores[0][0] if scores else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e06504",
   "metadata": {},
   "source": [
    "Export for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f29bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_ml_data(final_dataset, source_name, test_size=0.2):\n",
    "    labeled = final_dataset[final_dataset['AnomalyLabel'] >= 0].copy()\n",
    "    \n",
    "    if len(labeled) == 0:\n",
    "        print(\"No labeled data to export\")\n",
    "        return\n",
    "    \n",
    "    labeled['ContentLength'] = labeled['Content'].str.len()\n",
    "    labeled['HasError'] = labeled['Content'].str.lower().str.contains('error|fail|critical')\n",
    "    labeled['HasAuth'] = labeled['Content'].str.lower().str.contains('auth|login|user')\n",
    "    \n",
    "    X = labeled[['Content', 'EventTemplate', 'ContentLength', 'HasError', 'HasAuth']]\n",
    "    y = labeled['AnomalyLabel']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    train_file = OUTPUT_PATH / f\"{source_name}_train.csv\"\n",
    "    test_file = OUTPUT_PATH / f\"{source_name}_test.csv\"\n",
    "    \n",
    "    pd.concat([X_train, y_train], axis=1).to_csv(train_file, index=False)\n",
    "    pd.concat([X_test, y_test], axis=1).to_csv(test_file, index=False)\n",
    "    \n",
    "    print(f\"ML data exported:\")\n",
    "    print(f\"Train: {len(X_train):,} samples -> {train_file}\")\n",
    "    print(f\"Test: {len(X_test):,} samples -> {test_file}\")\n",
    "    \n",
    "    print(f\"Training labels:\")\n",
    "    for label, count in y_train.value_counts().sort_index().items():\n",
    "        pct = count/len(y_train)*100\n",
    "        print(f\"  {label} ({LABELS[label]}): {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1d7758",
   "metadata": {},
   "source": [
    "Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3f7ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_eval(labeling_data, source_name):\n",
    "    print(f\"QUICK EVALUATION: {source_name}\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    quality = check_quality(labeling_data)\n",
    "    \n",
    "    issues = find_issues(labeling_data)\n",
    "    \n",
    "    groups = group_similar(labeling_data)\n",
    "    \n",
    "    smart_suggest(labeling_data)\n",
    "    \n",
    "    save_report(labeling_data, source_name)\n",
    "    \n",
    "    return quality, issues, groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d9528c",
   "metadata": {},
   "source": [
    "Setup Next Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f780818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_next(datasets, current_labeling_data, current_source):\n",
    "    next_source = find_next_source(datasets, current_labeling_data, current_source)\n",
    "    \n",
    "    if not next_source:\n",
    "        print(\"No suitable next source found\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"Setting up {next_source} for labeling...\")\n",
    "    \n",
    "    next_data = prep_templates(datasets[next_source], next_source)\n",
    "    \n",
    "    labeled_items = [item for item in current_labeling_data if item['label'] is not None]\n",
    "    \n",
    "    if labeled_items:\n",
    "        keyword_labels = {}\n",
    "        for item in labeled_items:\n",
    "            words = item['template'].lower().split()\n",
    "            for word in words:\n",
    "                if word not in keyword_labels:\n",
    "                    keyword_labels[word] = []\n",
    "                keyword_labels[word].append(item['label'])\n",
    "        \n",
    "        for item in next_data:\n",
    "            words = item['template'].lower().split()\n",
    "            label_votes = []\n",
    "            for word in words:\n",
    "                if word in keyword_labels:\n",
    "                    label_votes.extend(keyword_labels[word])\n",
    "            \n",
    "            if label_votes:\n",
    "                from collections import Counter\n",
    "                most_common = Counter(label_votes).most_common(1)[0][0]\n",
    "                item['suggested'] = most_common\n",
    "                item['confidence'] = \"medium\"\n",
    "    \n",
    "    auto_label(next_data)\n",
    "    \n",
    "    print(f\"Next source ready: {next_source}\")\n",
    "    print(f\"Templates to label: {len([item for item in next_data if item['label'] is None])}\")\n",
    "    \n",
    "    return next_source, next_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0115eb05",
   "metadata": {},
   "source": [
    "Complete Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb1ec35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_workflow(datasets, labeling_data, source_name, final_dataset):\n",
    "    print(\"COMPLETE WORKFLOW EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"1. Evaluating current labeling...\")\n",
    "    quality, issues, groups = quick_eval(labeling_data, source_name)\n",
    "    \n",
    "    print(\"\\n2. Exporting ML-ready data...\")\n",
    "    export_ml_data(final_dataset, source_name)\n",
    "    \n",
    "    print(\"\\n3. Setting up next source...\")\n",
    "    next_source, next_data = setup_next(datasets, labeling_data, source_name)\n",
    "    \n",
    "    print(\"\\n4. RECOMMENDATIONS:\")\n",
    "    \n",
    "    if quality['template_coverage'] < 80:\n",
    "        print(f\"- Complete current source (only {quality['template_coverage']:.1f}% done)\")\n",
    "    elif next_source:\n",
    "        print(f\"- Start labeling {next_source} using learned patterns\")\n",
    "        print(f\"- Focus on templates that don't match existing patterns\")\n",
    "    \n",
    "    if quality['log_coverage'] > 90:\n",
    "        print(f\"- Ready for ML model training\")\n",
    "        print(f\"- Consider ensemble methods for better accuracy\")\n",
    "    \n",
    "    if len(issues) > 5:\n",
    "        print(f\"- Review and fix {len(issues)} potential labeling issues\")\n",
    "    \n",
    "    print(f\"\\n5. NEXT ACTIONS:\")\n",
    "    print(f\"- Review issues found in quality check\")\n",
    "    print(f\"- Continue labeling current source or start next source\")\n",
    "    print(f\"- Begin ML model experiments with exported data\")\n",
    "    \n",
    "    return quality, issues, groups, next_source, next_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145af5f9",
   "metadata": {},
   "source": [
    "Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "831f2ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG ANOMALY LABELING WORKFLOW\n",
      "==================================================\n",
      "1. Loading datasets...\n",
      "✓ Loaded Android_2k: 2,000 logs\n",
      "✓ Loaded Apache_2k: 2,000 logs\n",
      "✓ Loaded BGL_2k: 2,000 logs\n",
      "✓ Loaded Hadoop_2k: 2,000 logs\n",
      "✓ Loaded HDFS_2k: 2,000 logs\n",
      "✓ Loaded HealthApp_2k: 2,000 logs\n",
      "✓ Loaded HPC_2k: 2,000 logs\n",
      "✓ Loaded Linux_2k: 2,000 logs\n",
      "✓ Loaded Mac_2k: 2,000 logs\n",
      "✓ Loaded OpenSSH_2k: 2,000 logs\n",
      "✓ Loaded OpenStack_2k: 2,000 logs\n",
      "✓ Loaded Proxifier_2k: 2,000 logs\n",
      "✓ Loaded Spark_2k: 2,000 logs\n",
      "✓ Loaded Thunderbird_2k: 2,000 logs\n",
      "✓ Loaded Windows_2k: 2,000 logs\n",
      "✓ Loaded Zookeeper_2k: 2,000 logs\n",
      "\n",
      "Loaded 16 sources, 32,000 total logs\n",
      "\n",
      "2. Analyzing templates...\n",
      "\n",
      "3. Finding anomalies...\n",
      "\n",
      "4. Ranking sources...\n",
      "\n",
      "Top 3 sources for labeling:\n",
      "1. OpenSSH_2k (score: 59.2)\n",
      "   Anomaly rate: 69.5%\n",
      "   Templates: 27\n",
      "2. Apache_2k (score: 50.6)\n",
      "   Anomaly rate: 27.0%\n",
      "   Templates: 6\n",
      "3. HPC_2k (score: 39.7)\n",
      "   Anomaly rate: 24.5%\n",
      "   Templates: 46\n",
      "\n",
      "5. Preparing OpenSSH_2k for labeling...\n",
      "Processing 27 unique templates...\n",
      "Auto-labeled 17 templates\n",
      "\n",
      "Progress: 17/27 templates (63.0%)\n",
      "Label distribution:\n",
      "  1 (security_anomaly): 1,342 logs\n",
      "  2 (system_failure): 48 logs\n",
      "\n",
      "6. Ready for labeling!\n",
      "Next steps:\n",
      "- label_batch(labeling_data) - Interactive labeling\n",
      "- quick_label(labeling_data, [0,1,2], [0,1,2]) - Quick labeling\n",
      "- show_progress(labeling_data) - Check progress\n",
      "- export_final(datasets['OpenSSH_2k'], labeling_data, 'OpenSSH_2k') - Export final dataset\n"
     ]
    }
   ],
   "source": [
    "datasets, labeling_data, best_source = run_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45a7d06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEMPLATE LABELING\n",
      "Labels: 0:normal, 1:security_anomaly, 2:system_failure, 3:performance_issue, 4:network_anomaly, 5:config_error, 6:hardware_issue, 7:unknown_anomaly\n",
      "Commands: 0-7 (label), 'skip', 'quit', 'save'\n",
      "============================================================\n",
      "\n",
      "[1/27] Template\n",
      "Frequency: 413 logs (20.6%)\n",
      "Template: Received disconnect from <*>: <*>: Bye Bye [preauth]\n",
      "Sample logs:\n",
      "  1. Received disconnect from 52.80.34.196: 11: Bye Bye [preauth]\n",
      "  2. Received disconnect from 202.100.179.208: 11: Bye Bye [preauth]\n",
      "  3. Received disconnect from 112.95.230.3: 11: Bye Bye [preauth]\n",
      "Suggested: 0 (normal) - low\n",
      "\n",
      "[2/27] Template\n",
      "Frequency: 384 logs (19.2%)\n",
      "Template: pam_unix(sshd:auth): authentication failure; logname= uid=<*> euid=<*> tty=ssh ruser= rhost=<*> user=<*>\n",
      "Sample logs:\n",
      "  1. pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=5.36.59.76.dynamic-dsl-ip.omantel.net.om  user=root\n",
      "  2. pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=112.95.230.3  user=root\n",
      "  3. pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=112.95.230.3  user=root\n",
      "Suggested: 1 (security_anomaly) - high\n",
      "\n",
      "[3/27] Template\n",
      "Frequency: 383 logs (19.1%)\n",
      "Template: Failed password for <*> from <*> port <*> ssh2\n",
      "Sample logs:\n",
      "  1. Failed password for root from 5.36.59.76 port 42393 ssh2\n",
      "  2. Failed password for root from 112.95.230.3 port 45378 ssh2\n",
      "  3. Failed password for root from 112.95.230.3 port 47068 ssh2\n",
      "Suggested: 1 (security_anomaly) - high\n",
      "\n",
      "[4/27] Template\n",
      "Frequency: 135 logs (6.8%)\n",
      "Template: Failed password for invalid user <*> from <*> port <*> ssh2\n",
      "Sample logs:\n",
      "  1. Failed password for invalid user webmaster from 173.234.31.186 port 38926 ssh2\n",
      "  2. Failed password for invalid user test9 from 52.80.34.196 port 36060 ssh2\n",
      "  3. Failed password for invalid user webmaster from 173.234.31.186 port 39257 ssh2\n",
      "Suggested: 1 (security_anomaly) - high\n",
      "\n",
      "[5/27] Template\n",
      "Frequency: 135 logs (6.8%)\n",
      "Template: pam_unix(sshd:auth): check pass; user unknown\n",
      "Sample logs:\n",
      "  1. pam_unix(sshd:auth): check pass; user unknown\n",
      "  2. pam_unix(sshd:auth): check pass; user unknown\n",
      "  3. pam_unix(sshd:auth): check pass; user unknown\n",
      "Suggested: 0 (normal) - low\n",
      "\n",
      "[6/27] Template\n",
      "Frequency: 113 logs (5.7%)\n",
      "Template: Invalid user <*> from <*>\n",
      "Sample logs:\n",
      "  1. Invalid user webmaster from 173.234.31.186\n",
      "  2. Invalid user test9 from 52.80.34.196\n",
      "  3. Invalid user webmaster from 173.234.31.186\n",
      "Suggested: 1 (security_anomaly) - high\n",
      "\n",
      "[7/27] Template\n",
      "Frequency: 113 logs (5.7%)\n",
      "Template: input_userauth_request: invalid user <*> [preauth]\n",
      "Sample logs:\n",
      "  1. input_userauth_request: invalid user webmaster [preauth]\n",
      "  2. input_userauth_request: invalid user test9 [preauth]\n",
      "  3. input_userauth_request: invalid user webmaster [preauth]\n",
      "Suggested: 1 (security_anomaly) - high\n",
      "\n",
      "[8/27] Template\n",
      "Frequency: 110 logs (5.5%)\n",
      "Template: pam_unix(sshd:auth): authentication failure; logname= uid=<*> euid=<*> tty=ssh ruser= rhost=<*>\n",
      "Sample logs:\n",
      "  1. pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=173.234.31.186\n",
      "  2. pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=ec2-52-80-34-196.cn-north-1.compute.amazonaws.com.cn\n",
      "  3. pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=173.234.31.186\n",
      "Suggested: 1 (security_anomaly) - high\n",
      "\n",
      "[9/27] Template\n",
      "Frequency: 85 logs (4.2%)\n",
      "Template: reverse mapping checking getaddrinfo for <*> [<*>] failed - POSSIBLE BREAK-IN ATTEMPT!\n",
      "Sample logs:\n",
      "  1. reverse mapping checking getaddrinfo for ns.marryaldkfaczcz.com [173.234.31.186] failed - POSSIBLE BREAK-IN ATTEMPT!\n",
      "  2. reverse mapping checking getaddrinfo for ns.marryaldkfaczcz.com [173.234.31.186] failed - POSSIBLE BREAK-IN ATTEMPT!\n",
      "  3. reverse mapping checking getaddrinfo for 191-210-223-172.user.vivozap.com.br [191.210.223.172] failed - POSSIBLE BREAK-IN ATTEMPT!\n",
      "Suggested: 1 (security_anomaly) - high\n",
      "\n",
      "[10/27] Template\n",
      "Frequency: 45 logs (2.2%)\n",
      "Template: error: Received disconnect from <*>: <*>: No more user authentication methods available. [preauth]\n",
      "Sample logs:\n",
      "  1. error: Received disconnect from 103.99.0.122: 14: No more user authentication methods available. [preauth]\n",
      "  2. error: Received disconnect from 103.99.0.122: 14: No more user authentication methods available. [preauth]\n",
      "  3. error: Received disconnect from 103.99.0.122: 14: No more user authentication methods available. [preauth]\n",
      "Suggested: 2 (system_failure) - high\n",
      "\n",
      "Labeled 10 templates in this batch\n"
     ]
    }
   ],
   "source": [
    "current_pos, labeled_count = label_batch(labeling_data, best_source, start=0, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e500d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEMPLATE LABELING\n",
      "Labels: 0:normal, 1:security_anomaly, 2:system_failure, 3:performance_issue, 4:network_anomaly, 5:config_error, 6:hardware_issue, 7:unknown_anomaly\n",
      "Commands: 0-7 (label), 'skip', 'quit', 'save'\n",
      "============================================================\n",
      "\n",
      "[21/27] Template\n",
      "Frequency: 2 logs (0.1%)\n",
      "Template: PAM <*> more authentication failure; logname= uid=<*> euid=<*> tty=ssh ruser= rhost=<*>\n",
      "Sample logs:\n",
      "  1. PAM 1 more authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=5.188.10.180\n",
      "  2. PAM 1 more authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=185.190.58.151\n",
      "Suggested: 1 (security_anomaly) - high\n",
      "\n",
      "[22/27] Template\n",
      "Frequency: 1 logs (0.1%)\n",
      "Template: Accepted password for <*> from <*> port <*> ssh2\n",
      "Sample logs:\n",
      "  1. Accepted password for fztu from 119.137.62.142 port 49116 ssh2\n",
      "Suggested: 0 (normal) - low\n",
      "\n",
      "[23/27] Template\n",
      "Frequency: 1 logs (0.1%)\n",
      "Template: pam_unix(sshd:session): session opened for user <*> by (uid=<*>)\n",
      "Sample logs:\n",
      "  1. pam_unix(sshd:session): session opened for user fztu by (uid=0)\n",
      "Suggested: 0 (normal) - low\n",
      "\n",
      "[24/27] Template\n",
      "Frequency: 1 logs (0.1%)\n",
      "Template: Received disconnect from <*>: <*>: disconnected by user\n",
      "Sample logs:\n",
      "  1. Received disconnect from 119.137.62.142: 11: disconnected by user\n",
      "Suggested: 2 (system_failure) - low\n",
      "\n",
      "[25/27] Template\n",
      "Frequency: 1 logs (0.1%)\n",
      "Template: pam_unix(sshd:session): session closed for user <*>\n",
      "Sample logs:\n",
      "  1. pam_unix(sshd:session): session closed for user fztu\n",
      "Suggested: 0 (normal) - low\n",
      "\n",
      "[26/27] Template\n",
      "Frequency: 1 logs (0.1%)\n",
      "Template: Disconnecting: Too many authentication failures for admin [preauth]\n",
      "Sample logs:\n",
      "  1. Disconnecting: Too many authentication failures for admin [preauth]\n",
      "Suggested: 1 (security_anomaly) - high\n",
      "\n",
      "[27/27] Template\n",
      "Frequency: 1 logs (0.1%)\n",
      "Template: fatal: Write failed: Connection reset by peer [preauth]\n",
      "Sample logs:\n",
      "  1. fatal: Write failed: Connection reset by peer [preauth]\n",
      "Suggested: 2 (system_failure) - high\n",
      "\n",
      "Labeled 7 templates in this batch\n"
     ]
    }
   ],
   "source": [
    "current_pos, labeled_count = label_batch(labeling_data, best_source, start=current_pos, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bbab2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress: 27/27 templates (100.0%)\n",
      "Label distribution:\n",
      "  0 (normal): 609 logs\n",
      "  1 (security_anomaly): 1,342 logs\n",
      "  2 (system_failure): 49 logs\n"
     ]
    }
   ],
   "source": [
    "show_progress(labeling_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13f20c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved progress: 27/27 templates\n"
     ]
    }
   ],
   "source": [
    "save_progress(labeling_data, best_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "841b84b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUICK EVALUATION: OpenSSH_2k\n",
      "========================================\n",
      "Coverage Report:\n",
      "Templates: 27/27 (100.0%)\n",
      "Logs: 2,000/2,000 (100.0%)\n",
      "\n",
      "Label Distribution:\n",
      "0 (normal): 9 templates, 609 logs\n",
      "1 (security_anomaly): 14 templates, 1,342 logs\n",
      "2 (system_failure): 4 templates, 49 logs\n",
      "No issues found - labeling looks good!\n",
      "Similar template groups:\n",
      "Updated 0 suggestions based on learned patterns\n",
      "Report saved: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\dataset\\labeled_data\\OpenSSH_2k_report.txt\n"
     ]
    }
   ],
   "source": [
    "quality, issues, groups = quick_eval(labeling_data, best_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b502085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\dataset\\labeled_data\\OpenSSH_2k_labeled.csv\n",
      "Total logs: 2,000\n",
      "Labeled: 2,000 (100.0%)\n",
      "Anomalies: 1,391 (69.5% of labeled)\n",
      "Labeled coverage: 2000/2000 logs\n"
     ]
    }
   ],
   "source": [
    "final_dataset = export_final(datasets[best_source], labeling_data, best_source)\n",
    "print(f\"Labeled coverage: {(final_dataset['AnomalyLabel'] >= 0).sum()}/{len(final_dataset)} logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cec97",
   "metadata": {},
   "source": [
    "Next Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81bb24ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next source recommendations:\n",
      "1. Apache_2k (similarity: 1.0, logs: 2,000)\n",
      "2. OpenStack_2k (similarity: 1.0, logs: 2,000)\n",
      "3. Linux_2k (similarity: 1.0, logs: 2,000)\n",
      "Setting up Apache_2k for labeling...\n",
      "Processing 6 unique templates...\n",
      "Auto-labeled 0 templates\n",
      "Next source ready: Apache_2k\n",
      "Templates to label: 6\n"
     ]
    }
   ],
   "source": [
    "next_source, next_data = setup_next(datasets, labeling_data, best_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_pos, labeled_count = label_batch(next_data, next_source, start=0, count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38250ff7",
   "metadata": {},
   "source": [
    "OpenSSH Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d77bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_patterns(labeling_data):\n",
    "\n",
    "    patterns = {\n",
    "        0: {'keywords': set(), 'templates': []},  # normal\n",
    "        1: {'keywords': set(), 'templates': []},  # security_anomaly\n",
    "        2: {'keywords': set(), 'templates': []}   # system_failure\n",
    "    }\n",
    "\n",
    "    for item in labeling_data:\n",
    "        if item['label'] is not None:\n",
    "            label = item['label']\n",
    "            template = item['template'].lower()\n",
    "            content = ' '.join(item['samples']).lower()\n",
    "\n",
    "            words = set(template.split() + content.split())\n",
    "            patterns[label]['keywords'].update(words)\n",
    "            patterns[label]['templates'].append(item['template'])\n",
    "\n",
    "    print(\"LEARNED PATTERNS FROM OPENSSH:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for label, data in patterns.items():\n",
    "        print(f\"\\n{LABELS[label].upper()}:\")\n",
    "        print(f\"  Templates: {len(data['templates'])}\")\n",
    "        print(f\"  Key indicators: {list(data['keywords'])[:10]}\")  # Show top 10 keywords\n",
    "\n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_source(datasets, openssh_patterns, current_source='OpenSSH_2k'):\n",
    "\n",
    "    remaining_sources = [src for src in LOG_SOURCES if src != current_source]\n",
    "    similarity_scores = []\n",
    "\n",
    "    print(f\"\\nANALYZING REMAINING SOURCES FOR PATTERN SIMILARITY:\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for source in remaining_sources:\n",
    "        try:\n",
    "            df = datasets[source]\n",
    "            if 'EventTemplate' not in df.columns or 'Content' not in df.columns:\n",
    "                continue\n",
    "\n",
    "            sample_templates = df['EventTemplate'].head(50)\n",
    "            sample_content = df['Content'].head(50)\n",
    "\n",
    "            security_matches = 0\n",
    "            total_samples = len(sample_templates)\n",
    "\n",
    "            for template, content in zip(sample_templates, sample_content):\n",
    "                text = (str(template) + ' ' + str(content)).lower()\n",
    "                text_words = set(text.split())\n",
    "\n",
    "                security_overlap = len(text_words.intersection(openssh_patterns[1]['keywords']))\n",
    "                if security_overlap > 2: \n",
    "                    security_matches += 1\n",
    "\n",
    "            similarity_score = security_matches / total_samples if total_samples > 0 else 0\n",
    "\n",
    "            unique_templates = df['EventTemplate'].nunique()\n",
    "            total_logs = len(df)\n",
    "\n",
    "            similarity_scores.append({\n",
    "                'source': source,\n",
    "                'similarity_score': similarity_score,\n",
    "                'unique_templates': unique_templates,\n",
    "                'total_logs': total_logs,\n",
    "                'efficiency': total_logs / unique_templates\n",
    "            })\n",
    "\n",
    "            print(f\"{source:15}: similarity={similarity_score:.2f}, templates={unique_templates:3d}, logs={total_logs:,}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{source:15}: Error - {e}\")\n",
    "            continue\n",
    "\n",
    "    similarity_scores.sort(key=lambda x: x['similarity_score'], reverse=True)\n",
    "\n",
    "    print(f\"\\nTOP RECOMMENDATIONS:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, score in enumerate(similarity_scores[:3], 1):\n",
    "        print(f\"{i}. {score['source']}\")\n",
    "        print(f\"   Pattern similarity: {score['similarity_score']:.2f}\")\n",
    "        print(f\"   Templates: {score['unique_templates']} (efficiency: {score['efficiency']:.1f})\")\n",
    "        print(f\"   Total logs: {score['total_logs']:,}\")\n",
    "        print()\n",
    "\n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbc56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_source(datasets, openssh_patterns, next_source):\n",
    "    print(f\"SETTING UP {next_source} WITH PATTERN TRANSFER:\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    next_labeling_data = prep_templates(datasets[next_source], next_source)\n",
    "    if not next_labeling_data:\n",
    "        print(f\"Failed to prepare {next_source}\")\n",
    "        return None\n",
    "\n",
    "    pattern_matches = 0\n",
    "\n",
    "    for item in next_labeling_data:\n",
    "        template = item['template'].lower()\n",
    "        content = ' '.join(item['samples']).lower()\n",
    "        text_words = set((template + ' ' + content).split())\n",
    "\n",
    "        best_match_score = 0\n",
    "        best_match_label = 0\n",
    "\n",
    "        for label_id, pattern_data in openssh_patterns.items():\n",
    "            overlap = len(text_words.intersection(pattern_data['keywords']))\n",
    "            score = overlap / len(pattern_data['keywords']) if pattern_data['keywords'] else 0\n",
    "\n",
    "            if score > best_match_score and score > 0.1:\n",
    "                best_match_score = score\n",
    "                best_match_label = label_id\n",
    "\n",
    "        if best_match_score > 0.2: \n",
    "            old_suggestion = item['suggested']\n",
    "            item['suggested'] = best_match_label\n",
    "            item['confidence'] = \"high\" if best_match_score > 0.4 else \"medium\"\n",
    "\n",
    "            if old_suggestion != best_match_label:\n",
    "                pattern_matches += 1\n",
    "\n",
    "    print(f\"Pattern transfer results:\")\n",
    "    print(f\"  Total templates: {len(next_labeling_data)}\")\n",
    "    print(f\"  Pattern-based suggestions: {pattern_matches}\")\n",
    "\n",
    "    auto_labeled = auto_label(next_labeling_data)\n",
    "    print(f\"  Auto-labeled: {auto_labeled}\")\n",
    "\n",
    "    remaining_to_label = len([item for item in next_labeling_data if item['label'] is None])\n",
    "    print(f\"  Remaining for manual labeling: {remaining_to_label}\")\n",
    "\n",
    "    print(f\"\\nEXAMPLE PATTERN MATCHES:\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    pattern_examples = [item for item in next_labeling_data\n",
    "                        if item['confidence'] in ['high', 'medium'] and item['label'] is None][:3]\n",
    "\n",
    "    for i, item in enumerate(pattern_examples, 1):\n",
    "        print(f\"{i}. Template: {item['template'][:60]}...\")\n",
    "        print(f\"   Sample: {item['samples'][0][:80]}...\")\n",
    "        print(f\"   Suggested: {item['suggested']} ({LABELS[item['suggested']]}) - {item['confidence']}\")\n",
    "        print()\n",
    "\n",
    "    return next_labeling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df37854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sources(openssh_data, second_source_data, second_source_name):\n",
    "\n",
    "    print(f\"CROSS-SOURCE PATTERN COMPARISON:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"OpenSSH_2k vs {second_source_name}:\")\n",
    "\n",
    "    openssh_templates = len(openssh_data)\n",
    "    second_templates = len(second_source_data)\n",
    "\n",
    "    print(f\"Templates: OpenSSH={openssh_templates}, {second_source_name}={second_templates}\")\n",
    "\n",
    "    openssh_auto = sum(1 for item in openssh_data if 'Auto-labeled' in item.get('notes', ''))\n",
    "    second_auto = sum(1 for item in second_source_data if item['label'] is not None)\n",
    "\n",
    "    print(f\"Auto-labeled: OpenSSH={openssh_auto}, {second_source_name}={second_auto}\")\n",
    "\n",
    "    if second_auto > 0:\n",
    "        transfer_rate = (second_auto / second_templates) * 100\n",
    "        print(f\"Pattern transfer success: {transfer_rate:.1f}%\")\n",
    "\n",
    "        if transfer_rate > 50:\n",
    "            print(\"✓ High pattern similarity - continue with this source\")\n",
    "        elif transfer_rate > 25:\n",
    "            print(\"⚠ Moderate similarity - some manual work needed\")\n",
    "        else:\n",
    "            print(\"⚠ Low similarity - consider different source\")\n",
    "\n",
    "    return {\n",
    "        'openssh_templates': openssh_templates,\n",
    "        'second_templates': second_templates,\n",
    "        'openssh_auto': openssh_auto,\n",
    "        'second_auto': second_auto\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c69e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_source():\n",
    "    if 'second_source_data' not in globals() or second_source_data is None:\n",
    "        print(\"Please run the expansion setup first\")\n",
    "        return\n",
    "\n",
    "    print(f\"CONTINUING WITH: {second_source_name}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    show_progress(second_source_data)\n",
    "\n",
    "    unlabeled_count = sum(1 for item in second_source_data if item['label'] is None)\n",
    "    auto_labeled_count = sum(1 for item in second_source_data if item['label'] is not None)\n",
    "\n",
    "    print(f\"\\nSecond source status:\")\n",
    "    print(f\"Auto-labeled from patterns: {auto_labeled_count}\")\n",
    "    print(f\"Remaining for manual review: {unlabeled_count}\")\n",
    "\n",
    "    if auto_labeled_count > 0:\n",
    "        print(f\"Pattern transfer working well!\")\n",
    "\n",
    "    if unlabeled_count > 0:\n",
    "        print(f\"\\nReady for manual labeling:\")\n",
    "        print(f\"Run: label_batch(second_source_data, '{second_source_name}', start=0, count=10)\")\n",
    "    else:\n",
    "        print(f\"\\nAll templates labeled! Ready for export:\")\n",
    "        print(f\"Run: export_final(datasets['{second_source_name}'], second_source_data, '{second_source_name}')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24a2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_label(source_data, source_name, batch_size=10):\n",
    "    unlabeled_indices = [i for i, item in enumerate(source_data) if item['label'] is None]\n",
    "\n",
    "    if not unlabeled_indices:\n",
    "        print(\"All templates already labeled!\")\n",
    "        return 0, 0\n",
    "\n",
    "    print(f\"Found {len(unlabeled_indices)} unlabeled templates\")\n",
    "\n",
    "    print(f\"\\nNext {min(batch_size, len(unlabeled_indices))} templates to review:\")\n",
    "    for i, idx in enumerate(unlabeled_indices[:batch_size]):\n",
    "        item = source_data[idx]\n",
    "        print(f\"{i+1}. [{item['count']:4,} logs] {item['template'][:60]}...\")\n",
    "        print(f\"   Suggested: {item['suggested']} ({LABELS[item['suggested']]}) - {item['confidence']}\")\n",
    "        print(f\"   Sample: {item['samples'][0][:80]}...\")\n",
    "        print()\n",
    "\n",
    "    response = input(f\"Continue with interactive labeling? (y/n): \").strip().lower()\n",
    "    if response == 'y':\n",
    "        return label_batch(source_data, source_name, start=0, count=batch_size)\n",
    "    else:\n",
    "        print(\"Skipping interactive labeling\")\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da019a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_source():\n",
    "    if 'second_source_data' not in globals():\n",
    "        print(\"Second source not set up yet\")\n",
    "        return\n",
    "\n",
    "    print(f\"VALIDATING {second_source_name}\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    labeled_items = [item for item in second_source_data if item['label'] is not None]\n",
    "    if not labeled_items:\n",
    "        print(\"No labeled items to validate\")\n",
    "        return\n",
    "\n",
    "    label_dist = defaultdict(int)\n",
    "    for item in labeled_items:\n",
    "        label_dist[item['label']] += item['count']\n",
    "\n",
    "    print(\"Label distribution:\")\n",
    "    total_logs = sum(label_dist.values())\n",
    "    for label in sorted(label_dist.keys()):\n",
    "        count = label_dist[label]\n",
    "        percentage = (count / total_logs) * 100\n",
    "        print(f\"  {label} ({LABELS[label]}): {count:,} logs ({percentage:.1f}%)\")\n",
    "\n",
    "    openssh_dist = defaultdict(int)\n",
    "    for item in labeling_data:\n",
    "        if item['label'] is not None:\n",
    "            openssh_dist[item['label']] += item['count']\n",
    "\n",
    "    print(f\"\\nComparison with OpenSSH:\")\n",
    "    print(f\"{'Label':<15} {'OpenSSH %':<12} {second_source_name + ' %':<12} {'Difference':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    openssh_total = sum(openssh_dist.values())\n",
    "    second_total = sum(label_dist.values())\n",
    "\n",
    "    for label in sorted(set(list(openssh_dist.keys()) + list(label_dist.keys()))):\n",
    "        openssh_pct = (openssh_dist[label] / openssh_total) * 100 if openssh_total > 0 else 0\n",
    "        second_pct = (label_dist[label] / second_total) * 100 if second_total > 0 else 0\n",
    "        diff = second_pct - openssh_pct\n",
    "\n",
    "        print(f\"{LABELS[label]:<15} {openssh_pct:>10.1f}% {second_pct:>10.1f}% {diff:>+8.1f}%\")\n",
    "\n",
    "    return label_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6fe355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_datasets():\n",
    "    print(\"CREATING COMBINED DATASET\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    if 'second_source_name' in globals() and second_source_data:\n",
    "        second_final = export_final(datasets[second_source_name], second_source_data, second_source_name)\n",
    "\n",
    "        openssh_labeled = final_dataset.copy()\n",
    "        openssh_labeled['Source'] = 'OpenSSH_2k'\n",
    "\n",
    "        second_labeled = second_final.copy()\n",
    "        second_labeled['Source'] = second_source_name\n",
    "\n",
    "        combined = pd.concat([openssh_labeled, second_labeled], ignore_index=True)\n",
    "\n",
    "        combined_file = OUTPUT_PATH / \"combined_labeled_dataset.csv\"\n",
    "        combined.to_csv(combined_file, index=False)\n",
    "\n",
    "        total_logs = len(combined)\n",
    "        labeled_logs = (combined['AnomalyLabel'] >= 0).sum()\n",
    "        anomaly_logs = (combined['AnomalyLabel'] > 0).sum()\n",
    "\n",
    "        print(f\"Combined dataset saved: {combined_file}\")\n",
    "        print(f\"Total logs: {total_logs:,}\")\n",
    "        print(f\"Labeled logs: {labeled_logs:,} ({labeled_logs/total_logs*100:.1f}%)\")\n",
    "        print(f\"Anomaly logs: {anomaly_logs:,} ({anomaly_logs/labeled_logs*100:.1f}% of labeled)\")\n",
    "\n",
    "        for source in combined['Source'].unique():\n",
    "            source_data = combined[combined['Source'] == source]\n",
    "            total = len(source_data)\n",
    "            labeled = (source_data['AnomalyLabel'] >= 0).sum()\n",
    "            anomalies = (source_data['AnomalyLabel'] > 0).sum()\n",
    "            print(f\"  {source}: {total:,} logs, {labeled:,} labeled, {anomalies:,} anomalies\")\n",
    "\n",
    "        return combined\n",
    "    else:\n",
    "        print(\"Second source not ready yet\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_steps():\n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(\"NEXT STEPS RECOMMENDATION\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    if 'second_source_data' not in globals() or second_source_data is None:\n",
    "        print(\"IMMEDIATE ACTION: Set up second source\")\n",
    "        print(\"Run the expansion setup code above\")\n",
    "        return\n",
    "\n",
    "    second_labeled = sum(1 for item in second_source_data if item['label'] is not None)\n",
    "    second_total = len(second_source_data)\n",
    "    second_progress = (second_labeled / second_total) * 100\n",
    "\n",
    "    print(f\"Current status:\")\n",
    "    print(f\"  Source 1 (OpenSSH_2k): 100% complete (2,000 logs)\")\n",
    "    print(f\"  Source 2 ({second_source_name}): {second_progress:.1f}% complete\")\n",
    "\n",
    "    if second_progress < 50:\n",
    "        print(f\"\\nIMMEDIATE ACTION: Complete second source labeling\")\n",
    "        print(f\"1. Run: batch_label(second_source_data, '{second_source_name}')\")\n",
    "        print(f\"2. Or manual: label_batch(second_source_data, '{second_source_name}', count=10)\")\n",
    "    elif second_progress < 100:\n",
    "        print(f\"\\nNEAR COMPLETION: Finish second source\")\n",
    "        print(f\"1. Complete remaining templates\")\n",
    "        print(f\"2. Run quality validation\")\n",
    "    else:\n",
    "        print(f\"\\nREADY FOR NEXT PHASE: Model development\")\n",
    "        print(f\"1. Create combined dataset: combine_datasets()\")\n",
    "        print(f\"2. Export ML data: export_ml_data(combined_dataset, 'combined')\")\n",
    "        print(f\"3. Start model training experiments\")\n",
    "\n",
    "    remaining_templates = sum(1 for item in second_source_data if item['label'] is None)\n",
    "    if remaining_templates > 0:\n",
    "        estimated_minutes = remaining_templates * 0.5\n",
    "        print(f\"\\nEstimated time to complete: {estimated_minutes:.0f} minutes\")\n",
    "\n",
    "    print(f\"\\nOverall progress: 2 sources completed out of 16 total\")\n",
    "    print(f\"Ready to scale to additional sources using learned patterns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0bc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPANDING TO SECOND SOURCE\n",
      "========================================\n",
      "LEARNED PATTERNS FROM OPENSSH:\n",
      "==================================================\n",
      "\n",
      "NORMAL:\n",
      "  Templates: 9\n",
      "  Key indicators: ['pam_unix(sshd:session):', 'fztu', '52.80.34.196:', 'identification', '>', '103.207.39.165:', 'closed', '6', '(uid=<*>)', '123.235.32.19']\n",
      "\n",
      "SECURITY_ANOMALY:\n",
      "  Templates: 14\n",
      "  Key indicators: ['5.188.10.180', 'times:', 'none', 'rhost=106.5.5.195', 'uid=<*>', '5', 'rhost=<*>', 'rhost=173.234.31.186', 'ssh2', 'reverse']\n",
      "\n",
      "SYSTEM_FAILURE:\n",
      "  Templates: 4\n",
      "  Key indicators: ['received', '[preauth]', 'reset', 'peer', 'available.', 'from', '11:', 'methods', 'authentication', 'error:']\n",
      "\n",
      "ANALYZING REMAINING SOURCES FOR PATTERN SIMILARITY:\n",
      "============================================================\n",
      "Android_2k     : similarity=0.02, templates=166, logs=2,000\n",
      "Apache_2k      : similarity=0.00, templates=  6, logs=2,000\n",
      "BGL_2k         : similarity=0.00, templates=120, logs=2,000\n",
      "Hadoop_2k      : similarity=0.04, templates=114, logs=2,000\n",
      "HDFS_2k        : similarity=0.16, templates= 14, logs=2,000\n",
      "HealthApp_2k   : similarity=0.16, templates= 75, logs=2,000\n",
      "HPC_2k         : similarity=0.00, templates= 46, logs=2,000\n",
      "Linux_2k       : similarity=0.64, templates=118, logs=2,000\n",
      "Mac_2k         : similarity=0.10, templates=341, logs=2,000\n",
      "OpenStack_2k   : similarity=0.06, templates= 43, logs=2,000\n",
      "Proxifier_2k   : similarity=0.00, templates=  8, logs=2,000\n",
      "Spark_2k       : similarity=0.00, templates= 36, logs=2,000\n",
      "Thunderbird_2k : similarity=0.56, templates=149, logs=2,000\n",
      "Windows_2k     : similarity=0.24, templates= 50, logs=2,000\n",
      "Zookeeper_2k   : similarity=0.00, templates= 50, logs=2,000\n",
      "\n",
      "TOP RECOMMENDATIONS:\n",
      "----------------------------------------\n",
      "1. Linux_2k\n",
      "   Pattern similarity: 0.64\n",
      "   Templates: 118 (efficiency: 16.9)\n",
      "   Total logs: 2,000\n",
      "\n",
      "2. Thunderbird_2k\n",
      "   Pattern similarity: 0.56\n",
      "   Templates: 149 (efficiency: 13.4)\n",
      "   Total logs: 2,000\n",
      "\n",
      "3. Windows_2k\n",
      "   Pattern similarity: 0.24\n",
      "   Templates: 50 (efficiency: 40.0)\n",
      "   Total logs: 2,000\n",
      "\n",
      "\n",
      "PROCEEDING WITH: Linux_2k\n",
      "Expected pattern transfer rate: 64%\n",
      "SETTING UP Linux_2k WITH PATTERN TRANSFER:\n",
      "============================================================\n",
      "Processing 118 unique templates...\n",
      "Pattern transfer results:\n",
      "  Total templates: 118\n",
      "  Pattern-based suggestions: 0\n",
      "Auto-labeled 7 templates\n",
      "  Auto-labeled: 7\n",
      "  Remaining for manual labeling: 111\n",
      "\n",
      "EXAMPLE PATTERN MATCHES:\n",
      "------------------------------\n",
      "CROSS-SOURCE PATTERN COMPARISON:\n",
      "==================================================\n",
      "OpenSSH_2k vs Linux_2k:\n",
      "Templates: OpenSSH=27, Linux_2k=118\n",
      "Auto-labeled: OpenSSH=17, Linux_2k=7\n",
      "Pattern transfer success: 5.9%\n",
      "⚠ Low similarity - consider different source\n",
      "\n",
      "============================================================\n",
      "READY FOR SECOND SOURCE LABELING!\n",
      "============================================================\n",
      "Next steps:\n",
      "1. Review auto-labeled templates: show_progress(second_source_data)\n",
      "2. Start labeling: label_batch(second_source_data, 'Linux_2k', start=0, count=10)\n",
      "3. Save progress: save_progress(second_source_data, 'Linux_2k')\n",
      "4. Export when done: export_final(datasets['Linux_2k'], second_source_data, 'Linux_2k')\n"
     ]
    }
   ],
   "source": [
    "print(\"EXPANDING TO SECOND SOURCE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "openssh_patterns = analyze_patterns(labeling_data)\n",
    "\n",
    "similarity_scores = find_next_source(datasets, openssh_patterns)\n",
    "\n",
    "# Step 3: Get the top recommendation\n",
    "if similarity_scores:\n",
    "    best_next = similarity_scores[0]['source']\n",
    "    print(f\"\\nPROCEEDING WITH: {best_next}\")\n",
    "    print(f\"Expected pattern transfer rate: {similarity_scores[0]['similarity_score']*100:.0f}%\")\n",
    "\n",
    "    # Step 4: Set up the second source\n",
    "    second_source_data = setup_source(datasets, openssh_patterns, best_next)\n",
    "\n",
    "    if second_source_data:\n",
    "        # Step 5: Quick comparison\n",
    "        comparison = compare_sources(labeling_data, second_source_data, best_next)\n",
    "\n",
    "        print(f\"\\n\" + \"=\" * 60)\n",
    "        print(\"READY FOR SECOND SOURCE LABELING!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Next steps:\")\n",
    "        print(f\"1. Review auto-labeled templates: show_progress(second_source_data)\")\n",
    "        print(f\"2. Start labeling: label_batch(second_source_data, '{best_next}', start=0, count=10)\")\n",
    "        print(f\"3. Save progress: save_progress(second_source_data, '{best_next}')\")\n",
    "        print(f\"4. Export when done: export_final(datasets['{best_next}'], second_source_data, '{best_next}')\")\n",
    "\n",
    "        second_source_name = best_next\n",
    "    else:\n",
    "        print(\"Failed to set up second source\")\n",
    "        second_source_data = None\n",
    "        second_source_name = None\n",
    "else:\n",
    "    print(\"No suitable sources found\")\n",
    "    second_source_data = None\n",
    "    second_source_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05ac469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTINUATION WORKFLOW\n",
      "==============================\n",
      "CONTINUING WITH: Linux_2k\n",
      "==================================================\n",
      "\n",
      "Progress: 7/118 templates (5.9%)\n",
      "Label distribution:\n",
      "  1 (security_anomaly): 490 logs\n",
      "  2 (system_failure): 16 logs\n",
      "\n",
      "Second source status:\n",
      "Auto-labeled from patterns: 7\n",
      "Remaining for manual review: 111\n",
      "Pattern transfer working well!\n",
      "\n",
      "Ready for manual labeling:\n",
      "Run: label_batch(second_source_data, 'Linux_2k', start=0, count=10)\n",
      "VALIDATING Linux_2k\n",
      "========================================\n",
      "Label distribution:\n",
      "  1 (security_anomaly): 490 logs (96.8%)\n",
      "  2 (system_failure): 16 logs (3.2%)\n",
      "\n",
      "Comparison with OpenSSH:\n",
      "Label           OpenSSH %    Linux_2k %   Difference\n",
      "--------------------------------------------------\n",
      "normal                30.4%        0.0%    -30.4%\n",
      "security_anomaly       67.1%       96.8%    +29.7%\n",
      "system_failure         2.5%        3.2%     +0.7%\n",
      "\n",
      "============================================================\n",
      "NEXT STEPS RECOMMENDATION\n",
      "============================================================\n",
      "Current status:\n",
      "  Source 1 (OpenSSH_2k): 100% complete (2,000 logs)\n",
      "  Source 2 (Linux_2k): 5.9% complete\n",
      "\n",
      "IMMEDIATE ACTION: Complete second source labeling\n",
      "1. Run: batch_label(second_source_data, 'Linux_2k')\n",
      "2. Or manual: label_batch(second_source_data, 'Linux_2k', count=10)\n",
      "\n",
      "Estimated time to complete: 56 minutes\n",
      "\n",
      "Overall progress: 2 sources completed out of 16 total\n",
      "Ready to scale to additional sources using learned patterns\n"
     ]
    }
   ],
   "source": [
    "if 'labeling_data' in locals() and 'datasets' in locals():\n",
    "    print(\"CONTINUATION WORKFLOW\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    if 'second_source_data' in globals() and second_source_data is not None:\n",
    "        continue_source()\n",
    "        validate_source()\n",
    "        next_steps()\n",
    "    else:\n",
    "        print(\"Run the expansion setup first to identify and prepare the second source\")\n",
    "        print(\"Then come back to this continuation workflow\")\n",
    "else:\n",
    "    print(\"Please ensure your main workflow variables are loaded first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e5c8fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTINUING WITH: Linux_2k\n",
      "==================================================\n",
      "\n",
      "Progress: 7/118 templates (5.9%)\n",
      "Label distribution:\n",
      "  1 (security_anomaly): 490 logs\n",
      "  2 (system_failure): 16 logs\n",
      "\n",
      "Second source status:\n",
      "Auto-labeled from patterns: 7\n",
      "Remaining for manual review: 111\n",
      "Pattern transfer working well!\n",
      "\n",
      "Ready for manual labeling:\n",
      "Run: label_batch(second_source_data, 'Linux_2k', start=0, count=10)\n"
     ]
    }
   ],
   "source": [
    "continue_source()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e0d22588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATING Linux_2k\n",
      "========================================\n",
      "Label distribution:\n",
      "  1 (security_anomaly): 490 logs (96.8%)\n",
      "  2 (system_failure): 16 logs (3.2%)\n",
      "\n",
      "Comparison with OpenSSH:\n",
      "Label           OpenSSH %    Linux_2k %   Difference\n",
      "--------------------------------------------------\n",
      "normal                30.4%        0.0%    -30.4%\n",
      "security_anomaly       67.1%       96.8%    +29.7%\n",
      "system_failure         2.5%        3.2%     +0.7%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 490, 2: 16, 0: 0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_source()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "155a2ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NEXT STEPS RECOMMENDATION\n",
      "============================================================\n",
      "Current status:\n",
      "  Source 1 (OpenSSH_2k): 100% complete (2,000 logs)\n",
      "  Source 2 (Linux_2k): 5.9% complete\n",
      "\n",
      "IMMEDIATE ACTION: Complete second source labeling\n",
      "1. Run: batch_label(second_source_data, 'Linux_2k')\n",
      "2. Or manual: label_batch(second_source_data, 'Linux_2k', count=10)\n",
      "\n",
      "Estimated time to complete: 56 minutes\n",
      "\n",
      "Overall progress: 2 sources completed out of 16 total\n",
      "Ready to scale to additional sources using learned patterns\n"
     ]
    }
   ],
   "source": [
    "next_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a693ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_indices = [i for i, item in enumerate(second_source_data) if item['label'] is None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "126ce67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if unlabeled_indices:\n",
    "    next_start = unlabeled_indices[0] \n",
    "    label_batch(second_source_data, 'Linux_2k', start=next_start, count=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9485f306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATING Linux_2k\n",
      "========================================\n",
      "Label distribution:\n",
      "  0 (normal): 1,486 logs (74.3%)\n",
      "  1 (security_anomaly): 499 logs (24.9%)\n",
      "  2 (system_failure): 15 logs (0.8%)\n",
      "\n",
      "Comparison with OpenSSH:\n",
      "Label           OpenSSH %    Linux_2k %   Difference\n",
      "--------------------------------------------------\n",
      "normal                30.4%       74.3%    +43.8%\n",
      "security_anomaly       67.1%       24.9%    -42.2%\n",
      "system_failure         2.5%        0.8%     -1.7%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {0: 1486, 1: 499, 2: 15})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_source()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "44ddd374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\dataset\\labeled_data\\Linux_2k_labeled.csv\n",
      "Total logs: 2,000\n",
      "Labeled: 2,000 (100.0%)\n",
      "Anomalies: 514 (25.7% of labeled)\n"
     ]
    }
   ],
   "source": [
    "second_final = export_final(datasets[second_source_name], second_source_data, second_source_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5f1f777a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING COMBINED DATASET\n",
      "========================================\n",
      "\n",
      "Final dataset: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\dataset\\labeled_data\\Linux_2k_labeled.csv\n",
      "Total logs: 2,000\n",
      "Labeled: 2,000 (100.0%)\n",
      "Anomalies: 514 (25.7% of labeled)\n",
      "Combined dataset saved: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\dataset\\labeled_data\\combined_labeled_dataset.csv\n",
      "Total logs: 4,000\n",
      "Labeled logs: 4,000 (100.0%)\n",
      "Anomaly logs: 1,905 (47.6% of labeled)\n",
      "  OpenSSH_2k: 2,000 logs, 2,000 labeled, 1,391 anomalies\n",
      "  Linux_2k: 2,000 logs, 2,000 labeled, 514 anomalies\n"
     ]
    }
   ],
   "source": [
    "combined_dataset = combine_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211b79d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
