{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b2ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully\n",
      "Target sources: 16\n",
      "Label categories: 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PROJECT_ROOT = Path(r\"C:\\Computer Science\\AIMLDL\\log-anomaly-detection\")\n",
    "DATA_PATH = PROJECT_ROOT / \"dataset\" / \"structured_data\"\n",
    "OUTPUT_PATH = PROJECT_ROOT / \"dataset\" / \"labeled_data\"\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "LOG_SOURCES = [\n",
    "    'Android_2k', 'Apache_2k', 'BGL_2k', 'Hadoop_2k', 'HDFS_2k', \n",
    "    'HealthApp_2k', 'HPC_2k', 'Linux_2k', 'Mac_2k', 'OpenSSH_2k',\n",
    "    'OpenStack_2k', 'Proxifier_2k', 'Spark_2k', 'Thunderbird_2k',\n",
    "    'Windows_2k', 'Zookeeper_2k'\n",
    "]\n",
    "\n",
    "LABELS = {\n",
    "    0: \"normal\",\n",
    "    1: \"security_anomaly\", \n",
    "    2: \"system_failure\",\n",
    "    3: \"performance_issue\",\n",
    "    4: \"network_anomaly\", \n",
    "    5: \"config_error\",\n",
    "    6: \"hardware_issue\",\n",
    "    7: \"unknown_anomaly\"\n",
    "}\n",
    "\n",
    "PATTERNS = {\n",
    "    'security': ['authentication failure', 'invalid user', 'break-in attempt', \n",
    "                 'failed password', 'unauthorized', 'access denied', 'login failed',\n",
    "                 'permission denied', 'security violation', 'intrusion'],\n",
    "    'system': ['error', 'critical', 'fatal', 'exception', 'crash', 'abort',\n",
    "               'segmentation fault', 'core dump', 'kernel panic', 'died'],\n",
    "    'performance': ['timeout', 'slow', 'overload', 'resource exhausted', \n",
    "                    'quota exceeded', 'memory pressure', 'cpu spike', 'bottleneck',\n",
    "                    'high latency', 'response time'],\n",
    "    'network': ['connection refused', 'host unreachable', 'network unreachable',\n",
    "                'connection timeout', 'socket error', 'dns error', 'connection lost',\n",
    "                'network down', 'packet loss'],\n",
    "    'config': ['configuration error', 'config invalid', 'parameter error',\n",
    "               'setting invalid', 'option unknown', 'syntax error', 'parse error',\n",
    "               'invalid configuration', 'config mismatch'],\n",
    "    'hardware': ['hardware error', 'disk error', 'i/o error', 'device error',\n",
    "                 'sensor error', 'temperature', 'voltage', 'power failure',\n",
    "                 'component failure', 'device timeout']\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded successfully\")\n",
    "print(f\"Target sources: {len(LOG_SOURCES)}\")\n",
    "print(f\"Label categories: {len(LABELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ff199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_datasets():\n",
    "    datasets = {}\n",
    "    failed = []\n",
    "    \n",
    "    print(\"Loading datasets...\")\n",
    "    for source in LOG_SOURCES:\n",
    "        try:\n",
    "            file_path = DATA_PATH / f\"{source}.log_structured.csv\"\n",
    "            df = pd.read_csv(file_path)\n",
    "            datasets[source] = df\n",
    "            print(f\"âœ“ {source}: {len(df):,} logs, {df.shape[1]} columns\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— {source}: {e}\")\n",
    "            failed.append(source)\n",
    "    \n",
    "    total = sum(len(df) for df in datasets.values())\n",
    "    print(f\"\\nLoaded: {len(datasets)}/{len(LOG_SOURCES)} sources\")\n",
    "    print(f\"Total logs: {total:,}\")\n",
    "    if failed:\n",
    "        print(f\"Failed to load: {failed}\")\n",
    "    \n",
    "    return datasets, failed\n",
    "\n",
    "def analyze_datasets(datasets):\n",
    "    stats = {}\n",
    "    \n",
    "    print(\"Analyzing datasets...\")\n",
    "    for source, df in datasets.items():\n",
    "        if 'EventTemplate' not in df.columns:\n",
    "            print(f\"Warning: {source} missing EventTemplate column\")\n",
    "            continue\n",
    "            \n",
    "        templates = df['EventTemplate'].value_counts()\n",
    "        \n",
    "        anomaly_count = 0\n",
    "        if 'Content' in df.columns:\n",
    "            content_lower = df['Content'].str.lower()\n",
    "            for category, keywords in PATTERNS.items():\n",
    "                pattern = '|'.join(re.escape(kw) for kw in keywords)\n",
    "                matches = content_lower.str.contains(pattern, na=False, regex=True)\n",
    "                anomaly_count += matches.sum()\n",
    "        \n",
    "        stats[source] = {\n",
    "            'logs': len(df),\n",
    "            'templates': len(templates),\n",
    "            'efficiency': len(df) / len(templates),\n",
    "            'anomaly_rate': (anomaly_count / len(df)) * 100,\n",
    "            'top_templates': templates.head(3).to_dict()\n",
    "        }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def rank_sources_by_priority(stats, completed_sources=None):\n",
    "    if completed_sources is None:\n",
    "        completed_sources = []\n",
    "    \n",
    "    rankings = []\n",
    "    \n",
    "    for source, data in stats.items():\n",
    "        if source in completed_sources:\n",
    "            continue\n",
    "        \n",
    "        anomaly_score = data['anomaly_rate']\n",
    "        template_score = max(0, 100 - (data['templates'] / 20))\n",
    "        efficiency_score = min(100, data['efficiency'] / 10)\n",
    "        \n",
    "        priority = (anomaly_score * 0.4 + template_score * 0.3 + efficiency_score * 0.3)\n",
    "        \n",
    "        rankings.append({\n",
    "            'source': source,\n",
    "            'priority': priority,\n",
    "            'anomaly_rate': data['anomaly_rate'],\n",
    "            'templates': data['templates'],\n",
    "            'efficiency': data['efficiency']\n",
    "        })\n",
    "    \n",
    "    return sorted(rankings, key=lambda x: x['priority'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c1ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartPatternLibrary:\n",
    "    def __init__(self, save_path=None):\n",
    "        self.save_path = save_path or (OUTPUT_PATH / \"smart_patterns.json\")\n",
    "        self.label_patterns = {label: {\n",
    "            'keywords': defaultdict(int),\n",
    "            'templates': [],\n",
    "            'sources': set(),\n",
    "            'total_logs': 0\n",
    "        } for label in LABELS.keys()}\n",
    "        self.word_scores = defaultdict(lambda: defaultdict(float))\n",
    "        \n",
    "    def add_source_data(self, labeling_data, source_name):\n",
    "        print(f\"Learning patterns from {source_name}...\")\n",
    "        labeled_items = [item for item in labeling_data if item.get('label') is not None]\n",
    "        \n",
    "        for item in labeled_items:\n",
    "            label = int(item['label'])\n",
    "            template = item['template']\n",
    "            samples = item.get('samples', [])\n",
    "            log_count = item.get('count', 1)\n",
    "            \n",
    "            full_text = template.lower()\n",
    "            if samples:\n",
    "                full_text += ' ' + ' '.join(str(s).lower() for s in samples)\n",
    "            \n",
    "            words = set(re.findall(r'\\b[a-zA-Z]{3,}\\b', full_text))\n",
    "            common_words = {'the', 'and', 'for', 'are', 'with', 'this', 'that', 'from', 'was', 'not'}\n",
    "            words = words - common_words\n",
    "            \n",
    "            self.label_patterns[label]['sources'].add(source_name)\n",
    "            self.label_patterns[label]['templates'].append(template)\n",
    "            self.label_patterns[label]['total_logs'] += log_count\n",
    "            \n",
    "            for word in words:\n",
    "                self.label_patterns[label]['keywords'][word] += log_count\n",
    "                self.word_scores[word][label] += log_count\n",
    "        \n",
    "        self.save_library()\n",
    "        print(f\"Updated pattern library with {len(labeled_items)} templates from {source_name}\")\n",
    "    \n",
    "    def suggest_label(self, template, samples):\n",
    "        full_text = template.lower() + ' ' + ' '.join(str(s).lower() for s in samples)\n",
    "        words = set(re.findall(r'\\b[a-zA-Z]{3,}\\b', full_text))\n",
    "        \n",
    "        label_scores = defaultdict(float)\n",
    "        for word in words:\n",
    "            if word in self.word_scores:\n",
    "                word_total = sum(self.word_scores[word].values())\n",
    "                if word_total > 0:\n",
    "                    for label, score in self.word_scores[word].items():\n",
    "                        label_scores[label] += score / word_total\n",
    "        \n",
    "        if not label_scores:\n",
    "            return 0, \"low\"\n",
    "        \n",
    "        best_label = max(label_scores.keys(), key=lambda x: label_scores[x])\n",
    "        confidence = \"high\" if label_scores[best_label] > 2 else \"medium\" if label_scores[best_label] > 1 else \"low\"\n",
    "        return best_label, confidence\n",
    "    \n",
    "    def save_library(self):\n",
    "        save_data = {\n",
    "            'label_patterns': {},\n",
    "            'word_scores': {}\n",
    "        }\n",
    "        for label, patterns in self.label_patterns.items():\n",
    "            save_data['label_patterns'][str(label)] = {\n",
    "                'keywords': dict(patterns['keywords']),\n",
    "                'templates': patterns['templates'],\n",
    "                'sources': list(patterns['sources']),\n",
    "                'total_logs': patterns['total_logs']\n",
    "            }\n",
    "        for word, scores in self.word_scores.items():\n",
    "            save_data['word_scores'][word] = dict(scores)\n",
    "        \n",
    "        with open(self.save_path, 'w') as f:\n",
    "            json.dump(save_data, f, indent=2)\n",
    "    \n",
    "    def load_library(self):\n",
    "        if not self.save_path.exists():\n",
    "            return False\n",
    "        try:\n",
    "            with open(self.save_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            for label_str, patterns in data['label_patterns'].items():\n",
    "                label = int(label_str)\n",
    "                self.label_patterns[label]['keywords'] = defaultdict(int, patterns['keywords'])\n",
    "                self.label_patterns[label]['templates'] = patterns['templates']\n",
    "                \n",
    "                # Fix: Ensure sources is always a set\n",
    "                sources = patterns.get('sources', [])\n",
    "                if isinstance(sources, list):\n",
    "                    self.label_patterns[label]['sources'] = set(sources)\n",
    "                elif isinstance(sources, set):\n",
    "                    self.label_patterns[label]['sources'] = sources\n",
    "                else:\n",
    "                    # Handle unexpected data types\n",
    "                    self.label_patterns[label]['sources'] = set()\n",
    "                \n",
    "                self.label_patterns[label]['total_logs'] = patterns.get('total_logs', 0)\n",
    "            \n",
    "            self.word_scores.clear()\n",
    "            for word, scores in data.get('word_scores', {}).items():\n",
    "                self.word_scores[word] = defaultdict(float, {int(k): v for k, v in scores.items()})\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading pattern library: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        stats = {}\n",
    "        for label in range(len(LABELS)):\n",
    "            if self.label_patterns[label]['templates']:\n",
    "                # Fix: Ensure sources is always treated as a collection\n",
    "                sources = self.label_patterns[label]['sources']\n",
    "                if isinstance(sources, (list, set)):\n",
    "                    source_count = len(sources)\n",
    "                else:\n",
    "                    # Handle case where sources might be stored as int or other type\n",
    "                    source_count = 1 if sources else 0\n",
    "                \n",
    "                stats[label] = {\n",
    "                    'label_name': LABELS[label],\n",
    "                    'templates': len(self.label_patterns[label]['templates']),\n",
    "                    'keywords': len(self.label_patterns[label]['keywords']),\n",
    "                    'sources': source_count,\n",
    "                    'total_logs': self.label_patterns[label]['total_logs']\n",
    "                }\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e569d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_templates_for_labeling(df, source_name, pattern_library):\n",
    "    if 'EventTemplate' not in df.columns or 'Content' not in df.columns:\n",
    "        print(f\"Error: Missing required columns in {source_name}\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        return []\n",
    "    \n",
    "    templates = df['EventTemplate'].value_counts()\n",
    "    labeling_data = []\n",
    "    \n",
    "    print(f\"Processing {len(templates)} unique templates with smart suggestions...\")\n",
    "    \n",
    "    for template, count in templates.items():\n",
    "        matching_rows = df[df['EventTemplate'] == template]\n",
    "        samples = matching_rows['Content'].head(3).tolist()\n",
    "        samples = [str(s) if s is not None else 'Empty content' for s in samples]\n",
    "        \n",
    "        try:\n",
    "            suggested_label, confidence = pattern_library.suggest_label(template, samples)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Pattern suggestion failed for {template[:50]}: {e}\")\n",
    "            suggested_label, confidence = 0, \"low\"\n",
    "        \n",
    "        labeling_data.append({\n",
    "            'template': template,\n",
    "            'count': count,\n",
    "            'percentage': (count / len(df)) * 100,\n",
    "            'samples': samples,\n",
    "            'suggested': suggested_label,\n",
    "            'confidence': confidence,\n",
    "            'label': None,\n",
    "            'notes': ''\n",
    "        })\n",
    "    \n",
    "    return sorted(labeling_data, key=lambda x: x['count'], reverse=True)\n",
    "\n",
    "def auto_label_high_confidence(labeling_data):\n",
    "    auto_count = 0\n",
    "    for item in labeling_data:\n",
    "        if item['confidence'] == 'high' and item['label'] is None:\n",
    "            item['label'] = item['suggested']\n",
    "            item['notes'] = 'Auto-labeled (high confidence)'\n",
    "            auto_count += 1\n",
    "    \n",
    "    print(f\"Auto-labeled {auto_count} templates\")\n",
    "    return auto_count\n",
    "\n",
    "def interactive_labeling_session(data, source_name, start=0, count=10):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LABELING SESSION: {source_name}\")\n",
    "    print(\"Labels:\", \", \".join(f\"{k}:{v}\" for k, v in LABELS.items()))\n",
    "    print(\"Commands: 0-7 (label), 'skip', 'quit', 'save', 'info'\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    end = min(start + count, len(data))\n",
    "    labeled = 0\n",
    "    \n",
    "    for i in range(start, end):\n",
    "        item = data[i]\n",
    "        \n",
    "        print(f\"\\n[{i+1}/{len(data)}] Template\")\n",
    "        print(f\"Frequency: {item['count']:,} logs ({item['percentage']:.1f}%)\")\n",
    "        print(f\"Template: {item['template']}\")\n",
    "        print(\"Sample logs:\")\n",
    "        \n",
    "        for j, sample in enumerate(item['samples'][:3], 1):\n",
    "            display = sample[:120] + \"...\" if len(sample) > 120 else sample\n",
    "            print(f\"  {j}. {display}\")\n",
    "            \n",
    "        print(f\"Suggested: {item['suggested']} ({LABELS[item['suggested']]}) - {item['confidence']}\")\n",
    "        \n",
    "        while True:\n",
    "            response = input(f\"\\nLabel (suggested {item['suggested']}): \").strip()\n",
    "            \n",
    "            if response.lower() == 'quit':\n",
    "                return i, labeled\n",
    "            elif response.lower() == 'skip':\n",
    "                break\n",
    "            elif response.lower() == 'save':\n",
    "                save_labeling_progress(data, source_name)\n",
    "                continue\n",
    "            elif response.lower() == 'info':\n",
    "                print(f\"\\nAdditional info:\")\n",
    "                print(f\"Template pattern: {item['template']}\")\n",
    "                df = datasets.get(source_name)\n",
    "                if df is not None:\n",
    "                    more_samples = df[df['EventTemplate'] == item['template']]['Content'].head(5).tolist()\n",
    "                    for k, sample in enumerate(more_samples, 1):\n",
    "                        print(f\"  Extra {k}: {str(sample)[:100]}...\")\n",
    "                continue\n",
    "            elif response.isdigit() and 0 <= int(response) < len(LABELS):\n",
    "                item['label'] = int(response)\n",
    "                notes = input(\"Optional notes: \").strip()\n",
    "                if notes:\n",
    "                    item['notes'] = notes\n",
    "                labeled += 1\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Enter a number 0-{len(LABELS)-1}, 'skip', 'save', 'info', or 'quit'\")\n",
    "    \n",
    "    print(f\"\\nLabeled {labeled} templates in this session\")\n",
    "    return end, labeled\n",
    "\n",
    "def bulk_label_by_suggestion(labeling_data):\n",
    "    groups = defaultdict(list)\n",
    "    for item in labeling_data:\n",
    "        if item['label'] is None:\n",
    "            groups[item['suggested']].append(item)\n",
    "    \n",
    "    total_labeled = 0\n",
    "    \n",
    "    print(\"Bulk labeling by pattern suggestions:\")\n",
    "    for suggested_label, items in groups.items():\n",
    "        if len(items) == 0:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{LABELS[suggested_label]}: {len(items)} templates\")\n",
    "        \n",
    "        for i, item in enumerate(items[:3], 1):\n",
    "            print(f\"  {i}. [{item['count']:4,}] {item['template'][:60]}...\")\n",
    "        \n",
    "        if len(items) > 3:\n",
    "            print(f\"  ... and {len(items)-3} more\")\n",
    "        \n",
    "        choice = input(f\"Label all as {LABELS[suggested_label]}? (y/n/s=skip): \").strip().lower()\n",
    "        \n",
    "        if choice == 'y':\n",
    "            for item in items:\n",
    "                item['label'] = suggested_label\n",
    "                item['notes'] = 'Bulk labeled by suggestion'\n",
    "            total_labeled += len(items)\n",
    "            print(f\"Labeled {len(items)} templates\")\n",
    "    \n",
    "    print(f\"\\nBulk labeled {total_labeled} templates total\")\n",
    "    return total_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06885f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labeling_progress(data, source_name):\n",
    "    save_data = []\n",
    "    for item in data:\n",
    "        item_copy = item.copy()\n",
    "        if 'samples' in item_copy:\n",
    "             item_copy['samples'] = json.dumps(item_copy['samples'])\n",
    "        save_data.append(item_copy)\n",
    "    \n",
    "    df = pd.DataFrame(save_data)\n",
    "    progress_file = OUTPUT_PATH / f\"{source_name}_progress.csv\"\n",
    "    df.to_csv(progress_file, index=False)\n",
    "    \n",
    "    labeled = sum(1 for item in data if item['label'] is not None)\n",
    "    print(f\"Progress saved: {labeled}/{len(data)} templates for {source_name}\")\n",
    "\n",
    "def load_labeling_progress(source_name):\n",
    "    progress_file = OUTPUT_PATH / f\"{source_name}_progress.csv\"\n",
    "    if not progress_file.exists():\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(progress_file).where(pd.notna, None)\n",
    "        data = df.to_dict('records')\n",
    "        \n",
    "        for item in data:\n",
    "            if 'samples' in item and isinstance(item['samples'], str):\n",
    "                try:\n",
    "                    item['samples'] = json.loads(item['samples'])\n",
    "                except:\n",
    "                    item['samples'] = ['Error loading samples']\n",
    "        \n",
    "        labeled = sum(1 for item in data if item.get('label') is not None)\n",
    "        print(f\"Loaded progress: {labeled}/{len(data)} templates for {source_name}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading progress for {source_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def show_labeling_progress(data, source_name=None):\n",
    "    total = len(data)\n",
    "    labeled = sum(1 for item in data if item['label'] is not None)\n",
    "    \n",
    "    if source_name:\n",
    "        print(f\"\\nProgress for {source_name}:\")\n",
    "    else:\n",
    "        print(f\"\\nLabeling Progress:\")\n",
    "    \n",
    "    print(f\"Templates: {labeled}/{total} ({labeled/total*100:.1f}%)\")\n",
    "    \n",
    "    if labeled > 0:\n",
    "        total_logs = sum(item['count'] for item in data)\n",
    "        labeled_logs = sum(item['count'] for item in data if item['label'] is not None)\n",
    "        \n",
    "        print(f\"Log coverage: {labeled_logs:,}/{total_logs:,} ({labeled_logs/total_logs*100:.1f}%)\")\n",
    "        \n",
    "        dist = defaultdict(int)\n",
    "        for item in data:\n",
    "            if item['label'] is not None:\n",
    "                dist[int(item['label'])] += item['count']\n",
    "        \n",
    "        print(\"Label distribution:\")\n",
    "        for label in sorted(dist.keys()):\n",
    "            count = dist[label]\n",
    "            print(f\"  {label} ({LABELS[label]}): {count:,} logs\")\n",
    "    \n",
    "    return labeled, total\n",
    "\n",
    "def export_labeled_dataset(df, labeling_data, source_name):\n",
    "    template_labels = {item['template']: item['label'] \n",
    "                       for item in labeling_data if item['label'] is not None}\n",
    "    \n",
    "    result_df = df.copy()\n",
    "    result_df['AnomalyLabel'] = result_df['EventTemplate'].map(template_labels).fillna(-1).astype(int)\n",
    "    result_df['AnomalyLabelName'] = result_df['AnomalyLabel'].map(lambda x: LABELS.get(x, 'unlabeled'))\n",
    "    result_df['Source'] = source_name\n",
    "    \n",
    "    output_file = OUTPUT_PATH / f\"{source_name}_labeled.csv\"\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    total = len(result_df)\n",
    "    labeled_count = (result_df['AnomalyLabel'] >= 0).sum()\n",
    "    anomaly_count = (result_df['AnomalyLabel'] > 0).sum()\n",
    "    \n",
    "    print(f\"\\nExported labeled dataset: {output_file}\")\n",
    "    print(f\"Total logs: {total:,}\")\n",
    "    print(f\"Labeled logs: {labeled_count:,} ({labeled_count/total*100:.1f}%)\")\n",
    "    if labeled_count > 0:\n",
    "        print(f\"Anomaly logs: {anomaly_count:,} ({anomaly_count/labeled_count*100:.1f}% of labeled)\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26859c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceManager:\n",
    "    def __init__(self, datasets, stats, pattern_library):\n",
    "        self.datasets = datasets\n",
    "        self.stats = stats\n",
    "        self.pattern_library = pattern_library\n",
    "        self.completed = []\n",
    "        self.current_data = None\n",
    "        self.current_source = None\n",
    "        self.load_completed_sources()\n",
    "        \n",
    "    def load_completed_sources(self):\n",
    "        completed_file = OUTPUT_PATH / \"completed_sources.json\"\n",
    "        if completed_file.exists():\n",
    "            try:\n",
    "                with open(completed_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    self.completed = data.get('completed', [])\n",
    "                    print(f\"Loaded {len(self.completed)} completed sources from disk\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    def save_completed_sources(self):\n",
    "        completed_file = OUTPUT_PATH / \"completed_sources.json\"\n",
    "        with open(completed_file, 'w') as f:\n",
    "            json.dump({\n",
    "                'completed': self.completed,\n",
    "                'last_updated': datetime.now().isoformat()\n",
    "            }, f, indent=2)\n",
    "    \n",
    "    def get_next_recommended_source(self):\n",
    "        rankings = rank_sources_by_priority(self.stats, self.completed)\n",
    "        if not rankings:\n",
    "            return None\n",
    "        return rankings[0]['source']\n",
    "    \n",
    "    def start_new_source(self, source):\n",
    "        print(f\"\\nStarting source: {source}\")\n",
    "        \n",
    "        existing = load_labeling_progress(source)\n",
    "        if existing:\n",
    "            self.current_data = existing\n",
    "            print(\"Resumed from saved progress\")\n",
    "        else:\n",
    "            self.current_data = prepare_templates_for_labeling(\n",
    "                self.datasets[source], source, self.pattern_library)\n",
    "            auto_label_high_confidence(self.current_data)\n",
    "        \n",
    "        self.current_source = source\n",
    "        show_labeling_progress(self.current_data, source)\n",
    "        \n",
    "        return self.current_data\n",
    "    \n",
    "    def complete_current_source(self):\n",
    "        if not self.current_source or not self.current_data:\n",
    "            print(\"No active source to complete\")\n",
    "            return None\n",
    "        \n",
    "        final_df = export_labeled_dataset(\n",
    "            self.datasets[self.current_source], \n",
    "            self.current_data, \n",
    "            self.current_source\n",
    "        )\n",
    "        \n",
    "        self.pattern_library.add_source_data(self.current_data, self.current_source)\n",
    "        \n",
    "        if self.current_source not in self.completed:\n",
    "            self.completed.append(self.current_source)\n",
    "            self.save_completed_sources()\n",
    "        \n",
    "        print(f\"âœ“ Completed {self.current_source}\")\n",
    "        print(f\"Total completed sources: {len(self.completed)}/{len(LOG_SOURCES)}\")\n",
    "        \n",
    "        completed_source = self.current_source\n",
    "        self.current_source = None\n",
    "        self.current_data = None\n",
    "        \n",
    "        return final_df, completed_source\n",
    "    \n",
    "    def get_overall_status(self):\n",
    "        print(f\"\\nOVERALL STATUS\")\n",
    "        print(f\"{'='*40}\")\n",
    "        print(f\"Total sources: {len(LOG_SOURCES)}\")\n",
    "        print(f\"Completed sources: {len(self.completed)}\")\n",
    "        print(f\"Remaining sources: {len(LOG_SOURCES) - len(self.completed)}\")\n",
    "        print(f\"Progress: {len(self.completed)/len(LOG_SOURCES)*100:.1f}%\")\n",
    "        \n",
    "        if self.completed:\n",
    "            print(f\"\\nCompleted: {', '.join(self.completed)}\")\n",
    "        \n",
    "        try:\n",
    "            lib_stats = self.pattern_library.get_statistics()\n",
    "            if lib_stats:\n",
    "                total_templates = sum(s.get('templates', 0) for s in lib_stats.values())\n",
    "                all_sources = set()\n",
    "                for label_data in lib_stats.values():\n",
    "                    all_sources.update(label_data.get('sources', set()))\n",
    "                total_sources_in_lib = len(all_sources)\n",
    "                \n",
    "                print(f\"\\nPattern library: {total_templates} templates from {total_sources_in_lib} sources\")\n",
    "            else:\n",
    "                print(f\"\\nPattern library: Empty (no patterns learned yet)\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nPattern library: Error reading stats - {e}\")\n",
    "        \n",
    "        if self.current_source:\n",
    "            print(f\"\\nCurrent source: {self.current_source}\")\n",
    "            if self.current_data:\n",
    "                show_labeling_progress(self.current_data, self.current_source)\n",
    "        else:\n",
    "            next_source = self.get_next_recommended_source()\n",
    "            if next_source:\n",
    "                print(f\"\\nNext recommended: {next_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7fc5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_labeling_quality(labeling_data):\n",
    "    issues = []\n",
    "    \n",
    "    for i, item in enumerate(labeling_data):\n",
    "        if item.get('label') is None:\n",
    "            continue\n",
    "            \n",
    "        template = item['template'].lower()\n",
    "        content = ' '.join(str(s) for s in item['samples']).lower()\n",
    "        label = item['label']\n",
    "        \n",
    "        if label == 1:\n",
    "            security_words = ['auth', 'login', 'password', 'user', 'invalid', 'fail', 'denied', 'unauthorized']\n",
    "            if not any(word in content for word in security_words):\n",
    "                issues.append(f\"Template {i}: Security label without security keywords\")\n",
    "        \n",
    "        elif label == 0:\n",
    "            error_words = ['error', 'fail', 'critical', 'exception', 'crash', 'fatal']\n",
    "            if any(word in content for word in error_words):\n",
    "                issues.append(f\"Template {i}: Normal label with error keywords\")\n",
    "        \n",
    "        elif label > 0 and item['percentage'] > 15:\n",
    "            issues.append(f\"Template {i}: High-frequency anomaly ({item['percentage']:.1f}%)\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"\\nFound {len(issues)} potential issues:\")\n",
    "        for issue in issues[:10]:\n",
    "            print(f\"  {issue}\")\n",
    "    else:\n",
    "        print(\"\\nNo validation issues found - labeling quality looks good!\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "def analyze_cross_source_patterns(completed_sources_data):\n",
    "    if len(completed_sources_data) < 2:\n",
    "        print(\"Need at least 2 completed sources for cross-analysis\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nCROSS-SOURCE PATTERN ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    source_distributions = {}\n",
    "    for source_name, data in completed_sources_data.items():\n",
    "        dist = defaultdict(int)\n",
    "        total_logs = 0\n",
    "        \n",
    "        for item in data:\n",
    "            if item['label'] is not None:\n",
    "                dist[item['label']] += item['count']\n",
    "                total_logs += item['count']\n",
    "        \n",
    "        if total_logs > 0:\n",
    "            source_distributions[source_name] = {\n",
    "                label: (count/total_logs)*100 for label, count in dist.items()\n",
    "            }\n",
    "    \n",
    "    print(f\"{'Source':<15}\", end=\"\")\n",
    "    for label_id in sorted(LABELS.keys()):\n",
    "        print(f\"{LABELS[label_id][:8]:<10}\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * (15 + 10 * len(LABELS)))\n",
    "    \n",
    "    for source, dist in source_distributions.items():\n",
    "        print(f\"{source:<15}\", end=\"\")\n",
    "        for label_id in sorted(LABELS.keys()):\n",
    "            pct = dist.get(label_id, 0)\n",
    "            print(f\"{pct:>8.1f}% \", end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da6eafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_dataset(completed_sources):\n",
    "    if not completed_sources:\n",
    "        print(\"No completed sources found\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Creating combined dataset from {len(completed_sources)} sources...\")\n",
    "    \n",
    "    combined_dfs = []\n",
    "    for source in completed_sources:\n",
    "        labeled_file = OUTPUT_PATH / f\"{source}_labeled.csv\"\n",
    "        if labeled_file.exists():\n",
    "            df = pd.read_csv(labeled_file)\n",
    "            combined_dfs.append(df)\n",
    "            print(f\"Added {source}: {len(df):,} logs\")\n",
    "    \n",
    "    if not combined_dfs:\n",
    "        print(\"No labeled datasets found\")\n",
    "        return None\n",
    "    \n",
    "    combined = pd.concat(combined_dfs, ignore_index=True)\n",
    "    \n",
    "    combined_file = OUTPUT_PATH / \"combined_labeled_dataset.csv\"\n",
    "    combined.to_csv(combined_file, index=False)\n",
    "    \n",
    "    total = len(combined)\n",
    "    labeled = (combined['AnomalyLabel'] >= 0).sum()\n",
    "    anomalies = (combined['AnomalyLabel'] > 0).sum()\n",
    "    \n",
    "    print(f\"\\nCombined dataset saved: {combined_file}\")\n",
    "    print(f\"Total logs: {total:,}\")\n",
    "    print(f\"Labeled logs: {labeled:,} ({labeled/total*100:.1f}%)\")\n",
    "    if labeled > 0:\n",
    "        print(f\"Anomaly logs: {anomalies:,} ({anomalies/labeled*100:.1f}% of labeled)\")\n",
    "    \n",
    "    print(f\"\\nPer-source breakdown:\")\n",
    "    for source in combined['Source'].unique():\n",
    "        source_data = combined[combined['Source'] == source]\n",
    "        s_total = len(source_data)\n",
    "        s_labeled = (source_data['AnomalyLabel'] >= 0).sum()\n",
    "        s_anomalies = (source_data['AnomalyLabel'] > 0).sum()\n",
    "        print(f\"  {source}: {s_total:,} logs, {s_labeled:,} labeled, {s_anomalies:,} anomalies\")\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def export_ml_ready_data(dataset, output_name=\"combined\"):\n",
    "    labeled_data = dataset[dataset['AnomalyLabel'] >= 0].copy()\n",
    "    \n",
    "    if len(labeled_data) == 0:\n",
    "        print(\"No labeled data to export for ML\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Preparing ML data from {len(labeled_data):,} labeled logs...\")\n",
    "    \n",
    "    labeled_data['ContentLength'] = labeled_data['Content'].str.len()\n",
    "    labeled_data['TemplateLength'] = labeled_data['EventTemplate'].str.len()\n",
    "    labeled_data['HasError'] = labeled_data['Content'].str.lower().str.contains('error|fail|critical|exception')\n",
    "    labeled_data['HasAuth'] = labeled_data['Content'].str.lower().str.contains('auth|login|user|password')\n",
    "    labeled_data['HasNetwork'] = labeled_data['Content'].str.lower().str.contains('connection|network|timeout')\n",
    "    labeled_data['HasSystem'] = labeled_data['Content'].str.lower().str.contains('system|kernel|process')\n",
    "    labeled_data['HasNumbers'] = labeled_data['Content'].str.contains(r'\\d+')\n",
    "    labeled_data['HasIPAddress'] = labeled_data['Content'].str.contains(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b')\n",
    "    \n",
    "    feature_cols = ['Content', 'EventTemplate', 'ContentLength', 'TemplateLength', \n",
    "                    'HasError', 'HasAuth', 'HasNetwork', 'HasSystem', 'HasNumbers', \n",
    "                    'HasIPAddress', 'Source']\n",
    "    \n",
    "    X = labeled_data[feature_cols]\n",
    "    y = labeled_data['AnomalyLabel']\n",
    "    \n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "    except ValueError:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "    train_file = OUTPUT_PATH / f\"{output_name}_train.csv\"\n",
    "    test_file = OUTPUT_PATH / f\"{output_name}_test.csv\"\n",
    "    \n",
    "    pd.concat([X_train, y_train], axis=1).to_csv(train_file, index=False)\n",
    "    pd.concat([X_test, y_test], axis=1).to_csv(test_file, index=False)\n",
    "    \n",
    "    print(f\"\\nML data exported:\")\n",
    "    print(f\"Training set: {len(X_train):,} samples -> {train_file}\")\n",
    "    print(f\"Test set: {len(X_test):,} samples -> {test_file}\")\n",
    "    \n",
    "    print(f\"\\nTraining set label distribution:\")\n",
    "    for label, count in y_train.value_counts().sort_index().items():\n",
    "        pct = count/len(y_train)*100\n",
    "        print(f\"  {label} ({LABELS[label]}): {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    return train_file, test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f024f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamlined_workflow():\n",
    "    print(\"STREAMLINED MULTI-SOURCE LOG ANOMALY LABELING WORKFLOW\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    source_mgr.get_overall_status()\n",
    "    \n",
    "    if source_mgr.current_source and source_mgr.current_data:\n",
    "        print(f\"\\nActive source: {source_mgr.current_source}\")\n",
    "        labeled, total = show_labeling_progress(source_mgr.current_data, source_mgr.current_source)\n",
    "        \n",
    "        if labeled < total:\n",
    "            print(f\"\\nOptions:\")\n",
    "            print(f\"1. Continue labeling current source\")\n",
    "            print(f\"2. Bulk label remaining templates\")\n",
    "            print(f\"3. Complete source with current progress\")\n",
    "            print(f\"4. Switch to different source\")\n",
    "            \n",
    "            choice = input(\"Choose option (1-4): \").strip()\n",
    "            \n",
    "            if choice == '1':\n",
    "                return continue_labeling_current_source()\n",
    "            elif choice == '2':\n",
    "                return bulk_label_remaining_templates()\n",
    "            elif choice == '3':\n",
    "                return complete_current_source()\n",
    "            elif choice == '4':\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Invalid choice\")\n",
    "                return\n",
    "        else:\n",
    "            print(\"\\nCurrent source fully labeled!\")\n",
    "            choice = input(\"Complete this source? (y/n): \").strip().lower()\n",
    "            if choice == 'y':\n",
    "                return complete_current_source()\n",
    "    \n",
    "    next_source = source_mgr.get_next_recommended_source()\n",
    "    if next_source:\n",
    "        print(f\"\\nNext recommended source: {next_source}\")\n",
    "        source_stats = source_mgr.stats[next_source]\n",
    "        print(f\"  Templates: {source_stats['templates']}\")\n",
    "        print(f\"  Estimated anomaly rate: {source_stats['anomaly_rate']:.1f}%\")\n",
    "        print(f\"  Efficiency: {source_stats['efficiency']:.1f} logs/template\")\n",
    "        \n",
    "        choice = input(\"\\nStart this source? (y/n): \").strip().lower()\n",
    "        if choice == 'y':\n",
    "            source_mgr.start_new_source(next_source)\n",
    "            return 'source_started'\n",
    "    \n",
    "    if len(source_mgr.completed) >= len(LOG_SOURCES):\n",
    "        print(\"\\nðŸŽ‰ All sources completed!\")\n",
    "        print(\"Run create_combined_dataset() and export_ml_ready_data() for final export\")\n",
    "        return 'all_completed'\n",
    "    else:\n",
    "        print(\"\\nNo more recommended sources or user declined.\")\n",
    "        print(\"Use manual commands if needed.\")\n",
    "        return 'manual_needed'\n",
    "\n",
    "def continue_labeling_current_source(batch_size=10):\n",
    "    if not source_mgr.current_source or not source_mgr.current_data:\n",
    "        print(\"No active source. Run streamlined_workflow() first.\")\n",
    "        return\n",
    "    \n",
    "    unlabeled_indices = [i for i, item in enumerate(source_mgr.current_data) \n",
    "                         if item['label'] is None]\n",
    "    \n",
    "    if not unlabeled_indices:\n",
    "        print(\"All templates labeled! Run complete_current_source() to finish.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nContinuing labeling: {source_mgr.current_source}\")\n",
    "    print(f\"Remaining templates: {len(unlabeled_indices)}\")\n",
    "    \n",
    "    start_idx = unlabeled_indices[0]\n",
    "    \n",
    "    pos, labeled = interactive_labeling_session(\n",
    "        source_mgr.current_data, source_mgr.current_source, start_idx, batch_size\n",
    "    )\n",
    "    \n",
    "    save_labeling_progress(source_mgr.current_data, source_mgr.current_source)\n",
    "    \n",
    "    print(f\"\\nSession complete. Progress automatically saved.\")\n",
    "    show_labeling_progress(source_mgr.current_data, source_mgr.current_source)\n",
    "    \n",
    "    return pos, labeled\n",
    "\n",
    "def bulk_label_remaining_templates():\n",
    "    if not source_mgr.current_source or not source_mgr.current_data:\n",
    "        print(\"No active source\")\n",
    "        return\n",
    "    \n",
    "    unlabeled_count = sum(1 for item in source_mgr.current_data if item['label'] is None)\n",
    "    if unlabeled_count == 0:\n",
    "        print(\"All templates already labeled\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nBulk labeling {unlabeled_count} remaining templates...\")\n",
    "    \n",
    "    high_conf_count = 0\n",
    "    for item in source_mgr.current_data:\n",
    "        if item['label'] is None and item['confidence'] == 'high':\n",
    "            item['label'] = item['suggested']\n",
    "            item['notes'] = 'Bulk: Auto-accepted high confidence'\n",
    "            high_conf_count += 1\n",
    "    \n",
    "    print(f\"Auto-accepted {high_conf_count} high confidence suggestions\")\n",
    "    \n",
    "    remaining_unlabeled = [item for item in source_mgr.current_data if item['label'] is None]\n",
    "    if remaining_unlabeled:\n",
    "        total_bulk_labeled = bulk_label_by_suggestion(remaining_unlabeled)\n",
    "        print(f\"Bulk labeled {total_bulk_labeled} additional templates\")\n",
    "    \n",
    "    still_unlabeled = [item for item in source_mgr.current_data if item['label'] is None]\n",
    "    if still_unlabeled:\n",
    "        print(f\"\\nRemaining {len(still_unlabeled)} templates - options:\")\n",
    "        print(\"1. Label all as 'normal' (conservative)\")\n",
    "        print(\"2. Label all as 'unknown_anomaly' (liberal)\")  \n",
    "        print(\"3. Skip (leave unlabeled)\")\n",
    "        \n",
    "        choice = input(\"Choose (1-3): \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            for item in still_unlabeled:\n",
    "                item['label'] = 0\n",
    "                item['notes'] = 'Bulk: Default normal'\n",
    "            print(f\"Labeled {len(still_unlabeled)} templates as normal\")\n",
    "        elif choice == '2':\n",
    "            for item in still_unlabeled:\n",
    "                item['label'] = 7\n",
    "                item['notes'] = 'Bulk: Default unknown anomaly'\n",
    "            print(f\"Labeled {len(still_unlabeled)} templates as unknown anomaly\")\n",
    "    \n",
    "    save_labeling_progress(source_mgr.current_data, source_mgr.current_source)\n",
    "    show_labeling_progress(source_mgr.current_data, source_mgr.current_source)\n",
    "    \n",
    "    return True\n",
    "\n",
    "def complete_current_source():\n",
    "    if not source_mgr.current_source or not source_mgr.current_data:\n",
    "        print(\"No active source to complete\")\n",
    "        return None\n",
    "    \n",
    "    labeled_count = sum(1 for item in source_mgr.current_data if item['label'] is not None)\n",
    "    total_count = len(source_mgr.current_data)\n",
    "    completion_rate = labeled_count / total_count if total_count > 0 else 0\n",
    "    \n",
    "    print(f\"\\nCompleting source: {source_mgr.current_source}\")\n",
    "    print(f\"Template completion: {labeled_count}/{total_count} ({completion_rate*100:.1f}%)\")\n",
    "    \n",
    "    total_logs = sum(item['count'] for item in source_mgr.current_data)\n",
    "    labeled_logs = sum(item['count'] for item in source_mgr.current_data if item['label'] is not None)\n",
    "    log_coverage = labeled_logs / total_logs if total_logs > 0 else 0\n",
    "    \n",
    "    print(f\"Log coverage: {labeled_logs:,}/{total_logs:,} ({log_coverage*100:.1f}%)\")\n",
    "    \n",
    "    if completion_rate < 0.7:\n",
    "        print(\"Warning: Less than 70% of templates labeled\")\n",
    "        choice = input(\"Continue with completion anyway? (y/n): \").strip().lower()\n",
    "        if choice != 'y':\n",
    "            print(\"Completion cancelled. Continue labeling or use bulk labeling.\")\n",
    "            return None\n",
    "    \n",
    "    print(\"\\nValidating labeling quality...\")\n",
    "    issues = validate_labeling_quality(source_mgr.current_data)\n",
    "    \n",
    "    if len(issues) > 5:\n",
    "        print(f\"Found {len(issues)} potential issues. Review recommended.\")\n",
    "        choice = input(\"Continue with completion anyway? (y/n): \").strip().lower()\n",
    "        if choice != 'y':\n",
    "            print(\"Completion cancelled. Review labels first.\")\n",
    "            return None\n",
    "    \n",
    "    final_dataset, completed_source = source_mgr.complete_current_source()\n",
    "    \n",
    "    print(f\"\\nâœ… Successfully completed {completed_source}!\")\n",
    "    print(f\"Pattern library updated with new knowledge\")\n",
    "    \n",
    "    next_source = source_mgr.get_next_recommended_source()\n",
    "    if next_source:\n",
    "        print(f\"\\nNext recommended source: {next_source}\")\n",
    "        print(\"Run streamlined_workflow() to continue\")\n",
    "    else:\n",
    "        print(\"\\nðŸŽ‰ All prioritized sources completed!\")\n",
    "        print(\"Consider creating combined dataset and ML exports\")\n",
    "    \n",
    "    return final_dataset\n",
    "\n",
    "def quick_completion_statistics():\n",
    "    print(\"\\nQUICK COMPLETION STATISTICS\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    completed_count = len(source_mgr.completed)\n",
    "    remaining_count = len(LOG_SOURCES) - completed_count\n",
    "    \n",
    "    print(f\"Progress: {completed_count}/{len(LOG_SOURCES)} sources ({completed_count/len(LOG_SOURCES)*100:.1f}%)\")\n",
    "    \n",
    "    if source_mgr.completed:\n",
    "        print(f\"\\nCompleted sources:\")\n",
    "        total_logs_processed = 0\n",
    "        total_anomalies_found = 0\n",
    "        \n",
    "        for source in source_mgr.completed:\n",
    "            labeled_file = OUTPUT_PATH / f\"{source}_labeled.csv\"\n",
    "            if labeled_file.exists():\n",
    "                df = pd.read_csv(labeled_file)\n",
    "                logs = len(df)\n",
    "                anomalies = (df['AnomalyLabel'] > 0).sum()\n",
    "                total_logs_processed += logs\n",
    "                total_anomalies_found += anomalies\n",
    "                print(f\"  {source}: {logs:,} logs, {anomalies:,} anomalies ({anomalies/logs*100:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\nTotals: {total_logs_processed:,} logs, {total_anomalies_found:,} anomalies\")\n",
    "        \n",
    "        if total_logs_processed > 0:\n",
    "            print(f\"Overall anomaly rate: {total_anomalies_found/total_logs_processed*100:.1f}%\")\n",
    "    \n",
    "    if remaining_count > 0:\n",
    "        print(f\"\\nRemaining sources: {remaining_count}\")\n",
    "        next_source = source_mgr.get_next_recommended_source()\n",
    "        if next_source:\n",
    "            print(f\"Next recommended: {next_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5842fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_system():\n",
    "    global datasets, stats, pattern_library, source_mgr\n",
    "    \n",
    "    print(\"INITIALIZING LOG ANOMALY DETECTION SYSTEM\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"1. Loading datasets...\")\n",
    "    datasets, failed_sources = load_all_datasets()\n",
    "    \n",
    "    if not datasets:\n",
    "        print(\"ERROR: No datasets loaded successfully\")\n",
    "        return False\n",
    "    \n",
    "    print(\"2. Analyzing datasets...\")\n",
    "    stats = analyze_datasets(datasets)\n",
    "    \n",
    "    print(\"3. Initializing pattern library...\")\n",
    "    pattern_library = SmartPatternLibrary()\n",
    "    pattern_library.load_library()\n",
    "    \n",
    "    print(\"4. Setting up source manager...\")\n",
    "    source_mgr = SourceManager(datasets, stats, pattern_library)\n",
    "    \n",
    "    print(\"5. Showing initial rankings...\")\n",
    "    rankings = rank_sources_by_priority(stats, source_mgr.completed)\n",
    "    \n",
    "    print(f\"\\nTop 5 recommended sources:\")\n",
    "    for i, rank in enumerate(rankings[:5], 1):\n",
    "        print(f\"{i}. {rank['source']}: priority={rank['priority']:.1f}, \"\n",
    "              f\"anomalies={rank['anomaly_rate']:.1f}%, templates={rank['templates']}\")\n",
    "    \n",
    "    print(\"\\nâœ… System initialization complete!\")\n",
    "    return True\n",
    "\n",
    "def show_available_commands():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"AVAILABLE COMMANDS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nðŸš€ MAIN WORKFLOW:\")\n",
    "    print(\"  streamlined_workflow()                - Main entry point (start here)\")\n",
    "    print(\"  continue_labeling_current_source()    - Continue current labeling session\")\n",
    "    print(\"  complete_current_source()             - Finish and export current source\")\n",
    "    \n",
    "    print(\"\\nâš¡ BULK OPERATIONS:\")\n",
    "    print(\"  bulk_label_remaining_templates()      - Auto-label remaining templates\")\n",
    "    \n",
    "    print(\"\\nðŸ“Š STATUS & ANALYSIS:\")\n",
    "    print(\"  source_mgr.get_overall_status()       - Show complete progress\")\n",
    "    print(\"  quick_completion_statistics()         - Quick stats overview\")\n",
    "    \n",
    "    print(\"\\nðŸ’¾ DATA MANAGEMENT & EXPORT:\")\n",
    "    print(\"  create_combined_dataset(source_mgr.completed) - Combine completed sources\")\n",
    "    print(\"  export_ml_ready_data(combined_df)     - Export for ML training (use output of previous command)\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ðŸŽ¯ TO GET STARTED:\")\n",
    "    print(\"1. Run the initialization cell below.\")\n",
    "    print(\"2. Run: streamlined_workflow()\")\n",
    "    print(\"3. Follow the guided prompts!\")\n",
    "    print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76f578a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZING LOG ANOMALY DETECTION SYSTEM\n",
      "============================================================\n",
      "1. Loading datasets...\n",
      "Loading datasets...\n",
      "âœ“ Android_2k: 2,000 logs, 10 columns\n",
      "âœ“ Apache_2k: 2,000 logs, 6 columns\n",
      "âœ“ BGL_2k: 2,000 logs, 13 columns\n",
      "âœ“ Hadoop_2k: 2,000 logs, 9 columns\n",
      "âœ“ HDFS_2k: 2,000 logs, 9 columns\n",
      "âœ“ HealthApp_2k: 2,000 logs, 7 columns\n",
      "âœ“ HPC_2k: 2,000 logs, 10 columns\n",
      "âœ“ Linux_2k: 2,000 logs, 10 columns\n",
      "âœ“ Mac_2k: 2,000 logs, 11 columns\n",
      "âœ“ OpenSSH_2k: 2,000 logs, 9 columns\n",
      "âœ“ OpenStack_2k: 2,000 logs, 11 columns\n",
      "âœ“ Proxifier_2k: 2,000 logs, 6 columns\n",
      "âœ“ Spark_2k: 2,000 logs, 8 columns\n",
      "âœ“ Thunderbird_2k: 2,000 logs, 14 columns\n",
      "âœ“ Windows_2k: 2,000 logs, 8 columns\n",
      "âœ“ Zookeeper_2k: 2,000 logs, 10 columns\n",
      "\n",
      "Loaded: 16/16 sources\n",
      "Total logs: 32,000\n",
      "2. Analyzing datasets...\n",
      "Analyzing datasets...\n",
      "3. Initializing pattern library...\n",
      "4. Setting up source manager...\n",
      "Loaded 9 completed sources from disk\n",
      "5. Showing initial rankings...\n",
      "\n",
      "Top 5 recommended sources:\n",
      "1. OpenStack_2k: priority=32.3, anomalies=3.8%, templates=43\n",
      "2. Spark_2k: priority=31.1, anomalies=0.0%, templates=36\n",
      "3. Windows_2k: priority=30.5, anomalies=0.1%, templates=50\n",
      "4. Mac_2k: priority=30.1, anomalies=12.7%, templates=341\n",
      "5. HealthApp_2k: priority=29.7, anomalies=0.1%, templates=75\n",
      "\n",
      "âœ… System initialization complete!\n",
      "\n",
      "======================================================================\n",
      "AVAILABLE COMMANDS\n",
      "======================================================================\n",
      "\n",
      "ðŸš€ MAIN WORKFLOW:\n",
      "  streamlined_workflow()                - Main entry point (start here)\n",
      "  continue_labeling_current_source()    - Continue current labeling session\n",
      "  complete_current_source()             - Finish and export current source\n",
      "\n",
      "âš¡ BULK OPERATIONS:\n",
      "  bulk_label_remaining_templates()      - Auto-label remaining templates\n",
      "\n",
      "ðŸ“Š STATUS & ANALYSIS:\n",
      "  source_mgr.get_overall_status()       - Show complete progress\n",
      "  quick_completion_statistics()         - Quick stats overview\n",
      "\n",
      "ðŸ’¾ DATA MANAGEMENT & EXPORT:\n",
      "  create_combined_dataset(source_mgr.completed) - Combine completed sources\n",
      "  export_ml_ready_data(combined_df)     - Export for ML training (use output of previous command)\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ¯ TO GET STARTED:\n",
      "1. Run the initialization cell below.\n",
      "2. Run: streamlined_workflow()\n",
      "3. Follow the guided prompts!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "success = initialize_system()\n",
    "if success:\n",
    "    show_available_commands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e88f8254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STREAMLINED MULTI-SOURCE LOG ANOMALY LABELING WORKFLOW\n",
      "======================================================================\n",
      "\n",
      "OVERALL STATUS\n",
      "========================================\n",
      "Total sources: 16\n",
      "Completed sources: 10\n",
      "Remaining sources: 6\n",
      "Progress: 62.5%\n",
      "\n",
      "Completed: OpenSSH_2k, Apache_2k, BGL_2k, HPC_2k, Proxifier_2k, Zookeeper_2k, Linux_2k, HDFS_2k, Hadoop_2k, OpenStack_2k\n",
      "\n",
      "Pattern library: Error reading stats - 'int' object is not iterable\n",
      "\n",
      "Current source: Spark_2k\n",
      "\n",
      "Progress for Spark_2k:\n",
      "Templates: 36/36 (100.0%)\n",
      "Log coverage: 2,000/2,000 (100.0%)\n",
      "Label distribution:\n",
      "  0 (normal): 1,581 logs\n",
      "  1 (security_anomaly): 2 logs\n",
      "  3 (performance_issue): 412 logs\n",
      "  5 (config_error): 5 logs\n",
      "\n",
      "Active source: Spark_2k\n",
      "\n",
      "Progress for Spark_2k:\n",
      "Templates: 36/36 (100.0%)\n",
      "Log coverage: 2,000/2,000 (100.0%)\n",
      "Label distribution:\n",
      "  0 (normal): 1,581 logs\n",
      "  1 (security_anomaly): 2 logs\n",
      "  3 (performance_issue): 412 logs\n",
      "  5 (config_error): 5 logs\n",
      "\n",
      "Current source fully labeled!\n",
      "\n",
      "Completing source: Spark_2k\n",
      "Template completion: 36/36 (100.0%)\n",
      "Log coverage: 2,000/2,000 (100.0%)\n",
      "\n",
      "Validating labeling quality...\n",
      "\n",
      "Found 1 potential issues:\n",
      "  Template 0: High-frequency anomaly (18.8%)\n",
      "\n",
      "Exported labeled dataset: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\dataset\\labeled_data\\Spark_2k_labeled.csv\n",
      "Total logs: 2,000\n",
      "Labeled logs: 2,000 (100.0%)\n",
      "Anomaly logs: 419 (20.9% of labeled)\n",
      "Learning patterns from Spark_2k...\n",
      "Updated pattern library with 36 templates from Spark_2k\n",
      "âœ“ Completed Spark_2k\n",
      "Total completed sources: 11/16\n",
      "\n",
      "âœ… Successfully completed Spark_2k!\n",
      "Pattern library updated with new knowledge\n",
      "\n",
      "Next recommended source: Windows_2k\n",
      "Run streamlined_workflow() to continue\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineId</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Level</th>\n",
       "      <th>Component</th>\n",
       "      <th>Content</th>\n",
       "      <th>EventId</th>\n",
       "      <th>EventTemplate</th>\n",
       "      <th>AnomalyLabel</th>\n",
       "      <th>AnomalyLabelName</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17/06/09</td>\n",
       "      <td>20:10:40</td>\n",
       "      <td>INFO</td>\n",
       "      <td>executor.CoarseGrainedExecutorBackend</td>\n",
       "      <td>Registered signal handlers for [TERM, HUP, INT]</td>\n",
       "      <td>E22</td>\n",
       "      <td>Registered signal handlers for [TERM, HUP, INT]</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Spark_2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17/06/09</td>\n",
       "      <td>20:10:40</td>\n",
       "      <td>INFO</td>\n",
       "      <td>spark.SecurityManager</td>\n",
       "      <td>Changing view acls to: yarn,curi</td>\n",
       "      <td>E5</td>\n",
       "      <td>Changing view acls to: &lt;*&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Spark_2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17/06/09</td>\n",
       "      <td>20:10:40</td>\n",
       "      <td>INFO</td>\n",
       "      <td>spark.SecurityManager</td>\n",
       "      <td>Changing modify acls to: yarn,curi</td>\n",
       "      <td>E4</td>\n",
       "      <td>Changing modify acls to: &lt;*&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Spark_2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17/06/09</td>\n",
       "      <td>20:10:40</td>\n",
       "      <td>INFO</td>\n",
       "      <td>spark.SecurityManager</td>\n",
       "      <td>SecurityManager: authentication disabled; ui a...</td>\n",
       "      <td>E26</td>\n",
       "      <td>SecurityManager: authentication disabled; ui a...</td>\n",
       "      <td>1</td>\n",
       "      <td>security_anomaly</td>\n",
       "      <td>Spark_2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17/06/09</td>\n",
       "      <td>20:10:41</td>\n",
       "      <td>INFO</td>\n",
       "      <td>spark.SecurityManager</td>\n",
       "      <td>Changing view acls to: yarn,curi</td>\n",
       "      <td>E5</td>\n",
       "      <td>Changing view acls to: &lt;*&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Spark_2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>17/06/09</td>\n",
       "      <td>20:11:11</td>\n",
       "      <td>INFO</td>\n",
       "      <td>storage.BlockManager</td>\n",
       "      <td>Found block rdd_42_30 locally</td>\n",
       "      <td>E10</td>\n",
       "      <td>Found block rdd_&lt;*&gt; locally</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Spark_2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>17/06/09</td>\n",
       "      <td>20:11:11</td>\n",
       "      <td>INFO</td>\n",
       "      <td>executor.Executor</td>\n",
       "      <td>Finished task 29.0 in stage 29.0 (TID 1349). 2...</td>\n",
       "      <td>E9</td>\n",
       "      <td>Finished task &lt;*&gt; in stage &lt;*&gt; (TID &lt;*&gt;). &lt;*&gt; ...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Spark_2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>17/06/09</td>\n",
       "      <td>20:11:11</td>\n",
       "      <td>INFO</td>\n",
       "      <td>executor.CoarseGrainedExecutorBackend</td>\n",
       "      <td>Got assigned task 1354</td>\n",
       "      <td>E11</td>\n",
       "      <td>Got assigned task &lt;*&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Spark_2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>17/06/09</td>\n",
       "      <td>20:11:11</td>\n",
       "      <td>INFO</td>\n",
       "      <td>executor.Executor</td>\n",
       "      <td>Running task 34.0 in stage 29.0 (TID 1354)</td>\n",
       "      <td>E24</td>\n",
       "      <td>Running task &lt;*&gt; in stage &lt;*&gt; (TID &lt;*&gt;)</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Spark_2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>17/06/09</td>\n",
       "      <td>20:11:11</td>\n",
       "      <td>INFO</td>\n",
       "      <td>storage.BlockManager</td>\n",
       "      <td>Found block rdd_42_32 locally</td>\n",
       "      <td>E10</td>\n",
       "      <td>Found block rdd_&lt;*&gt; locally</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Spark_2k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LineId      Date      Time Level                              Component  \\\n",
       "0          1  17/06/09  20:10:40  INFO  executor.CoarseGrainedExecutorBackend   \n",
       "1          2  17/06/09  20:10:40  INFO                  spark.SecurityManager   \n",
       "2          3  17/06/09  20:10:40  INFO                  spark.SecurityManager   \n",
       "3          4  17/06/09  20:10:40  INFO                  spark.SecurityManager   \n",
       "4          5  17/06/09  20:10:41  INFO                  spark.SecurityManager   \n",
       "...      ...       ...       ...   ...                                    ...   \n",
       "1995    1996  17/06/09  20:11:11  INFO                   storage.BlockManager   \n",
       "1996    1997  17/06/09  20:11:11  INFO                      executor.Executor   \n",
       "1997    1998  17/06/09  20:11:11  INFO  executor.CoarseGrainedExecutorBackend   \n",
       "1998    1999  17/06/09  20:11:11  INFO                      executor.Executor   \n",
       "1999    2000  17/06/09  20:11:11  INFO                   storage.BlockManager   \n",
       "\n",
       "                                                Content EventId  \\\n",
       "0       Registered signal handlers for [TERM, HUP, INT]     E22   \n",
       "1                      Changing view acls to: yarn,curi      E5   \n",
       "2                    Changing modify acls to: yarn,curi      E4   \n",
       "3     SecurityManager: authentication disabled; ui a...     E26   \n",
       "4                      Changing view acls to: yarn,curi      E5   \n",
       "...                                                 ...     ...   \n",
       "1995                      Found block rdd_42_30 locally     E10   \n",
       "1996  Finished task 29.0 in stage 29.0 (TID 1349). 2...      E9   \n",
       "1997                             Got assigned task 1354     E11   \n",
       "1998         Running task 34.0 in stage 29.0 (TID 1354)     E24   \n",
       "1999                      Found block rdd_42_32 locally     E10   \n",
       "\n",
       "                                          EventTemplate  AnomalyLabel  \\\n",
       "0       Registered signal handlers for [TERM, HUP, INT]             0   \n",
       "1                            Changing view acls to: <*>             0   \n",
       "2                          Changing modify acls to: <*>             0   \n",
       "3     SecurityManager: authentication disabled; ui a...             1   \n",
       "4                            Changing view acls to: <*>             0   \n",
       "...                                                 ...           ...   \n",
       "1995                        Found block rdd_<*> locally             0   \n",
       "1996  Finished task <*> in stage <*> (TID <*>). <*> ...             0   \n",
       "1997                              Got assigned task <*>             0   \n",
       "1998            Running task <*> in stage <*> (TID <*>)             0   \n",
       "1999                        Found block rdd_<*> locally             0   \n",
       "\n",
       "      AnomalyLabelName    Source  \n",
       "0               normal  Spark_2k  \n",
       "1               normal  Spark_2k  \n",
       "2               normal  Spark_2k  \n",
       "3     security_anomaly  Spark_2k  \n",
       "4               normal  Spark_2k  \n",
       "...                ...       ...  \n",
       "1995            normal  Spark_2k  \n",
       "1996            normal  Spark_2k  \n",
       "1997            normal  Spark_2k  \n",
       "1998            normal  Spark_2k  \n",
       "1999            normal  Spark_2k  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamlined_workflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
