{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8bcb1eb",
   "metadata": {},
   "source": [
    "Meta-Learning for Few-Shot Log Anomaly Detection in Extreme Imbalance Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d7c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "import gc\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, matthews_corrcoef\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee125145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "ROOT = Path(r\"C:\\Computer Science\\AIMLDL\\log-anomaly-detection\")\n",
    "FEAT_PATH = ROOT / \"features\"\n",
    "RESULTS_PATH = ROOT / \"results\" / \"meta_learning\"\n",
    "MODELS_PATH = ROOT / \"models\" / \"meta_learning\"\n",
    "\n",
    "RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21301e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 sources\n",
      "Classes: 2\n"
     ]
    }
   ],
   "source": [
    "feat_file = FEAT_PATH / \"enhanced_imbalanced_features.pkl\"\n",
    "with open(feat_file, 'rb') as f:\n",
    "    feat_data = pickle.load(f)\n",
    "    data_dict = feat_data['hybrid_features_data']\n",
    "    num_classes = feat_data['config'].get('num_classes', 2)\n",
    "\n",
    "split_file = FEAT_PATH / \"enhanced_cross_source_splits.pkl\"\n",
    "with open(split_file, 'rb') as f:\n",
    "    split_data = pickle.load(f)\n",
    "    splits = split_data['splits']\n",
    "\n",
    "print(f\"Loaded {len(data_dict)} sources\")\n",
    "print(f\"Classes: {num_classes}\")\n",
    "\n",
    "LABEL_MAP = {0: 'normal', 1: 'anomaly'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b44e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, y_proba=None):\n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    metrics['balanced_acc'] = balanced_accuracy_score(y_true, y_pred)\n",
    "    metrics['f1_macro'] = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    metrics['f1_weighted'] = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    metrics['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    per_class = {}\n",
    "    for cls in np.unique(np.concatenate([y_true, y_pred])):\n",
    "        y_true_bin = (y_true == cls).astype(int)\n",
    "        y_pred_bin = (y_pred == cls).astype(int)\n",
    "        if y_true_bin.sum() > 0:\n",
    "            per_class[int(cls)] = {\n",
    "                'precision': precision_score(y_true_bin, y_pred_bin, zero_division=0),\n",
    "                'recall': recall_score(y_true_bin, y_pred_bin, zero_division=0),\n",
    "                'f1': f1_score(y_true_bin, y_pred_bin, zero_division=0),\n",
    "                'support': int(y_true_bin.sum())\n",
    "            }\n",
    "    metrics['per_class'] = per_class\n",
    "    \n",
    "    if y_proba is not None and len(np.unique(y_true)) == 2:\n",
    "        try:\n",
    "            metrics['auroc'] = roc_auc_score(y_true, y_proba[:, 1])\n",
    "            metrics['auprc'] = average_precision_score(y_true, y_proba[:, 1])\n",
    "        except:\n",
    "            metrics['auroc'] = 0.0\n",
    "            metrics['auprc'] = 0.0\n",
    "    else:\n",
    "        metrics['auroc'] = 0.0\n",
    "        metrics['auprc'] = 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def create_few_shot_episode(X, y, n_way, k_shot, q_query, balance=True):\n",
    "    classes = np.unique(y)\n",
    "    if len(classes) < n_way:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    selected_classes = np.random.choice(classes, n_way, replace=False)\n",
    "    \n",
    "    support_X, support_y = [], []\n",
    "    query_X, query_y = [], []\n",
    "    \n",
    "    for cls in selected_classes:\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        \n",
    "        if len(cls_indices) < k_shot + q_query:\n",
    "            if balance:\n",
    "                return None, None, None, None\n",
    "            else:\n",
    "                available = len(cls_indices)\n",
    "                k_use = min(k_shot, available // 2)\n",
    "                q_use = available - k_use\n",
    "                if k_use == 0 or q_use == 0:\n",
    "                    return None, None, None, None\n",
    "        else:\n",
    "            k_use = k_shot\n",
    "            q_use = q_query\n",
    "        \n",
    "        selected = np.random.choice(cls_indices, k_use + q_use, replace=False)\n",
    "        support_indices = selected[:k_use]\n",
    "        query_indices = selected[k_use:k_use + q_use]\n",
    "        \n",
    "        support_X.append(X[support_indices])\n",
    "        support_y.append(y[support_indices])\n",
    "        query_X.append(X[query_indices])\n",
    "        query_y.append(y[query_indices])\n",
    "    \n",
    "    support_X = np.vstack(support_X)\n",
    "    support_y = np.concatenate(support_y)\n",
    "    query_X = np.vstack(query_X)\n",
    "    query_y = np.concatenate(query_y)\n",
    "    \n",
    "    shuffle_support = np.random.permutation(len(support_y))\n",
    "    support_X = support_X[shuffle_support]\n",
    "    support_y = support_y[shuffle_support]\n",
    "    \n",
    "    shuffle_query = np.random.permutation(len(query_y))\n",
    "    query_X = query_X[shuffle_query]\n",
    "    query_y = query_y[shuffle_query]\n",
    "    \n",
    "    return support_X, support_y, query_X, query_y\n",
    "\n",
    "def create_imbalanced_episode(X, y, minority_k_shot, majority_k_shot, q_query_per_class):\n",
    "    classes = np.unique(y)\n",
    "    if len(classes) != 2:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    class_counts = [np.sum(y == cls) for cls in classes]\n",
    "    minority_cls = classes[np.argmin(class_counts)]\n",
    "    majority_cls = classes[np.argmax(class_counts)]\n",
    "    \n",
    "    minority_indices = np.where(y == minority_cls)[0]\n",
    "    majority_indices = np.where(y == majority_cls)[0]\n",
    "    \n",
    "    if len(minority_indices) < minority_k_shot + q_query_per_class:\n",
    "        return None, None, None, None\n",
    "    if len(majority_indices) < majority_k_shot + q_query_per_class:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    minority_selected = np.random.choice(minority_indices, minority_k_shot + q_query_per_class, replace=False)\n",
    "    majority_selected = np.random.choice(majority_indices, majority_k_shot + q_query_per_class, replace=False)\n",
    "    \n",
    "    support_X = np.vstack([X[minority_selected[:minority_k_shot]], X[majority_selected[:majority_k_shot]]])\n",
    "    support_y = np.concatenate([y[minority_selected[:minority_k_shot]], y[majority_selected[:majority_k_shot]]])\n",
    "    \n",
    "    query_X = np.vstack([X[minority_selected[minority_k_shot:]], X[majority_selected[majority_k_shot:]]])\n",
    "    query_y = np.concatenate([y[minority_selected[minority_k_shot:]], y[majority_selected[majority_k_shot:]]])\n",
    "    \n",
    "    shuffle_support = np.random.permutation(len(support_y))\n",
    "    support_X = support_X[shuffle_support]\n",
    "    support_y = support_y[shuffle_support]\n",
    "    \n",
    "    shuffle_query = np.random.permutation(len(query_y))\n",
    "    query_X = query_X[shuffle_query]\n",
    "    query_y = query_y[shuffle_query]\n",
    "    \n",
    "    return support_X, support_y, query_X, query_y\n",
    "\n",
    "\n",
    "def prototypical_loss(embeddings, labels, n_way):\n",
    "    classes = torch.unique(labels)\n",
    "    prototypes = []\n",
    "    \n",
    "    for cls in classes:\n",
    "        cls_mask = labels == cls\n",
    "        cls_embeddings = embeddings[cls_mask]\n",
    "        prototype = cls_embeddings.mean(dim=0)\n",
    "        prototypes.append(prototype)\n",
    "    \n",
    "    prototypes = torch.stack(prototypes)\n",
    "    \n",
    "    distances = torch.cdist(embeddings, prototypes, p=2)\n",
    "    log_probs = F.log_softmax(-distances, dim=1)\n",
    "    \n",
    "    loss = F.nll_loss(log_probs, labels)\n",
    "    return loss\n",
    "\n",
    "def focal_loss(logits, labels, alpha=0.25, gamma=2.0):\n",
    "    ce_loss = F.cross_entropy(logits, labels, reduction='none')\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    focal_loss = alpha * (1 - pt) ** gamma * ce_loss\n",
    "    return focal_loss.mean()\n",
    "\n",
    "def contrastive_loss(embeddings, labels, temperature=0.5):\n",
    "    embeddings = F.normalize(embeddings, dim=1)\n",
    "    similarity_matrix = torch.matmul(embeddings, embeddings.T) / temperature\n",
    "    \n",
    "    labels = labels.contiguous().view(-1, 1)\n",
    "    mask = torch.eq(labels, labels.T).float().to(device)\n",
    "    \n",
    "    logits_max, _ = torch.max(similarity_matrix, dim=1, keepdim=True)\n",
    "    logits = similarity_matrix - logits_max.detach()\n",
    "    \n",
    "    exp_logits = torch.exp(logits)\n",
    "    log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "    \n",
    "    mask_sum = mask.sum(1)\n",
    "    mask_sum = torch.clamp(mask_sum, min=1.0)\n",
    "    \n",
    "    mean_log_prob_pos = (mask * log_prob).sum(1) / mask_sum\n",
    "    loss = -mean_log_prob_pos.mean()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def meta_network(input_dim, hidden_dims=[256, 128], output_dim=64, dropout=0.3):\n",
    "    layers = []\n",
    "    prev_dim = input_dim\n",
    "    for hidden_dim in hidden_dims:\n",
    "        layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "        layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "        prev_dim = hidden_dim\n",
    "    layers.append(nn.Linear(prev_dim, output_dim))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def classifier_head(input_dim, num_classes=2, dropout=0.2):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, input_dim // 2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(input_dim // 2, num_classes)\n",
    "    )\n",
    "\n",
    "def attention_pooling(input_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, 1),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "def maml_inner_loop(model, support_X, support_y, inner_lr, inner_steps, loss_fn):\n",
    "    model_copy = MetaLearner(model.input_dim, model.hidden_dims, model.embedding_dim, \n",
    "                             model.dropout, model.num_classes).to(device)\n",
    "    model_copy.load_state_dict(model.state_dict())\n",
    "    \n",
    "    optimizer = SGD(model_copy.parameters(), lr=inner_lr)\n",
    "    \n",
    "    support_X_tensor = torch.FloatTensor(support_X).to(device)\n",
    "    support_y_tensor = torch.LongTensor(support_y).to(device)\n",
    "    \n",
    "    for step in range(inner_steps):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model_copy.predict(support_X_tensor)\n",
    "        loss = loss_fn(logits, support_y_tensor)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model_copy.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model_copy\n",
    "\n",
    "def memory_efficient_maml(model, support_X, support_y, inner_lr, inner_steps, loss_fn):\n",
    "    params = {name: param.clone() for name, param in model.named_parameters()}\n",
    "    \n",
    "    support_X_tensor = torch.FloatTensor(support_X).to(device)\n",
    "    support_y_tensor = torch.LongTensor(support_y).to(device)\n",
    "    \n",
    "    for step in range(inner_steps):\n",
    "        embeddings = model(support_X_tensor)\n",
    "        logits = model.classifier(embeddings)\n",
    "        loss = loss_fn(logits, support_y_tensor)\n",
    "        \n",
    "        grads = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "        \n",
    "        for (name, param), grad in zip(model.named_parameters(), grads):\n",
    "            param.data = param.data - inner_lr * grad\n",
    "    \n",
    "    result_params = {name: param.clone() for name, param in model.named_parameters()}\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        param.data = params[name].data\n",
    "    \n",
    "    return result_params\n",
    "\n",
    "def process_single_task(encoder_state, classifier_state, source_name, source_features, source_labels, \n",
    "                       source_k_shots, inner_lr, inner_steps, q_query, device_id, input_dim, hidden_dims, \n",
    "                       embedding_dim, dropout, num_classes):\n",
    "    local_device = torch.device(f\"cuda:{device_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    local_encoder = meta_network(input_dim, hidden_dims, embedding_dim, dropout).to(local_device)\n",
    "    local_encoder.load_state_dict(encoder_state)\n",
    "    local_encoder.input_dim = input_dim\n",
    "    local_encoder.hidden_dims = hidden_dims\n",
    "    local_encoder.output_dim = embedding_dim\n",
    "    local_encoder.dropout = dropout\n",
    "    \n",
    "    local_classifier = classifier_head(embedding_dim, num_classes, dropout).to(local_device)\n",
    "    local_classifier.load_state_dict(classifier_state)\n",
    "    local_encoder.classifier = local_classifier\n",
    "    \n",
    "    X_source = source_features[source_name]\n",
    "    y_source = source_labels[source_name]\n",
    "    k_shots = source_k_shots[source_name]\n",
    "    \n",
    "    episode = create_imbalanced_episode(\n",
    "        X_source, y_source, \n",
    "        k_shots['minority'], k_shots['majority'], q_query\n",
    "    )\n",
    "    \n",
    "    if episode[0] is None:\n",
    "        return None\n",
    "    \n",
    "    support_X, support_y, query_X, query_y = episode\n",
    "    \n",
    "    adapted_model = maml_inner_loop(\n",
    "        local_encoder, support_X, support_y, \n",
    "        inner_lr, inner_steps, focal_loss\n",
    "    )\n",
    "    \n",
    "    query_X_tensor = torch.FloatTensor(query_X).to(local_device)\n",
    "    query_y_tensor = torch.LongTensor(query_y).to(local_device)\n",
    "    \n",
    "    query_embeddings = adapted_model(query_X_tensor)\n",
    "    query_logits = adapted_model.classifier(query_embeddings)\n",
    "    \n",
    "    task_loss = focal_loss(query_logits, query_y_tensor)\n",
    "    \n",
    "    return task_loss.cpu()\n",
    "\n",
    "def compute_prototypes(embeddings, labels):\n",
    "    classes = torch.unique(labels)\n",
    "    prototypes = []\n",
    "    for cls in classes:\n",
    "        cls_mask = labels == cls\n",
    "        cls_embeddings = embeddings[cls_mask]\n",
    "        prototype = cls_embeddings.mean(dim=0)\n",
    "        prototypes.append(prototype)\n",
    "    return torch.stack(prototypes), classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2580a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 200\n",
    "hidden_dims = [256, 128]\n",
    "embedding_dim = 64\n",
    "dropout = 0.3\n",
    "\n",
    "class MetaLearner(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, embedding_dim, dropout, num_classes):\n",
    "        super(MetaLearner, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.dropout = dropout\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.encoder = meta_network(input_dim, hidden_dims, embedding_dim, dropout)\n",
    "        self.classifier = classifier_head(embedding_dim, num_classes, dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeddings = self.encoder(x)\n",
    "        return embeddings\n",
    "    \n",
    "    def predict(self, x):\n",
    "        embeddings = self.encoder(x)\n",
    "        logits = self.classifier(embeddings)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f755c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 95,522\n",
      "Encoder parameters: 93,376\n",
      "Classifier parameters: 2,146\n"
     ]
    }
   ],
   "source": [
    "model = MetaLearner(input_dim, hidden_dims, embedding_dim, dropout, num_classes).to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Encoder parameters: {sum(p.numel() for p in model.encoder.parameters()):,}\")\n",
    "print(f\"Classifier parameters: {sum(p.numel() for p in model.classifier.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d9505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meta-Learning Configuration:\n",
      "  Meta LR: 0.001\n",
      "  Inner LR: 0.01\n",
      "  Inner steps: 5\n",
      "  Meta batch size: 8\n",
      "  Iterations: 1000\n",
      "  K-shot (minority): 5\n",
      "  K-shot (majority): 10\n",
      "  Query samples: 15\n",
      "  Early stopping patience: 100\n",
      "  LR scheduler: CosineAnnealingWarmRestarts\n"
     ]
    }
   ],
   "source": [
    "QUICK_TEST = False\n",
    "\n",
    "if QUICK_TEST:\n",
    "    meta_lr = 1e-3\n",
    "    inner_lr = 1e-2\n",
    "    inner_steps = 3\n",
    "    meta_batch_size = 2\n",
    "    num_meta_iterations = 50\n",
    "    k_shot_minority = 3\n",
    "    k_shot_majority = 5\n",
    "    q_query = 10\n",
    "    early_stopping_patience = 20\n",
    "    min_delta = 1e-4\n",
    "    print(\"\\nQUICK TEST MODE ENABLED\")\n",
    "else:\n",
    "    meta_lr = 1e-3\n",
    "    inner_lr = 1e-2\n",
    "    inner_steps = 5\n",
    "    meta_batch_size = 8\n",
    "    num_meta_iterations = 1000\n",
    "    k_shot_minority = 5\n",
    "    k_shot_majority = 10\n",
    "    q_query = 15\n",
    "    early_stopping_patience = 100\n",
    "    min_delta = 1e-4\n",
    "\n",
    "meta_optimizer = Adam(model.parameters(), lr=meta_lr)\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "scheduler = CosineAnnealingWarmRestarts(meta_optimizer, T_0=100, T_mult=2, eta_min=1e-5)\n",
    "\n",
    "print(f\"\\nMeta-Learning Configuration:\")\n",
    "print(f\"  Meta LR: {meta_lr}\")\n",
    "print(f\"  Inner LR: {inner_lr}\")\n",
    "print(f\"  Inner steps: {inner_steps}\")\n",
    "print(f\"  Meta batch size: {meta_batch_size}\")\n",
    "print(f\"  Iterations: {num_meta_iterations}\")\n",
    "print(f\"  K-shot (minority): {k_shot_minority}\")\n",
    "print(f\"  K-shot (majority): {k_shot_majority}\")\n",
    "print(f\"  Query samples: {q_query}\")\n",
    "print(f\"  Early stopping patience: {early_stopping_patience}\")\n",
    "print(f\"  LR scheduler: CosineAnnealingWarmRestarts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598fb2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training sources: 13\n",
      "Sources (sorted by imbalance): ['HPC_2k', 'Windows_2k', 'Hadoop_2k', 'Apache_2k', 'Zookeeper_2k', 'Mac_2k', 'Thunderbird_2k', 'BGL_2k', 'Proxifier_2k', 'Linux_2k', 'Android_2k', 'HealthApp_2k', 'Spark_2k']\n",
      "Imbalance ratios: [('HPC_2k', '1.2:1'), ('Windows_2k', '1.5:1'), ('Hadoop_2k', '1.9:1'), ('Apache_2k', '2.5:1'), ('Zookeeper_2k', '2.9:1')]\n"
     ]
    }
   ],
   "source": [
    "train_sources = []\n",
    "source_imbalance_ratios = {}\n",
    "\n",
    "for source_name, source_data in data_dict.items():\n",
    "    if source_data['labels'] is not None:\n",
    "        labels = source_data['labels']\n",
    "        if len(np.unique(labels)) >= 2:\n",
    "            train_sources.append(source_name)\n",
    "            unique, counts = np.unique(labels, return_counts=True)\n",
    "            imb_ratio = counts.max() / counts.min() if len(counts) > 1 else 1.0\n",
    "            source_imbalance_ratios[source_name] = imb_ratio\n",
    "\n",
    "train_sources_sorted = sorted(train_sources, key=lambda x: source_imbalance_ratios[x])\n",
    "\n",
    "print(f\"\\nTraining sources: {len(train_sources)}\")\n",
    "print(f\"Sources (sorted by imbalance): {train_sources_sorted}\")\n",
    "print(f\"Imbalance ratios: {[(s, f'{source_imbalance_ratios[s]:.1f}:1') for s in train_sources_sorted[:5]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7729dd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Android_2k: 2000 samples, imbalance 75.92:1, k-shot 5/10\n",
      "  Apache_2k: 2000 samples, imbalance 2.50:1, k-shot 5/10\n",
      "  BGL_2k: 2000 samples, imbalance 10.90:1, k-shot 5/10\n",
      "  Hadoop_2k: 2000 samples, imbalance 1.90:1, k-shot 5/10\n",
      "  HealthApp_2k: 2000 samples, imbalance 180.82:1, k-shot 2/5\n",
      "  HPC_2k: 2000 samples, imbalance 1.25:1, k-shot 5/10\n",
      "  Linux_2k: 2000 samples, imbalance 20.28:1, k-shot 5/10\n",
      "  Mac_2k: 2000 samples, imbalance 3.62:1, k-shot 5/10\n",
      "  Proxifier_2k: 2000 samples, imbalance 19.62:1, k-shot 5/10\n",
      "  Spark_2k: 2000 samples, imbalance 249.00:1, k-shot 2/4\n",
      "  Thunderbird_2k: 2000 samples, imbalance 9.26:1, k-shot 5/10\n",
      "  Windows_2k: 2000 samples, imbalance 1.53:1, k-shot 5/10\n",
      "  Zookeeper_2k: 2000 samples, imbalance 2.89:1, k-shot 5/10\n",
      "\n",
      "Prepared 13 sources for meta-training\n"
     ]
    }
   ],
   "source": [
    "feat_variant = 'selected_imbalanced'\n",
    "\n",
    "source_features = {}\n",
    "source_labels = {}\n",
    "source_scalers = {}\n",
    "source_k_shots = {}\n",
    "\n",
    "for source_name in train_sources:\n",
    "    source_data = data_dict[source_name]\n",
    "    if feat_variant in source_data['feature_variants']:\n",
    "        X = source_data['feature_variants'][feat_variant]\n",
    "        y = source_data['labels']\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        source_features[source_name] = X_scaled\n",
    "        source_labels[source_name] = y\n",
    "        source_scalers[source_name] = scaler\n",
    "        \n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        imb_ratio = counts.max() / counts.min() if len(counts) > 1 else 1.0\n",
    "        minority_count = counts.min()\n",
    "        \n",
    "        k_min = max(2, min(k_shot_minority, minority_count // 4))\n",
    "        k_maj = max(k_min, min(k_shot_majority, minority_count // 2))\n",
    "        source_k_shots[source_name] = {'minority': k_min, 'majority': k_maj}\n",
    "        \n",
    "        print(f\"  {source_name}: {len(y)} samples, imbalance {imb_ratio:.2f}:1, k-shot {k_min}/{k_maj}\")\n",
    "\n",
    "print(f\"\\nPrepared {len(source_features)} sources for meta-training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "070f1949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Meta-Training with improvements...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting Meta-Training with improvements...\")\n",
    "\n",
    "best_meta_loss = float('inf')\n",
    "meta_losses = []\n",
    "patience_counter = 0\n",
    "curriculum_phase = 0\n",
    "curriculum_thresholds = [5, 20, 100]\n",
    "\n",
    "def get_curriculum_sources(phase, sources_sorted, imbalance_ratios):\n",
    "    if phase == 0:\n",
    "        return [s for s in sources_sorted if imbalance_ratios[s] <= curriculum_thresholds[0]]\n",
    "    elif phase == 1:\n",
    "        return [s for s in sources_sorted if imbalance_ratios[s] <= curriculum_thresholds[1]]\n",
    "    elif phase == 2:\n",
    "        return [s for s in sources_sorted if imbalance_ratios[s] <= curriculum_thresholds[2]]\n",
    "    else:\n",
    "        return sources_sorted\n",
    "\n",
    "curriculum_sources = get_curriculum_sources(curriculum_phase, train_sources_sorted, source_imbalance_ratios)\n",
    "if not curriculum_sources:\n",
    "    curriculum_sources = train_sources_sorted[:len(train_sources_sorted)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef1d247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with curriculum phase 0: 6 sources\n",
      "Iter 50/1000 - Loss: 0.0459, LR: 0.000505, Patience: 43/100\n",
      "Iter 100/1000 - Loss: 0.0456, LR: 0.001000, Patience: 42/100\n",
      "Iter 150/1000 - Loss: 0.0458, LR: 0.000855, Patience: 25/100\n",
      "Iter 200/1000 - Loss: 0.0457, LR: 0.000505, Patience: 75/100\n",
      "\n",
      "Curriculum phase 1: 9 sources\n",
      "\n",
      "Early stopping at iteration 225\n",
      "\n",
      "Meta-training complete. Best meta loss: 0.0417\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting with curriculum phase {curriculum_phase}: {len(curriculum_sources)} sources\")\n",
    "\n",
    "for iteration in range(num_meta_iterations):\n",
    "    if iteration > 0 and iteration % 200 == 0 and curriculum_phase < 3:\n",
    "        curriculum_phase += 1\n",
    "        curriculum_sources = get_curriculum_sources(curriculum_phase, train_sources_sorted, source_imbalance_ratios)\n",
    "        if not curriculum_sources:\n",
    "            curriculum_sources = train_sources_sorted\n",
    "        print(f\"\\nCurriculum phase {curriculum_phase}: {len(curriculum_sources)} sources\")\n",
    "    \n",
    "    meta_optimizer.zero_grad()\n",
    "    meta_loss = 0.0\n",
    "    valid_tasks = 0\n",
    "    \n",
    "    task_losses = []\n",
    "    \n",
    "    for batch_idx in range(meta_batch_size):\n",
    "        available_sources = [s for s in curriculum_sources if s in source_features]\n",
    "        if not available_sources:\n",
    "            available_sources = list(source_features.keys())\n",
    "        \n",
    "        source_name = np.random.choice(available_sources)\n",
    "        X_source = source_features[source_name]\n",
    "        y_source = source_labels[source_name]\n",
    "        k_shots = source_k_shots[source_name]\n",
    "        \n",
    "        episode = create_imbalanced_episode(\n",
    "            X_source, y_source, \n",
    "            k_shots['minority'], k_shots['majority'], q_query\n",
    "        )\n",
    "        \n",
    "        if episode[0] is None:\n",
    "            continue\n",
    "        \n",
    "        support_X, support_y, query_X, query_y = episode\n",
    "        \n",
    "        adapted_model = maml_inner_loop(\n",
    "            model, support_X, support_y, \n",
    "            inner_lr, inner_steps, focal_loss\n",
    "        )\n",
    "        \n",
    "        query_X_tensor = torch.FloatTensor(query_X).to(device)\n",
    "        query_y_tensor = torch.LongTensor(query_y).to(device)\n",
    "        \n",
    "        query_logits = adapted_model.predict(query_X_tensor)\n",
    "        \n",
    "        task_loss = focal_loss(query_logits, query_y_tensor)\n",
    "        task_losses.append(task_loss)\n",
    "        valid_tasks += 1\n",
    "    \n",
    "    if valid_tasks > 0:\n",
    "        meta_loss = torch.stack(task_losses).mean()\n",
    "        meta_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        meta_optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        current_loss = meta_loss.item()\n",
    "        meta_losses.append(current_loss)\n",
    "        \n",
    "        if current_loss < best_meta_loss - min_delta:\n",
    "            best_meta_loss = current_loss\n",
    "            patience_counter = 0\n",
    "            torch.save({\n",
    "                'model': model.state_dict(),\n",
    "                'iteration': iteration,\n",
    "                'meta_loss': best_meta_loss,\n",
    "                'curriculum_phase': curriculum_phase\n",
    "            }, MODELS_PATH / 'best_meta_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if (iteration + 1) % 50 == 0:\n",
    "            avg_loss = np.mean(meta_losses[-50:])\n",
    "            current_lr = meta_optimizer.param_groups[0]['lr']\n",
    "            print(f\"Iter {iteration + 1}/{num_meta_iterations} - Loss: {avg_loss:.4f}, LR: {current_lr:.6f}, Patience: {patience_counter}/{early_stopping_patience}\")\n",
    "        \n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"\\nEarly stopping at iteration {iteration + 1}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nMeta-training complete. Best meta loss: {best_meta_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad43ba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best meta-model from iteration 124\n",
      "\n",
      "Evaluating on test sources...\n",
      "\n",
      "Android_2k:\n",
      "  F1-Macro: 0.3383\n",
      "  Balanced Acc: 0.7300\n",
      "  AUROC: 0.8929\n",
      "  MCC: 0.1047\n",
      "\n",
      "Apache_2k:\n",
      "  F1-Macro: 0.2195\n",
      "  Balanced Acc: 0.4760\n",
      "  AUROC: 0.8086\n",
      "  MCC: -0.1548\n",
      "\n",
      "BGL_2k:\n",
      "  F1-Macro: 0.1689\n",
      "  Balanced Acc: 0.2253\n",
      "  AUROC: 0.1926\n",
      "  MCC: -0.3661\n",
      "\n",
      "Hadoop_2k:\n",
      "  F1-Macro: 0.3050\n",
      "  Balanced Acc: 0.3173\n",
      "  AUROC: 0.2970\n",
      "  MCC: -0.3875\n",
      "\n",
      "HealthApp_2k:\n",
      "  F1-Macro: 0.1413\n",
      "  Balanced Acc: 0.5779\n",
      "  AUROC: 0.6447\n",
      "  MCC: 0.0319\n",
      "\n",
      "HPC_2k:\n",
      "  F1-Macro: 0.2531\n",
      "  Balanced Acc: 0.3129\n",
      "  AUROC: 0.3385\n",
      "  MCC: -0.4386\n",
      "\n",
      "Linux_2k:\n",
      "  F1-Macro: 0.4578\n",
      "  Balanced Acc: 0.4741\n",
      "  AUROC: 0.4666\n",
      "  MCC: -0.0264\n",
      "\n",
      "Mac_2k:\n",
      "  F1-Macro: 0.3800\n",
      "  Balanced Acc: 0.5642\n",
      "  AUROC: 0.5456\n",
      "  MCC: 0.1296\n",
      "\n",
      "Proxifier_2k:\n",
      "  F1-Macro: 0.2243\n",
      "  Balanced Acc: 0.2786\n",
      "  AUROC: 0.2376\n",
      "  MCC: -0.2096\n",
      "\n",
      "Spark_2k:\n",
      "  F1-Macro: 0.1537\n",
      "  Balanced Acc: 0.4634\n",
      "  AUROC: 0.4470\n",
      "  MCC: -0.0121\n",
      "\n",
      "Thunderbird_2k:\n",
      "  F1-Macro: 0.0973\n",
      "  Balanced Acc: 0.5016\n",
      "  AUROC: 0.8886\n",
      "  MCC: 0.0106\n",
      "\n",
      "Windows_2k:\n",
      "  F1-Macro: 0.3020\n",
      "  Balanced Acc: 0.4884\n",
      "  AUROC: 0.0934\n",
      "  MCC: -0.0607\n",
      "\n",
      "Zookeeper_2k:\n",
      "  F1-Macro: 0.4641\n",
      "  Balanced Acc: 0.6342\n",
      "  AUROC: 0.5761\n",
      "  MCC: 0.2846\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(MODELS_PATH / 'best_meta_model.pt')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "print(f\"Loaded best meta-model from iteration {checkpoint['iteration']}\")\n",
    "\n",
    "print(\"\\nEvaluating on test sources...\")\n",
    "\n",
    "test_results = []\n",
    "\n",
    "test_splits = splits[:3] if QUICK_TEST else splits\n",
    "\n",
    "for split in test_splits:\n",
    "    test_source = split['test_source']\n",
    "    train_sources_split = split['train_sources']\n",
    "    \n",
    "    if test_source not in data_dict:\n",
    "        continue\n",
    "    \n",
    "    test_data = data_dict[test_source]\n",
    "    if test_data['labels'] is None:\n",
    "        continue\n",
    "    \n",
    "    if feat_variant not in test_data['feature_variants']:\n",
    "        continue\n",
    "    \n",
    "    X_test = test_data['feature_variants'][feat_variant]\n",
    "    y_test = test_data['labels']\n",
    "    \n",
    "    if len(np.unique(y_test)) < 2:\n",
    "        continue\n",
    "    \n",
    "    scaler_test = StandardScaler()\n",
    "    X_test_scaled = scaler_test.fit_transform(X_test)\n",
    "    \n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    \n",
    "    for src in train_sources_split:\n",
    "        if src in source_features:\n",
    "            X_train_list.append(source_features[src])\n",
    "            y_train_list.append(source_labels[src])\n",
    "    \n",
    "    if not X_train_list:\n",
    "        continue\n",
    "    \n",
    "    X_train_combined = np.vstack(X_train_list)\n",
    "    y_train_combined = np.concatenate(y_train_list)\n",
    "    \n",
    "    unique, counts = np.unique(y_train_combined, return_counts=True)\n",
    "    minority_count = counts.min()\n",
    "    \n",
    "    k_shot_adapt = min(k_shot_minority, minority_count // 2)\n",
    "    if k_shot_adapt < 2:\n",
    "        continue\n",
    "    \n",
    "    episode = create_imbalanced_episode(\n",
    "        X_train_combined, y_train_combined,\n",
    "        k_shot_adapt, k_shot_adapt * 2, 10\n",
    "    )\n",
    "    \n",
    "    if episode[0] is None:\n",
    "        continue\n",
    "    \n",
    "    support_X, support_y, _, _ = episode\n",
    "    \n",
    "    adapted_model = maml_inner_loop(\n",
    "        model, support_X, support_y,\n",
    "        inner_lr, inner_steps * 2, focal_loss\n",
    "    )\n",
    "    \n",
    "    adapted_model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "        test_logits = adapted_model.predict(X_test_tensor)\n",
    "        test_probs = F.softmax(test_logits, dim=1).cpu().numpy()\n",
    "        test_preds = torch.argmax(test_logits, dim=1).cpu().numpy()\n",
    "    \n",
    "    metrics = calculate_metrics(y_test, test_preds, test_probs)\n",
    "    \n",
    "    test_results.append({\n",
    "        'test_source': test_source,\n",
    "        'f1_macro': metrics['f1_macro'],\n",
    "        'balanced_acc': metrics['balanced_acc'],\n",
    "        'auroc': metrics['auroc'],\n",
    "        'mcc': metrics['mcc'],\n",
    "        'test_samples': len(y_test),\n",
    "        'support_samples': len(support_y)\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{test_source}:\")\n",
    "    print(f\"  F1-Macro: {metrics['f1_macro']:.4f}\")\n",
    "    print(f\"  Balanced Acc: {metrics['balanced_acc']:.4f}\")\n",
    "    print(f\"  AUROC: {metrics['auroc']:.4f}\")\n",
    "    print(f\"  MCC: {metrics['mcc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eef53d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "META-LEARNING EVALUATION SUMMARY\n",
      "================================================================================\n",
      "   test_source  f1_macro  balanced_acc    auroc       mcc  test_samples  support_samples\n",
      "  Zookeeper_2k  0.464143      0.634246 0.576143  0.284632          2000               15\n",
      "      Linux_2k  0.457766      0.474141 0.466561 -0.026444          2000               15\n",
      "        Mac_2k  0.379984      0.564228 0.545648  0.129553          2000               15\n",
      "    Android_2k  0.338315      0.729990 0.892896  0.104651          2000               15\n",
      "     Hadoop_2k  0.304979      0.317275 0.297044 -0.387549          2000               15\n",
      "    Windows_2k  0.302047      0.488363 0.093377 -0.060682          2000               15\n",
      "        HPC_2k  0.253060      0.312886 0.338485 -0.438630          2000               15\n",
      "  Proxifier_2k  0.224257      0.278592 0.237639 -0.209639          2000               15\n",
      "     Apache_2k  0.219481      0.476004 0.808558 -0.154828          2000               15\n",
      "        BGL_2k  0.168943      0.225333 0.192585 -0.366068          2000               15\n",
      "      Spark_2k  0.153670      0.463353 0.446975 -0.012121          2000               15\n",
      "  HealthApp_2k  0.141308      0.577929 0.644682  0.031851          2000               15\n",
      "Thunderbird_2k  0.097269      0.501591 0.888586  0.010596          2000               15\n",
      "\n",
      "============================================================\n",
      "AGGREGATE STATISTICS\n",
      "============================================================\n",
      "Sources evaluated: 13\n",
      "Average F1-Macro: 0.2696 ± 0.1180\n",
      "Average Balanced Acc: 0.4649 ± 0.1474\n",
      "Average AUROC: 0.4946 ± 0.2628\n",
      "Average MCC: -0.0842 ± 0.2173\n",
      "\n",
      "Results saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\results\\meta_learning\\meta_learning_results_20251122_045034.csv\n",
      "Summary saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\results\\meta_learning\\meta_learning_summary.pkl\n"
     ]
    }
   ],
   "source": [
    "if test_results:\n",
    "    df_results = pd.DataFrame(test_results)\n",
    "    df_results = df_results.sort_values('f1_macro', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"META-LEARNING EVALUATION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_results.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AGGREGATE STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Sources evaluated: {len(test_results)}\")\n",
    "    print(f\"Average F1-Macro: {df_results['f1_macro'].mean():.4f} ± {df_results['f1_macro'].std():.4f}\")\n",
    "    print(f\"Average Balanced Acc: {df_results['balanced_acc'].mean():.4f} ± {df_results['balanced_acc'].std():.4f}\")\n",
    "    print(f\"Average AUROC: {df_results['auroc'].mean():.4f} ± {df_results['auroc'].std():.4f}\")\n",
    "    print(f\"Average MCC: {df_results['mcc'].mean():.4f} ± {df_results['mcc'].std():.4f}\")\n",
    "    \n",
    "    results_file = RESULTS_PATH / f\"meta_learning_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    df_results.to_csv(results_file, index=False)\n",
    "    print(f\"\\nResults saved to: {results_file}\")\n",
    "    \n",
    "    with open(RESULTS_PATH / 'meta_learning_summary.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'results': test_results,\n",
    "            'meta_losses': meta_losses,\n",
    "            'config': {\n",
    "                'meta_lr': meta_lr,\n",
    "                'inner_lr': inner_lr,\n",
    "                'inner_steps': inner_steps,\n",
    "                'meta_batch_size': meta_batch_size,\n",
    "                'num_meta_iterations': num_meta_iterations,\n",
    "                'k_shot_minority': k_shot_minority,\n",
    "                'k_shot_majority': k_shot_majority,\n",
    "                'q_query': q_query,\n",
    "                'input_dim': input_dim,\n",
    "                'hidden_dims': hidden_dims,\n",
    "                'embedding_dim': embedding_dim\n",
    "            },\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }, f)\n",
    "    print(f\"Summary saved to: {RESULTS_PATH / 'meta_learning_summary.pkl'}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo test results generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9bc312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prototypical Network Evaluation...\n",
      "\n",
      "Android_2k (Prototypical):\n",
      "  F1-Macro: 0.3740\n",
      "  Balanced Acc: 0.4613\n",
      "  AUROC: 0.4873\n",
      "\n",
      "Apache_2k (Prototypical):\n",
      "  F1-Macro: 0.7000\n",
      "  Balanced Acc: 0.7860\n",
      "  AUROC: 0.9776\n",
      "\n",
      "BGL_2k (Prototypical):\n",
      "  F1-Macro: 0.4609\n",
      "  Balanced Acc: 0.4979\n",
      "  AUROC: 0.4848\n",
      "\n",
      "Hadoop_2k (Prototypical):\n",
      "  F1-Macro: 0.3248\n",
      "  Balanced Acc: 0.3709\n",
      "  AUROC: 0.2035\n",
      "\n",
      "HealthApp_2k (Prototypical):\n",
      "  F1-Macro: 0.2386\n",
      "  Balanced Acc: 0.2023\n",
      "  AUROC: 0.1738\n",
      "\n",
      "HPC_2k (Prototypical):\n",
      "  F1-Macro: 0.6822\n",
      "  Balanced Acc: 0.6834\n",
      "  AUROC: 0.5826\n",
      "\n",
      "Linux_2k (Prototypical):\n",
      "  F1-Macro: 0.2166\n",
      "  Balanced Acc: 0.2532\n",
      "  AUROC: 0.1819\n",
      "\n",
      "Mac_2k (Prototypical):\n",
      "  F1-Macro: 0.5104\n",
      "  Balanced Acc: 0.5531\n",
      "  AUROC: 0.5680\n",
      "\n",
      "Proxifier_2k (Prototypical):\n",
      "  F1-Macro: 0.4154\n",
      "  Balanced Acc: 0.3734\n",
      "  AUROC: 0.3074\n",
      "\n",
      "Spark_2k (Prototypical):\n",
      "  F1-Macro: 0.4762\n",
      "  Balanced Acc: 0.9152\n",
      "  AUROC: 0.9704\n",
      "\n",
      "Thunderbird_2k (Prototypical):\n",
      "  F1-Macro: 0.7134\n",
      "  Balanced Acc: 0.7928\n",
      "  AUROC: 0.8994\n",
      "\n",
      "Windows_2k (Prototypical):\n",
      "  F1-Macro: 0.3611\n",
      "  Balanced Acc: 0.3599\n",
      "  AUROC: 0.4537\n",
      "\n",
      "Zookeeper_2k (Prototypical):\n",
      "  F1-Macro: 0.8754\n",
      "  Balanced Acc: 0.8936\n",
      "  AUROC: 0.9516\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrototypical Network Evaluation...\")\n",
    "\n",
    "prototypical_results = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "proto_splits = splits[:3] if QUICK_TEST else splits\n",
    "\n",
    "for split in proto_splits:\n",
    "    test_source = split['test_source']\n",
    "    \n",
    "    if test_source not in data_dict:\n",
    "        continue\n",
    "    \n",
    "    test_data = data_dict[test_source]\n",
    "    if test_data['labels'] is None or feat_variant not in test_data['feature_variants']:\n",
    "        continue\n",
    "    \n",
    "    X_test = test_data['feature_variants'][feat_variant]\n",
    "    y_test = test_data['labels']\n",
    "    \n",
    "    if len(np.unique(y_test)) < 2:\n",
    "        continue\n",
    "    \n",
    "    scaler_test = StandardScaler()\n",
    "    X_test_scaled = scaler_test.fit_transform(X_test)\n",
    "    \n",
    "    X_train_list = []\n",
    "    y_train_list = []\n",
    "    \n",
    "    for src in split['train_sources']:\n",
    "        if src in source_features:\n",
    "            X_train_list.append(source_features[src])\n",
    "            y_train_list.append(source_labels[src])\n",
    "    \n",
    "    if not X_train_list:\n",
    "        continue\n",
    "    \n",
    "    X_train_combined = np.vstack(X_train_list)\n",
    "    y_train_combined = np.concatenate(y_train_list)\n",
    "    \n",
    "    unique, counts = np.unique(y_train_combined, return_counts=True)\n",
    "    minority_count = counts.min()\n",
    "    k_proto = min(20, minority_count // 2)\n",
    "    \n",
    "    if k_proto < 5:\n",
    "        continue\n",
    "    \n",
    "    episode = create_imbalanced_episode(\n",
    "        X_train_combined, y_train_combined,\n",
    "        k_proto, k_proto * 2, 0\n",
    "    )\n",
    "    \n",
    "    if episode[0] is None:\n",
    "        continue\n",
    "    \n",
    "    support_X, support_y, _, _ = episode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        support_X_tensor = torch.FloatTensor(support_X).to(device)\n",
    "        support_y_tensor = torch.LongTensor(support_y).to(device)\n",
    "        support_embeddings = model(support_X_tensor)\n",
    "        \n",
    "        prototypes, proto_classes = compute_prototypes(support_embeddings, support_y_tensor)\n",
    "        \n",
    "        X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "        test_embeddings = model(X_test_tensor)\n",
    "        \n",
    "        distances = torch.cdist(test_embeddings, prototypes, p=2)\n",
    "        test_preds = torch.argmin(distances, dim=1).cpu().numpy()\n",
    "        \n",
    "        probs = F.softmax(-distances, dim=1).cpu().numpy()\n",
    "    \n",
    "    metrics = calculate_metrics(y_test, test_preds, probs)\n",
    "    \n",
    "    prototypical_results.append({\n",
    "        'test_source': test_source,\n",
    "        'f1_macro': metrics['f1_macro'],\n",
    "        'balanced_acc': metrics['balanced_acc'],\n",
    "        'auroc': metrics['auroc'],\n",
    "        'mcc': metrics['mcc'],\n",
    "        'test_samples': len(y_test),\n",
    "        'prototypes': len(prototypes)\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{test_source} (Prototypical):\")\n",
    "    print(f\"  F1-Macro: {metrics['f1_macro']:.4f}\")\n",
    "    print(f\"  Balanced Acc: {metrics['balanced_acc']:.4f}\")\n",
    "    print(f\"  AUROC: {metrics['auroc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96869ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PROTOTYPICAL NETWORK EVALUATION SUMMARY\n",
      "================================================================================\n",
      "   test_source  f1_macro  balanced_acc    auroc       mcc  test_samples  prototypes\n",
      "  Zookeeper_2k  0.875446      0.893592 0.951563  0.754650          2000           2\n",
      "Thunderbird_2k  0.713395      0.792833 0.899428  0.458260          2000           2\n",
      "     Apache_2k  0.699977      0.786024 0.977609  0.520686          2000           2\n",
      "        HPC_2k  0.682177      0.683364 0.582615  0.365182          2000           2\n",
      "        Mac_2k  0.510389      0.553081 0.567969  0.087924          2000           2\n",
      "      Spark_2k  0.476247      0.915161 0.970444  0.138557          2000           2\n",
      "        BGL_2k  0.460949      0.497882 0.484788 -0.002561          2000           2\n",
      "  Proxifier_2k  0.415376      0.373358 0.307393 -0.127220          2000           2\n",
      "    Android_2k  0.374027      0.461324 0.487316 -0.017738          2000           2\n",
      "    Windows_2k  0.361068      0.359891 0.453685 -0.277294          2000           2\n",
      "     Hadoop_2k  0.324830      0.370909 0.203492 -0.264555          2000           2\n",
      "  HealthApp_2k  0.238622      0.202317 0.173774 -0.094630          2000           2\n",
      "      Linux_2k  0.216627      0.253243 0.181923 -0.231377          2000           2\n",
      "\n",
      "============================================================\n",
      "PROTOTYPICAL AGGREGATE STATISTICS\n",
      "============================================================\n",
      "Sources evaluated: 13\n",
      "Average F1-Macro: 0.4884 ± 0.2004\n",
      "Average Balanced Acc: 0.5495 ± 0.2420\n",
      "Average AUROC: 0.5571 ± 0.3051\n",
      "\n",
      "Prototypical results saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\results\\meta_learning\\prototypical_results_20251122_045035.csv\n"
     ]
    }
   ],
   "source": [
    "if prototypical_results:\n",
    "    df_proto = pd.DataFrame(prototypical_results)\n",
    "    df_proto = df_proto.sort_values('f1_macro', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PROTOTYPICAL NETWORK EVALUATION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_proto.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROTOTYPICAL AGGREGATE STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Sources evaluated: {len(prototypical_results)}\")\n",
    "    print(f\"Average F1-Macro: {df_proto['f1_macro'].mean():.4f} ± {df_proto['f1_macro'].std():.4f}\")\n",
    "    print(f\"Average Balanced Acc: {df_proto['balanced_acc'].mean():.4f} ± {df_proto['balanced_acc'].std():.4f}\")\n",
    "    print(f\"Average AUROC: {df_proto['auroc'].mean():.4f} ± {df_proto['auroc'].std():.4f}\")\n",
    "    \n",
    "    proto_file = RESULTS_PATH / f\"prototypical_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    df_proto.to_csv(proto_file, index=False)\n",
    "    print(f\"\\nPrototypical results saved to: {proto_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba438ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Few-Shot Transfer Learning Evaluation...\n",
      "\n",
      "Apache_2k (Transfer):\n",
      "  F1-Macro: 0.9930\n",
      "  Balanced Acc: 0.9960\n",
      "  AUROC: 0.9996\n",
      "\n",
      "BGL_2k (Transfer):\n",
      "  F1-Macro: 0.9681\n",
      "  Balanced Acc: 0.9753\n",
      "  AUROC: 0.9964\n",
      "\n",
      "Hadoop_2k (Transfer):\n",
      "  F1-Macro: 0.9603\n",
      "  Balanced Acc: 0.9673\n",
      "  AUROC: 0.9905\n",
      "\n",
      "HPC_2k (Transfer):\n",
      "  F1-Macro: 0.9755\n",
      "  Balanced Acc: 0.9772\n",
      "  AUROC: 0.9983\n",
      "\n",
      "Linux_2k (Transfer):\n",
      "  F1-Macro: 0.9397\n",
      "  Balanced Acc: 0.9936\n",
      "  AUROC: 0.9997\n",
      "\n",
      "Mac_2k (Transfer):\n",
      "  F1-Macro: 0.9676\n",
      "  Balanced Acc: 0.9703\n",
      "  AUROC: 0.9844\n",
      "\n",
      "Proxifier_2k (Transfer):\n",
      "  F1-Macro: 1.0000\n",
      "  Balanced Acc: 1.0000\n",
      "  AUROC: 1.0000\n",
      "\n",
      "Thunderbird_2k (Transfer):\n",
      "  F1-Macro: 0.8563\n",
      "  Balanced Acc: 0.9212\n",
      "  AUROC: 0.9901\n",
      "\n",
      "Windows_2k (Transfer):\n",
      "  F1-Macro: 0.9829\n",
      "  Balanced Acc: 0.9858\n",
      "  AUROC: 0.9997\n",
      "\n",
      "Zookeeper_2k (Transfer):\n",
      "  F1-Macro: 0.9917\n",
      "  Balanced Acc: 0.9957\n",
      "  AUROC: 0.9999\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFew-Shot Transfer Learning Evaluation...\")\n",
    "\n",
    "transfer_results = []\n",
    "\n",
    "transfer_splits = splits[:3] if QUICK_TEST else splits\n",
    "\n",
    "for split in transfer_splits:\n",
    "    test_source = split['test_source']\n",
    "    \n",
    "    if test_source not in data_dict:\n",
    "        continue\n",
    "    \n",
    "    test_data = data_dict[test_source]\n",
    "    if test_data['labels'] is None or feat_variant not in test_data['feature_variants']:\n",
    "        continue\n",
    "    \n",
    "    X_test_full = test_data['feature_variants'][feat_variant]\n",
    "    y_test_full = test_data['labels']\n",
    "    \n",
    "    if len(np.unique(y_test_full)) < 2:\n",
    "        continue\n",
    "    \n",
    "    scaler_transfer = StandardScaler()\n",
    "    X_test_scaled = scaler_transfer.fit_transform(X_test_full)\n",
    "    \n",
    "    unique, counts = np.unique(y_test_full, return_counts=True)\n",
    "    minority_count = counts.min()\n",
    "    k_transfer = min(10, minority_count // 3)\n",
    "    \n",
    "    if k_transfer < 3:\n",
    "        continue\n",
    "    \n",
    "    X_train_transfer, X_test_transfer, y_train_transfer, y_test_transfer = train_test_split(\n",
    "        X_test_scaled, y_test_full, test_size=0.7, random_state=SEED, stratify=y_test_full\n",
    "    )\n",
    "    \n",
    "    episode = create_imbalanced_episode(\n",
    "        X_train_transfer, y_train_transfer,\n",
    "        k_transfer, k_transfer * 2, 5\n",
    "    )\n",
    "    \n",
    "    if episode[0] is None:\n",
    "        continue\n",
    "    \n",
    "    support_X, support_y, _, _ = episode\n",
    "    \n",
    "    transfer_model = MetaLearner(input_dim, hidden_dims, embedding_dim, dropout, num_classes).to(device)\n",
    "    transfer_model.load_state_dict(model.state_dict())\n",
    "    \n",
    "    transfer_optimizer = Adam(transfer_model.parameters(), lr=1e-3)\n",
    "    \n",
    "    support_X_tensor = torch.FloatTensor(support_X).to(device)\n",
    "    support_y_tensor = torch.LongTensor(support_y).to(device)\n",
    "    \n",
    "    transfer_model.train()\n",
    "    for epoch in range(50):\n",
    "        transfer_optimizer.zero_grad()\n",
    "        logits = transfer_model.predict(support_X_tensor)\n",
    "        loss = focal_loss(logits, support_y_tensor)\n",
    "        loss.backward()\n",
    "        transfer_optimizer.step()\n",
    "    \n",
    "    transfer_model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = torch.FloatTensor(X_test_transfer).to(device)\n",
    "        test_logits = transfer_model.predict(X_test_tensor)\n",
    "        test_probs = F.softmax(test_logits, dim=1).cpu().numpy()\n",
    "        test_preds = torch.argmax(test_logits, dim=1).cpu().numpy()\n",
    "    \n",
    "    metrics = calculate_metrics(y_test_transfer, test_preds, test_probs)\n",
    "    \n",
    "    transfer_results.append({\n",
    "        'test_source': test_source,\n",
    "        'f1_macro': metrics['f1_macro'],\n",
    "        'balanced_acc': metrics['balanced_acc'],\n",
    "        'auroc': metrics['auroc'],\n",
    "        'mcc': metrics['mcc'],\n",
    "        'train_samples': len(support_y),\n",
    "        'test_samples': len(y_test_transfer)\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{test_source} (Transfer):\")\n",
    "    print(f\"  F1-Macro: {metrics['f1_macro']:.4f}\")\n",
    "    print(f\"  Balanced Acc: {metrics['balanced_acc']:.4f}\")\n",
    "    print(f\"  AUROC: {metrics['auroc']:.4f}\")\n",
    "    \n",
    "    del transfer_model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f5831a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRANSFER LEARNING EVALUATION SUMMARY\n",
      "================================================================================\n",
      "   test_source  f1_macro  balanced_acc    auroc      mcc  train_samples  test_samples\n",
      "  Proxifier_2k  1.000000      1.000000 1.000000 1.000000             30          1400\n",
      "     Apache_2k  0.993041      0.996000 0.999580 0.986179             30          1400\n",
      "  Zookeeper_2k  0.991654      0.995673 0.999904 0.983446             30          1400\n",
      "    Windows_2k  0.982922      0.985784 0.999712 0.966235             30          1400\n",
      "        HPC_2k  0.975496      0.977167 0.998339 0.951483             30          1400\n",
      "        BGL_2k  0.968099      0.975303 0.996444 0.936355             30          1400\n",
      "        Mac_2k  0.967551      0.970344 0.984365 0.935154             30          1400\n",
      "     Hadoop_2k  0.960280      0.967293 0.990465 0.921677             30          1400\n",
      "      Linux_2k  0.939747      0.993628 0.999693 0.886029             30          1400\n",
      "Thunderbird_2k  0.856307      0.921235 0.990099 0.726888             30          1400\n",
      "\n",
      "============================================================\n",
      "TRANSFER AGGREGATE STATISTICS\n",
      "============================================================\n",
      "Sources evaluated: 10\n",
      "Average F1-Macro: 0.9635 ± 0.0417\n",
      "Average Balanced Acc: 0.9782 ± 0.0232\n",
      "Average AUROC: 0.9959 ± 0.0056\n",
      "\n",
      "Transfer results saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\results\\meta_learning\\transfer_results_20251122_045037.csv\n"
     ]
    }
   ],
   "source": [
    "if transfer_results:\n",
    "    df_transfer = pd.DataFrame(transfer_results)\n",
    "    df_transfer = df_transfer.sort_values('f1_macro', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRANSFER LEARNING EVALUATION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(df_transfer.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRANSFER AGGREGATE STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Sources evaluated: {len(transfer_results)}\")\n",
    "    print(f\"Average F1-Macro: {df_transfer['f1_macro'].mean():.4f} ± {df_transfer['f1_macro'].std():.4f}\")\n",
    "    print(f\"Average Balanced Acc: {df_transfer['balanced_acc'].mean():.4f} ± {df_transfer['balanced_acc'].std():.4f}\")\n",
    "    print(f\"Average AUROC: {df_transfer['auroc'].mean():.4f} ± {df_transfer['auroc'].std():.4f}\")\n",
    "    \n",
    "    transfer_file = RESULTS_PATH / f\"transfer_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    df_transfer.to_csv(transfer_file, index=False)\n",
    "    print(f\"\\nTransfer results saved to: {transfer_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08e167a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARATIVE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "        Source  MAML F1  Proto F1  Transfer F1 Best Method\n",
      "     Apache_2k 0.219481  0.699977     0.993041    Transfer\n",
      "Thunderbird_2k 0.097269  0.713395     0.856307    Transfer\n",
      "    Windows_2k 0.302047  0.361068     0.982922    Transfer\n",
      "     Hadoop_2k 0.304979  0.324830     0.960280    Transfer\n",
      "  Zookeeper_2k 0.464143  0.875446     0.991654    Transfer\n",
      "      Linux_2k 0.457766  0.216627     0.939747    Transfer\n",
      "        HPC_2k 0.253060  0.682177     0.975496    Transfer\n",
      "        Mac_2k 0.379984  0.510389     0.967551    Transfer\n",
      "        BGL_2k 0.168943  0.460949     0.968099    Transfer\n",
      "  Proxifier_2k 0.224257  0.415376     1.000000    Transfer\n",
      "\n",
      "============================================================\n",
      "METHOD COMPARISON\n",
      "============================================================\n",
      "MAML Average F1: 0.2872\n",
      "Prototypical Average F1: 0.5260\n",
      "Transfer Average F1: 0.9635\n",
      "\n",
      "Best method frequency:\n",
      "  Transfer: 10 times (100.0%)\n",
      "\n",
      "Comparison saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\results\\meta_learning\\method_comparison_20251122_045037.csv\n",
      "\n",
      "Final model saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\models\\meta_learning\\final_meta_model.pt\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARATIVE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if test_results and prototypical_results and transfer_results:\n",
    "    comparison_data = []\n",
    "    \n",
    "    sources_all = set([r['test_source'] for r in test_results])\n",
    "    sources_proto = set([r['test_source'] for r in prototypical_results])\n",
    "    sources_transfer = set([r['test_source'] for r in transfer_results])\n",
    "    common_sources = sources_all & sources_proto & sources_transfer\n",
    "    \n",
    "    for source in common_sources:\n",
    "        maml_result = next((r for r in test_results if r['test_source'] == source), None)\n",
    "        proto_result = next((r for r in prototypical_results if r['test_source'] == source), None)\n",
    "        transfer_result = next((r for r in transfer_results if r['test_source'] == source), None)\n",
    "        \n",
    "        if maml_result and proto_result and transfer_result:\n",
    "            comparison_data.append({\n",
    "                'Source': source,\n",
    "                'MAML F1': maml_result['f1_macro'],\n",
    "                'Proto F1': proto_result['f1_macro'],\n",
    "                'Transfer F1': transfer_result['f1_macro'],\n",
    "                'Best Method': max([\n",
    "                    ('MAML', maml_result['f1_macro']),\n",
    "                    ('Proto', proto_result['f1_macro']),\n",
    "                    ('Transfer', transfer_result['f1_macro'])\n",
    "                ], key=lambda x: x[1])[0]\n",
    "            })\n",
    "    \n",
    "    if comparison_data:\n",
    "        df_comparison = pd.DataFrame(comparison_data)\n",
    "        print(\"\\n\" + df_comparison.to_string(index=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"METHOD COMPARISON\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"MAML Average F1: {df_comparison['MAML F1'].mean():.4f}\")\n",
    "        print(f\"Prototypical Average F1: {df_comparison['Proto F1'].mean():.4f}\")\n",
    "        print(f\"Transfer Average F1: {df_comparison['Transfer F1'].mean():.4f}\")\n",
    "        \n",
    "        best_counts = df_comparison['Best Method'].value_counts()\n",
    "        print(f\"\\nBest method frequency:\")\n",
    "        for method, count in best_counts.items():\n",
    "            print(f\"  {method}: {count} times ({count/len(df_comparison)*100:.1f}%)\")\n",
    "        \n",
    "        comparison_file = RESULTS_PATH / f\"method_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        df_comparison.to_csv(comparison_file, index=False)\n",
    "        print(f\"\\nComparison saved to: {comparison_file}\")\n",
    "\n",
    "torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'config': {\n",
    "        'input_dim': input_dim,\n",
    "        'hidden_dims': hidden_dims,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'dropout': dropout,\n",
    "        'num_classes': num_classes\n",
    "    },\n",
    "    'meta_config': {\n",
    "        'meta_lr': meta_lr,\n",
    "        'inner_lr': inner_lr,\n",
    "        'inner_steps': inner_steps,\n",
    "        'meta_batch_size': meta_batch_size,\n",
    "        'num_meta_iterations': num_meta_iterations,\n",
    "        'early_stopping_patience': early_stopping_patience,\n",
    "        'curriculum_learning': True\n",
    "    },\n",
    "    'training_info': {\n",
    "        'final_iteration': len(meta_losses),\n",
    "        'best_meta_loss': best_meta_loss,\n",
    "        'curriculum_phases': curriculum_phase + 1\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}, MODELS_PATH / 'final_meta_model.pt')\n",
    "\n",
    "print(f\"\\nFinal model saved to: {MODELS_PATH / 'final_meta_model.pt'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09dcaebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\results\\meta_learning\\meta_learning_visualization.png\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    axes[0, 0].plot(meta_losses)\n",
    "    axes[0, 0].set_title('Meta-Training Loss')\n",
    "    axes[0, 0].set_xlabel('Iteration')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    if test_results:\n",
    "        sources = [r['test_source'] for r in test_results]\n",
    "        f1_scores = [r['f1_macro'] for r in test_results]\n",
    "        axes[0, 1].barh(sources, f1_scores)\n",
    "        axes[0, 1].set_title('F1-Macro by Source (MAML)')\n",
    "        axes[0, 1].set_xlabel('F1-Macro')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    if comparison_data:\n",
    "        methods = ['MAML', 'Proto', 'Transfer']\n",
    "        avg_f1s = [\n",
    "            df_comparison['MAML F1'].mean(),\n",
    "            df_comparison['Proto F1'].mean(),\n",
    "            df_comparison['Transfer F1'].mean()\n",
    "        ]\n",
    "        axes[1, 0].bar(methods, avg_f1s)\n",
    "        axes[1, 0].set_title('Average F1-Macro by Method')\n",
    "        axes[1, 0].set_ylabel('F1-Macro')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    window = 50\n",
    "    if len(meta_losses) > window:\n",
    "        smoothed = np.convolve(meta_losses, np.ones(window)/window, mode='valid')\n",
    "        axes[1, 1].plot(smoothed)\n",
    "        axes[1, 1].set_title(f'Smoothed Meta-Training Loss (window={window})')\n",
    "        axes[1, 1].set_xlabel('Iteration')\n",
    "        axes[1, 1].set_ylabel('Loss')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_PATH / 'meta_learning_visualization.png', dpi=150, bbox_inches='tight')\n",
    "    print(f\"Visualization saved to: {RESULTS_PATH / 'meta_learning_visualization.png'}\")\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"Visualization skipped: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
