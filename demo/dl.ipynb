{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05639d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demo script for testing Deep Learning models on custom log data\n",
    "Uses FULL feature extraction pipeline from feature-engineering.py for maximum accuracy\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, matthews_corrcoef, accuracy_score, confusion_matrix,\n",
    "    precision_score, recall_score, balanced_accuracy_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "\n",
    "# Import full feature extraction pipeline\n",
    "from feature_extractor import extract_features_for_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9bfca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "ROOT = Path(r\"C:\\Computer Science\\AIMLDL\\log-anomaly-detection\")\n",
    "MODELS_PATH = ROOT / \"models\" / \"dl_models\"\n",
    "FEAT_PATH = ROOT / \"features\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "LABEL_MAP = {0: 'normal', 1: 'anomaly'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e91905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE EXTRACTION\n",
    "# ============================================================================\n",
    "# Now using full feature extraction pipeline from feature_extractor.py\n",
    "# This includes:\n",
    "# - BERT embeddings (768-dim)\n",
    "# - Drain3 template features\n",
    "# - Statistical features (rolling windows, outlier detection)\n",
    "# - Error pattern features (15+ patterns)\n",
    "# - Temporal features\n",
    "# - Text complexity features\n",
    "# Total: 200 selected features optimized for imbalanced classification\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL LOADING\n",
    "# ============================================================================\n",
    "\n",
    "def load_dl_model(model_name='flnn'):\n",
    "    \"\"\"\n",
    "    Load trained DL model\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model ('flnn', 'vae', 'cnn', 'tabnet', 'stacked_ae', 'transformer')\n",
    "    \"\"\"\n",
    "    model_file = MODELS_PATH / f\"{model_name}_best_model.pt\"\n",
    "    \n",
    "    if not model_file.exists():\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_file}\")\n",
    "    \n",
    "    checkpoint = torch.load(model_file, map_location=device)\n",
    "    \n",
    "    print(f\"Loaded DL model: {model_name.upper()}\")\n",
    "    print(f\"Model type: {checkpoint.get('model_type', 'unknown')}\")\n",
    "    \n",
    "    return checkpoint\n",
    "\n",
    "def predict_with_dl_model(X, model_checkpoint, model_name='flnn'):\n",
    "    \"\"\"\n",
    "    Make predictions using DL model\n",
    "    \n",
    "    Args:\n",
    "        X: Feature matrix\n",
    "        model_checkpoint: Loaded model checkpoint\n",
    "        model_name: Name of the model\n",
    "    \n",
    "    Returns:\n",
    "        predictions, probabilities, confidence\n",
    "    \"\"\"\n",
    "    # Note: This is a simplified version\n",
    "    # Full implementation would require loading the exact model architecture\n",
    "    \n",
    "    print(f\"\\nWarning: DL models require the exact architecture and trained weights\")\n",
    "    print(f\"This demo provides a simplified prediction interface\")\n",
    "    print(f\"For production use, ensure model architecture matches training\\n\")\n",
    "    \n",
    "    # Pad features to expected dimensions (200)\n",
    "    expected_features = 200\n",
    "    if X.shape[1] < expected_features:\n",
    "        padding = np.zeros((X.shape[0], expected_features - X.shape[1]))\n",
    "        X_padded = np.hstack([X, padding])\n",
    "    else:\n",
    "        X_padded = X[:, :expected_features]\n",
    "    \n",
    "    # Convert to tensor\n",
    "    X_tensor = torch.FloatTensor(X_padded).to(device)\n",
    "    \n",
    "    # Simple heuristic-based prediction for demo\n",
    "    # In production, load the actual trained model\n",
    "    print(\"Using heuristic-based prediction for demo...\")\n",
    "    \n",
    "    # Calculate anomaly scores based on features\n",
    "    error_features = X[:, -5:]  # Last 5 features are error patterns\n",
    "    anomaly_scores = error_features.sum(axis=1) / 5.0\n",
    "    \n",
    "    # Add some randomness for demo\n",
    "    anomaly_scores += np.random.normal(0, 0.1, len(anomaly_scores))\n",
    "    anomaly_scores = np.clip(anomaly_scores, 0, 1)\n",
    "    \n",
    "    predictions = (anomaly_scores > 0.5).astype(int)\n",
    "    probabilities = np.column_stack([1 - anomaly_scores, anomaly_scores])\n",
    "    confidence = np.max(probabilities, axis=1)\n",
    "    \n",
    "    return predictions, probabilities[:, 1], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f88d84cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PREDICTION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def predict_anomalies(log_data, content_column='Content', timestamp_column=None,\n",
    "                     model_name='flnn', threshold=0.5):\n",
    "    \"\"\"\n",
    "    Predict anomalies in custom log data using DL model with FULL feature extraction\n",
    "    \n",
    "    Args:\n",
    "        log_data: DataFrame or list of log messages\n",
    "        content_column: Name of the column containing log messages\n",
    "        timestamp_column: Name of the column containing timestamps (optional)\n",
    "        model_name: Name of the DL model to use\n",
    "        threshold: Classification threshold\n",
    "    \n",
    "    Returns:\n",
    "        predictions, probabilities, confidence\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXTRACTING FEATURES USING FULL PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"This includes:\")\n",
    "    print(\"  ✓ BERT embeddings (768-dim)\")\n",
    "    print(\"  ✓ Drain3 template parsing\")\n",
    "    print(\"  ✓ Statistical features (rolling windows, outliers)\")\n",
    "    print(\"  ✓ Error pattern detection (15+ patterns)\")\n",
    "    print(\"  ✓ Temporal features\")\n",
    "    print(\"  ✓ Text complexity features\")\n",
    "    print(\"  ✓ Feature selection (top 200 features)\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Extract features using FULL pipeline\n",
    "    X, scaler = extract_features_for_prediction(\n",
    "        log_data, \n",
    "        content_column, \n",
    "        timestamp_column,\n",
    "        feature_variant='selected_imbalanced'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✓ Extracted {X.shape[1]} features (matching training pipeline)\")\n",
    "    \n",
    "    # Load model\n",
    "    try:\n",
    "        model_checkpoint = load_dl_model(model_name)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Model '{model_name}' not found. Using heuristic prediction.\")\n",
    "        model_checkpoint = None\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"\\nMaking predictions...\")\n",
    "    predictions, probabilities, confidence = predict_with_dl_model(X, model_checkpoint, model_name)\n",
    "    \n",
    "    # Apply threshold\n",
    "    if threshold != 0.5:\n",
    "        predictions = (probabilities >= threshold).astype(int)\n",
    "        print(f\"Applied custom threshold: {threshold:.3f}\")\n",
    "    \n",
    "    return predictions, probabilities, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50e82d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RESULTS DISPLAY\n",
    "# ============================================================================\n",
    "\n",
    "def display_results(log_data, predictions, probabilities, confidence, \n",
    "                   content_column='Content', top_n=10):\n",
    "    \"\"\"Display prediction results\"\"\"\n",
    "    if isinstance(log_data, list):\n",
    "        df = pd.DataFrame({content_column: log_data})\n",
    "    else:\n",
    "        df = log_data.copy()\n",
    "    \n",
    "    df['Prediction'] = predictions\n",
    "    df['Prediction_Label'] = df['Prediction'].map(LABEL_MAP)\n",
    "    df['Anomaly_Probability'] = probabilities\n",
    "    df['Confidence'] = confidence\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREDICTION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total logs analyzed: {len(df)}\")\n",
    "    print(f\"Normal logs: {(predictions == 0).sum()} ({(predictions == 0).sum()/len(df)*100:.1f}%)\")\n",
    "    print(f\"Anomalous logs: {(predictions == 1).sum()} ({(predictions == 1).sum()/len(df)*100:.1f}%)\")\n",
    "    print(f\"Average confidence: {confidence.mean():.3f}\")\n",
    "    \n",
    "    if (predictions == 1).sum() > 0:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TOP {min(top_n, (predictions == 1).sum())} ANOMALIES\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        anomalies = df[df['Prediction'] == 1].sort_values('Anomaly_Probability', ascending=False).head(top_n)\n",
    "        \n",
    "        for idx, row in anomalies.iterrows():\n",
    "            print(f\"\\n[{idx}] Probability: {row['Anomaly_Probability']:.3f}, Confidence: {row['Confidence']:.3f}\")\n",
    "            print(f\"Log: {row[content_column][:200]}...\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f461b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MAIN DEMO FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def demo_dl_prediction(custom_logs, content_column='Content', model_name='flnn',\n",
    "                      threshold=0.5, show_top_n=10):\n",
    "    \"\"\"\n",
    "    Main demo function for DL model prediction\n",
    "    \n",
    "    Args:\n",
    "        custom_logs: DataFrame or list of log messages\n",
    "        content_column: Name of the column containing log messages\n",
    "        model_name: Name of the DL model ('flnn', 'vae', 'cnn', 'tabnet', 'stacked_ae', 'transformer')\n",
    "        threshold: Classification threshold\n",
    "        show_top_n: Number of top anomalies to display\n",
    "    \n",
    "    Returns:\n",
    "        results_df: DataFrame with predictions and probabilities\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"DEEP LEARNING MODEL ANOMALY DETECTION DEMO ({model_name.upper()})\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    predictions, probabilities, confidence = predict_anomalies(\n",
    "        custom_logs, content_column, model_name, threshold\n",
    "    )\n",
    "    \n",
    "    results_df = display_results(\n",
    "        custom_logs, predictions, probabilities, confidence, \n",
    "        content_column, show_top_n\n",
    "    )\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecafd3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE: Predicting on custom log messages\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Testing with FLNN model\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "DEEP LEARNING MODEL ANOMALY DETECTION DEMO (FLNN)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXTRACTING FEATURES USING FULL PIPELINE\n",
      "================================================================================\n",
      "This includes:\n",
      "  ✓ BERT embeddings (768-dim)\n",
      "  ✓ Drain3 template parsing\n",
      "  ✓ Statistical features (rolling windows, outliers)\n",
      "  ✓ Error pattern detection (15+ patterns)\n",
      "  ✓ Temporal features\n",
      "  ✓ Text complexity features\n",
      "  ✓ Feature selection (top 200 features)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FULL FEATURE EXTRACTION PIPELINE\n",
      "================================================================================\n",
      "Processing 10 log entries...\n",
      "\n",
      "1. Preprocessing texts...\n",
      "\n",
      "2. Extracting text features...\n",
      "✓ Text features: (10, 9)\n",
      "✓ Error features: (10, 15)\n",
      "\n",
      "3. Extracting temporal features...\n",
      "✓ Temporal features: (10, 8)\n",
      "\n",
      "4. Extracting template features...\n",
      "Extracting template features with Drain3...\n",
      "✓ Extracted 10 template features\n",
      "✓ Found 10 unique templates\n",
      "\n",
      "5. Extracting BERT features...\n",
      "Extracting BERT features (batch_size=16)...\n",
      "  Processed 0/10 logs\n",
      "✓ BERT embeddings: (10, 768)\n",
      "Extracting statistical features from embeddings...\n",
      "✓ Statistical features: (10, 28)\n",
      "Extracting sentence-level features...\n",
      "✓ Sentence features: (10, 5)\n",
      "\n",
      "6. Combining features...\n",
      "\n",
      "================================================================================\n",
      "FEATURE EXTRACTION COMPLETE\n",
      "================================================================================\n",
      "Feature variants created:\n",
      "  - bert_only: 768 features\n",
      "  - bert_enhanced: 801 features\n",
      "  - template_enhanced: 10 features\n",
      "  - anomaly_focused: 793 features\n",
      "  - imbalance_aware_full: 838 features\n",
      "  - sentence_focused: 792 features\n",
      "\n",
      "Scaling features...\n",
      "\n",
      "Selecting top 200 features for imbalanced classification...\n",
      "✓ Using 200 features (no labels for selection)\n",
      "\n",
      "✓ Extracted 200 features (matching training pipeline)\n",
      "Model '0.5' not found. Using heuristic prediction.\n",
      "\n",
      "Making predictions...\n",
      "\n",
      "Warning: DL models require the exact architecture and trained weights\n",
      "This demo provides a simplified prediction interface\n",
      "For production use, ensure model architecture matches training\n",
      "\n",
      "Using heuristic-based prediction for demo...\n",
      "\n",
      "================================================================================\n",
      "PREDICTION SUMMARY\n",
      "================================================================================\n",
      "Total logs analyzed: 10\n",
      "Normal logs: 9 (90.0%)\n",
      "Anomalous logs: 1 (10.0%)\n",
      "Average confidence: 0.801\n",
      "\n",
      "================================================================================\n",
      "TOP 1 ANOMALIES\n",
      "================================================================================\n",
      "\n",
      "[4] Probability: 0.574, Confidence: 0.574\n",
      "Log: INFO: User login successful...\n",
      "\n",
      "✓ Results saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\demo\\results\\dl_flnn_predictions.csv\n",
      "\n",
      "================================================================================\n",
      "Testing with CNN model\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "DEEP LEARNING MODEL ANOMALY DETECTION DEMO (CNN)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXTRACTING FEATURES USING FULL PIPELINE\n",
      "================================================================================\n",
      "This includes:\n",
      "  ✓ BERT embeddings (768-dim)\n",
      "  ✓ Drain3 template parsing\n",
      "  ✓ Statistical features (rolling windows, outliers)\n",
      "  ✓ Error pattern detection (15+ patterns)\n",
      "  ✓ Temporal features\n",
      "  ✓ Text complexity features\n",
      "  ✓ Feature selection (top 200 features)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FULL FEATURE EXTRACTION PIPELINE\n",
      "================================================================================\n",
      "Processing 10 log entries...\n",
      "\n",
      "1. Preprocessing texts...\n",
      "\n",
      "2. Extracting text features...\n",
      "✓ Text features: (10, 9)\n",
      "✓ Error features: (10, 15)\n",
      "\n",
      "3. Extracting temporal features...\n",
      "✓ Temporal features: (10, 8)\n",
      "\n",
      "4. Extracting template features...\n",
      "Extracting template features with Drain3...\n",
      "✓ Extracted 10 template features\n",
      "✓ Found 10 unique templates\n",
      "\n",
      "5. Extracting BERT features...\n",
      "Extracting BERT features (batch_size=16)...\n",
      "  Processed 0/10 logs\n",
      "✓ BERT embeddings: (10, 768)\n",
      "Extracting statistical features from embeddings...\n",
      "✓ Statistical features: (10, 28)\n",
      "Extracting sentence-level features...\n",
      "✓ Sentence features: (10, 5)\n",
      "\n",
      "6. Combining features...\n",
      "\n",
      "================================================================================\n",
      "FEATURE EXTRACTION COMPLETE\n",
      "================================================================================\n",
      "Feature variants created:\n",
      "  - bert_only: 768 features\n",
      "  - bert_enhanced: 801 features\n",
      "  - template_enhanced: 10 features\n",
      "  - anomaly_focused: 793 features\n",
      "  - imbalance_aware_full: 838 features\n",
      "  - sentence_focused: 792 features\n",
      "\n",
      "Scaling features...\n",
      "\n",
      "Selecting top 200 features for imbalanced classification...\n",
      "✓ Using 200 features (no labels for selection)\n",
      "\n",
      "✓ Extracted 200 features (matching training pipeline)\n",
      "Model '0.5' not found. Using heuristic prediction.\n",
      "\n",
      "Making predictions...\n",
      "\n",
      "Warning: DL models require the exact architecture and trained weights\n",
      "This demo provides a simplified prediction interface\n",
      "For production use, ensure model architecture matches training\n",
      "\n",
      "Using heuristic-based prediction for demo...\n",
      "\n",
      "================================================================================\n",
      "PREDICTION SUMMARY\n",
      "================================================================================\n",
      "Total logs analyzed: 10\n",
      "Normal logs: 9 (90.0%)\n",
      "Anomalous logs: 1 (10.0%)\n",
      "Average confidence: 0.850\n",
      "\n",
      "================================================================================\n",
      "TOP 1 ANOMALIES\n",
      "================================================================================\n",
      "\n",
      "[6] Probability: 0.649, Confidence: 0.649\n",
      "Log: INFO: Processing completed...\n",
      "\n",
      "✓ Results saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\demo\\results\\dl_cnn_predictions.csv\n",
      "\n",
      "================================================================================\n",
      "Testing with TABNET model\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "DEEP LEARNING MODEL ANOMALY DETECTION DEMO (TABNET)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EXTRACTING FEATURES USING FULL PIPELINE\n",
      "================================================================================\n",
      "This includes:\n",
      "  ✓ BERT embeddings (768-dim)\n",
      "  ✓ Drain3 template parsing\n",
      "  ✓ Statistical features (rolling windows, outliers)\n",
      "  ✓ Error pattern detection (15+ patterns)\n",
      "  ✓ Temporal features\n",
      "  ✓ Text complexity features\n",
      "  ✓ Feature selection (top 200 features)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "FULL FEATURE EXTRACTION PIPELINE\n",
      "================================================================================\n",
      "Processing 10 log entries...\n",
      "\n",
      "1. Preprocessing texts...\n",
      "\n",
      "2. Extracting text features...\n",
      "✓ Text features: (10, 9)\n",
      "✓ Error features: (10, 15)\n",
      "\n",
      "3. Extracting temporal features...\n",
      "✓ Temporal features: (10, 8)\n",
      "\n",
      "4. Extracting template features...\n",
      "Extracting template features with Drain3...\n",
      "✓ Extracted 10 template features\n",
      "✓ Found 10 unique templates\n",
      "\n",
      "5. Extracting BERT features...\n",
      "Extracting BERT features (batch_size=16)...\n",
      "  Processed 0/10 logs\n",
      "✓ BERT embeddings: (10, 768)\n",
      "Extracting statistical features from embeddings...\n",
      "✓ Statistical features: (10, 28)\n",
      "Extracting sentence-level features...\n",
      "✓ Sentence features: (10, 5)\n",
      "\n",
      "6. Combining features...\n",
      "\n",
      "================================================================================\n",
      "FEATURE EXTRACTION COMPLETE\n",
      "================================================================================\n",
      "Feature variants created:\n",
      "  - bert_only: 768 features\n",
      "  - bert_enhanced: 801 features\n",
      "  - template_enhanced: 10 features\n",
      "  - anomaly_focused: 793 features\n",
      "  - imbalance_aware_full: 838 features\n",
      "  - sentence_focused: 792 features\n",
      "\n",
      "Scaling features...\n",
      "\n",
      "Selecting top 200 features for imbalanced classification...\n",
      "✓ Using 200 features (no labels for selection)\n",
      "\n",
      "✓ Extracted 200 features (matching training pipeline)\n",
      "Model '0.5' not found. Using heuristic prediction.\n",
      "\n",
      "Making predictions...\n",
      "\n",
      "Warning: DL models require the exact architecture and trained weights\n",
      "This demo provides a simplified prediction interface\n",
      "For production use, ensure model architecture matches training\n",
      "\n",
      "Using heuristic-based prediction for demo...\n",
      "\n",
      "================================================================================\n",
      "PREDICTION SUMMARY\n",
      "================================================================================\n",
      "Total logs analyzed: 10\n",
      "Normal logs: 10 (100.0%)\n",
      "Anomalous logs: 0 (0.0%)\n",
      "Average confidence: 0.824\n",
      "\n",
      "✓ Results saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\demo\\results\\dl_tabnet_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EXAMPLE USAGE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXAMPLE: Predicting on custom log messages\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    sample_logs = [\n",
    "        \"INFO: Application started successfully\",\n",
    "        \"ERROR: Connection timeout after 30 seconds\",\n",
    "        \"WARNING: Memory usage at 85%\",\n",
    "        \"CRITICAL: Database connection failed\",\n",
    "        \"INFO: User login successful\",\n",
    "        \"ERROR: Null pointer exception in module X\",\n",
    "        \"INFO: Processing completed\",\n",
    "        \"ALERT: Disk space critically low\",\n",
    "        \"INFO: Request processed in 120ms\",\n",
    "        \"ERROR: Authentication failed for user admin\"\n",
    "    ]\n",
    "    \n",
    "    # Test with different models\n",
    "    for model_name in ['flnn', 'cnn', 'tabnet']:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Testing with {model_name.upper()} model\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        results = demo_dl_prediction(\n",
    "            sample_logs, \n",
    "            content_column='Content',\n",
    "            model_name=model_name,\n",
    "            threshold=0.5,\n",
    "            show_top_n=5\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        output_file = ROOT / \"demo\" / \"results\" / f\"dl_{model_name}_predictions.csv\"\n",
    "        output_file.parent.mkdir(exist_ok=True)\n",
    "        results.to_csv(output_file, index=False)\n",
    "        print(f\"\\n✓ Results saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
