{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17674acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model on cuda...\n",
      "✓ BERT model loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, matthews_corrcoef, accuracy_score, confusion_matrix,\n",
    "    precision_score, recall_score, balanced_accuracy_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "\n",
    "from feature_extractor import extract_features_for_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e2e6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path(r\"C:\\Computer Science\\AIMLDL\\log-anomaly-detection\")\n",
    "MODELS_PATH = ROOT / \"models\" / \"federated_contrastive\"\n",
    "RESULTS_PATH = ROOT / \"demo\" / \"results\" / \"federated-contrastive\"\n",
    "RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "LABEL_MAP = {0: 'normal', 1: 'anomaly'}\n",
    "\n",
    "# Model configuration (must match training)\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "MAX_LENGTH = 128\n",
    "PROJECTION_DIM = 128\n",
    "HIDDEN_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5446eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateAwareAttention(nn.Module):\n",
    "    \"\"\"Template-aware attention mechanism\"\"\"\n",
    "    def __init__(self, hidden_dim, num_templates):\n",
    "        super().__init__()\n",
    "        self.template_embeddings = nn.Embedding(num_templates + 1, hidden_dim)\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=8, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "    \n",
    "    def forward(self, x, template_ids):\n",
    "        template_emb = self.template_embeddings(template_ids).unsqueeze(1)\n",
    "        attn_out, _ = self.attention(x.unsqueeze(1), template_emb, template_emb)\n",
    "        return self.norm(x + attn_out.squeeze(1))\n",
    "\n",
    "class FedLogCLModel(nn.Module):\n",
    "    \"\"\"Federated Contrastive Learning Model\"\"\"\n",
    "    def __init__(self, model_name, projection_dim, hidden_dim, num_templates, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.encoder_dim = self.encoder.config.hidden_size\n",
    "        \n",
    "        # Projection head for contrastive learning\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(self.encoder_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim, projection_dim)\n",
    "        )\n",
    "        \n",
    "        # Template-aware attention\n",
    "        self.template_attention = TemplateAwareAttention(projection_dim, num_templates)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(projection_dim, hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim // 4, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, template_ids=None):\n",
    "        # Encode\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.pooler_output\n",
    "        \n",
    "        # Project\n",
    "        projected = self.projection_head(pooled)\n",
    "        \n",
    "        # Template attention (optional)\n",
    "        if template_ids is not None:\n",
    "            projected = self.template_attention(projected, template_ids)\n",
    "        \n",
    "        # Classify\n",
    "        logits = self.classifier(projected)\n",
    "        \n",
    "        return projected, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93adcb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fedlogcl_model():\n",
    "    \"\"\"Load trained FedLogCL model\"\"\"\n",
    "    # Try to find the latest model file\n",
    "    model_files = list(MODELS_PATH.glob(\"split_*_round_*.pt\"))\n",
    "    \n",
    "    if not model_files:\n",
    "        raise FileNotFoundError(f\"No FedLogCL models found in {MODELS_PATH}\")\n",
    "    \n",
    "    # Sort by round number and get the latest\n",
    "    model_files.sort(key=lambda x: int(x.stem.split('_')[-1]))\n",
    "    model_file = model_files[-1]\n",
    "    \n",
    "    print(f\"Loading FedLogCL model from: {model_file}\")\n",
    "    checkpoint = torch.load(model_file, map_location=device)\n",
    "    \n",
    "    # Get model configuration from checkpoint\n",
    "    num_templates = checkpoint.get('num_templates', 1000)\n",
    "    \n",
    "    # Create model\n",
    "    model = FedLogCLModel(\n",
    "        BERT_MODEL, PROJECTION_DIM, HIDDEN_DIM, \n",
    "        num_templates, num_classes=2\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load state dict\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "    elif 'model' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint, strict=False)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"✓ Loaded FedLogCL model\")\n",
    "    print(f\"  Templates: {num_templates}\")\n",
    "    if 'round' in checkpoint:\n",
    "        print(f\"  Training round: {checkpoint['round']}\")\n",
    "    if 'test_f1' in checkpoint:\n",
    "        print(f\"  Test F1: {checkpoint['test_f1']:.4f}\")\n",
    "    \n",
    "    return model, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3945a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_fedlogcl(log_data, content_column='Content', timestamp_column=None):\n",
    "    \"\"\"\n",
    "    Make predictions using FedLogCL model with FULL feature extraction\n",
    "    \n",
    "    Args:\n",
    "        log_data: DataFrame or list of log messages\n",
    "        content_column: Name of the column containing log messages\n",
    "        timestamp_column: Name of the column containing timestamps (optional)\n",
    "    \n",
    "    Returns:\n",
    "        predictions, probabilities, confidence, embeddings\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FEDERATED CONTRASTIVE LEARNING (FedLogCL) ANOMALY DETECTION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Extract features using FULL pipeline\n",
    "    print(\"\\nExtracting features using full pipeline...\")\n",
    "    X, scaler = extract_features_for_prediction(\n",
    "        log_data, \n",
    "        content_column, \n",
    "        timestamp_column,\n",
    "        feature_variant='selected_imbalanced'\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Extracted {X.shape[1]} features\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"\\nLoading FedLogCL model...\")\n",
    "    model, checkpoint = load_fedlogcl_model()\n",
    "    \n",
    "    # For FedLogCL, we use the features to create pseudo-embeddings\n",
    "    # In a real scenario, you'd tokenize and use BERT, but for demo we use extracted features\n",
    "    print(\"\\nMaking predictions...\")\n",
    "    \n",
    "    # Convert features to tensor\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "    \n",
    "    # Create a simple projection from features to BERT-like embeddings\n",
    "    # This is a workaround since we're using extracted features instead of raw text\n",
    "    with torch.no_grad():\n",
    "        # Use a simple linear projection to match BERT embedding size\n",
    "        if not hasattr(model, 'feature_projection'):\n",
    "            model.feature_projection = nn.Linear(X.shape[1], model.encoder_dim).to(device)\n",
    "        \n",
    "        # Project features to BERT embedding space\n",
    "        pseudo_embeddings = model.feature_projection(X_tensor)\n",
    "        \n",
    "        # Pass through projection head\n",
    "        projected = model.projection_head(pseudo_embeddings)\n",
    "        \n",
    "        # Classify\n",
    "        logits = model.classifier(projected)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        embeddings = projected.cpu().numpy()\n",
    "        all_preds = preds.cpu().numpy()\n",
    "        all_probs = probs.cpu().numpy()\n",
    "    \n",
    "    anomaly_probs = all_probs[:, 1]\n",
    "    confidence = np.max(all_probs, axis=1)\n",
    "    \n",
    "    return all_preds, anomaly_probs, confidence, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b01208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(log_data, predictions, probabilities, confidence, \n",
    "                   content_column='Content', top_n=10):\n",
    "    \"\"\"Display prediction results\"\"\"\n",
    "    if isinstance(log_data, list):\n",
    "        df = pd.DataFrame({content_column: log_data})\n",
    "    else:\n",
    "        df = log_data.copy()\n",
    "    \n",
    "    df['Prediction'] = predictions\n",
    "    df['Prediction_Label'] = df['Prediction'].map(LABEL_MAP)\n",
    "    df['Anomaly_Probability'] = probabilities\n",
    "    df['Confidence'] = confidence\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREDICTION SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total logs analyzed: {len(df)}\")\n",
    "    print(f\"Normal logs: {(predictions == 0).sum()} ({(predictions == 0).sum()/len(df)*100:.1f}%)\")\n",
    "    print(f\"Anomalous logs: {(predictions == 1).sum()} ({(predictions == 1).sum()/len(df)*100:.1f}%)\")\n",
    "    print(f\"Average confidence: {confidence.mean():.3f}\")\n",
    "    \n",
    "    if (predictions == 1).sum() > 0:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TOP {min(top_n, (predictions == 1).sum())} ANOMALIES\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        anomalies = df[df['Prediction'] == 1].sort_values('Anomaly_Probability', ascending=False).head(top_n)\n",
    "        \n",
    "        for idx, row in anomalies.iterrows():\n",
    "            print(f\"\\n[{idx}] Probability: {row['Anomaly_Probability']:.3f}, Confidence: {row['Confidence']:.3f}\")\n",
    "            print(f\"Log: {row[content_column][:200]}...\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f408603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_fedlogcl_prediction(log_data, content_column='Content', timestamp_column=None, show_top_n=10):\n",
    "    \"\"\"\n",
    "    Main demo function for FedLogCL prediction\n",
    "    \n",
    "    Args:\n",
    "        log_data: DataFrame or list of log messages\n",
    "        content_column: Name of the column containing log messages\n",
    "        timestamp_column: Name of the column containing timestamps (optional)\n",
    "        show_top_n: Number of top anomalies to display\n",
    "    \n",
    "    Returns:\n",
    "        results_df: DataFrame with predictions and probabilities\n",
    "        embeddings: Contrastive embeddings\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    predictions, probabilities, confidence, embeddings = predict_with_fedlogcl(\n",
    "        log_data, content_column, timestamp_column\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    results_df = display_results(\n",
    "        log_data, predictions, probabilities, confidence, \n",
    "        content_column, show_top_n\n",
    "    )\n",
    "    \n",
    "    return results_df, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "572f84b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE: Predicting on custom log messages with FedLogCL\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "FEDERATED CONTRASTIVE LEARNING (FedLogCL) ANOMALY DETECTION\n",
      "================================================================================\n",
      "\n",
      "Extracting features using full pipeline...\n",
      "\n",
      "================================================================================\n",
      "FULL FEATURE EXTRACTION PIPELINE\n",
      "================================================================================\n",
      "Processing 15 log entries...\n",
      "\n",
      "1. Preprocessing texts...\n",
      "\n",
      "2. Extracting text features...\n",
      "✓ Text features: (15, 9)\n",
      "✓ Error features: (15, 15)\n",
      "\n",
      "3. Extracting temporal features...\n",
      "✓ Temporal features: (15, 8)\n",
      "\n",
      "4. Extracting template features...\n",
      "Extracting template features with Drain3...\n",
      "✓ Extracted 10 template features\n",
      "✓ Found 15 unique templates\n",
      "\n",
      "5. Extracting BERT features...\n",
      "Extracting BERT features (batch_size=16)...\n",
      "  Processed 0/15 logs\n",
      "✓ BERT embeddings: (15, 768)\n",
      "Extracting statistical features from embeddings...\n",
      "✓ Statistical features: (15, 28)\n",
      "Extracting sentence-level features...\n",
      "✓ Sentence features: (15, 5)\n",
      "\n",
      "6. Combining features...\n",
      "\n",
      "================================================================================\n",
      "FEATURE EXTRACTION COMPLETE\n",
      "================================================================================\n",
      "Feature variants created:\n",
      "  - bert_only: 768 features\n",
      "  - bert_enhanced: 801 features\n",
      "  - template_enhanced: 10 features\n",
      "  - anomaly_focused: 793 features\n",
      "  - imbalance_aware_full: 838 features\n",
      "  - sentence_focused: 792 features\n",
      "\n",
      "Scaling features...\n",
      "\n",
      "Selecting top 200 features for imbalanced classification...\n",
      "✓ Using 200 features (no labels for selection)\n",
      "✓ Extracted 200 features\n",
      "\n",
      "Loading FedLogCL model...\n",
      "Loading FedLogCL model from: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\models\\federated_contrastive\\split_0_round_3.pt\n",
      "✓ Loaded FedLogCL model\n",
      "  Templates: 1000\n",
      "  Training round: 3\n",
      "  Test F1: 0.4673\n",
      "\n",
      "Making predictions...\n",
      "\n",
      "================================================================================\n",
      "PREDICTION SUMMARY\n",
      "================================================================================\n",
      "Total logs analyzed: 15\n",
      "Normal logs: 15 (100.0%)\n",
      "Anomalous logs: 0 (0.0%)\n",
      "Average confidence: 0.531\n",
      "\n",
      "✓ Results saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\demo\\results\\federated-contrastive\\fedlogcl_predictions.csv\n",
      "✓ Embeddings saved to: C:\\Computer Science\\AIMLDL\\log-anomaly-detection\\demo\\results\\federated-contrastive\\fedlogcl_embeddings.npy\n",
      "\n",
      "Embedding statistics:\n",
      "  Shape: (15, 128)\n",
      "  Mean: 0.0095\n",
      "  Std: 0.1404\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXAMPLE: Predicting on custom log messages with FedLogCL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    sample_logs = [\n",
    "        \"INFO: Application started successfully at port 8080\",\n",
    "        \"ERROR: Connection timeout after 30 seconds to database server\",\n",
    "        \"WARNING: Memory usage at 85% threshold exceeded\",\n",
    "        \"CRITICAL: Database connection failed - max retries reached\",\n",
    "        \"INFO: User authentication successful for user john.doe\",\n",
    "        \"ERROR: Null pointer exception in module UserService.processRequest\",\n",
    "        \"INFO: Data processing completed in 2.5 seconds\",\n",
    "        \"ALERT: Disk space critically low - only 5% remaining\",\n",
    "        \"INFO: HTTP request processed successfully in 120ms\",\n",
    "        \"ERROR: Authentication failed for user admin - invalid credentials\",\n",
    "        \"WARNING: High CPU usage detected - 95% utilization\",\n",
    "        \"INFO: Scheduled backup completed successfully\",\n",
    "        \"CRITICAL: Out of memory error in worker thread\",\n",
    "        \"ERROR: Failed to parse configuration file - invalid JSON\",\n",
    "        \"INFO: Service health check passed\"\n",
    "    ]\n",
    "    \n",
    "    results, embeddings = demo_fedlogcl_prediction(\n",
    "        sample_logs, \n",
    "        content_column='Content',\n",
    "        show_top_n=5\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    output_file = RESULTS_PATH / \"fedlogcl_predictions.csv\"\n",
    "    results.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✓ Results saved to: {output_file}\")\n",
    "    \n",
    "    # Save embeddings\n",
    "    embeddings_file = RESULTS_PATH / \"fedlogcl_embeddings.npy\"\n",
    "    np.save(embeddings_file, embeddings)\n",
    "    print(f\"✓ Embeddings saved to: {embeddings_file}\")\n",
    "    \n",
    "    print(f\"\\nEmbedding statistics:\")\n",
    "    print(f\"  Shape: {embeddings.shape}\")\n",
    "    print(f\"  Mean: {embeddings.mean():.4f}\")\n",
    "    print(f\"  Std: {embeddings.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f4b70e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Prediction_Label</th>\n",
       "      <th>Anomaly_Probability</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFO: Application started successfully at port...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.476469</td>\n",
       "      <td>0.523531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ERROR: Connection timeout after 30 seconds to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.462726</td>\n",
       "      <td>0.537274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WARNING: Memory usage at 85% threshold exceeded</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.473793</td>\n",
       "      <td>0.526207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CRITICAL: Database connection failed - max ret...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.470870</td>\n",
       "      <td>0.529130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFO: User authentication successful for user ...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.471968</td>\n",
       "      <td>0.528032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ERROR: Null pointer exception in module UserSe...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.463803</td>\n",
       "      <td>0.536197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFO: Data processing completed in 2.5 seconds</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.465281</td>\n",
       "      <td>0.534719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ALERT: Disk space critically low - only 5% rem...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.472367</td>\n",
       "      <td>0.527632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INFO: HTTP request processed successfully in 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.466476</td>\n",
       "      <td>0.533524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ERROR: Authentication failed for user admin - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.472155</td>\n",
       "      <td>0.527845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WARNING: High CPU usage detected - 95% utiliza...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.473395</td>\n",
       "      <td>0.526605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>INFO: Scheduled backup completed successfully</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.466191</td>\n",
       "      <td>0.533809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CRITICAL: Out of memory error in worker thread</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.463861</td>\n",
       "      <td>0.536139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ERROR: Failed to parse configuration file - in...</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.462446</td>\n",
       "      <td>0.537554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>INFO: Service health check passed</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.470473</td>\n",
       "      <td>0.529527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Content  Prediction  \\\n",
       "0   INFO: Application started successfully at port...           0   \n",
       "1   ERROR: Connection timeout after 30 seconds to ...           0   \n",
       "2     WARNING: Memory usage at 85% threshold exceeded           0   \n",
       "3   CRITICAL: Database connection failed - max ret...           0   \n",
       "4   INFO: User authentication successful for user ...           0   \n",
       "5   ERROR: Null pointer exception in module UserSe...           0   \n",
       "6      INFO: Data processing completed in 2.5 seconds           0   \n",
       "7   ALERT: Disk space critically low - only 5% rem...           0   \n",
       "8   INFO: HTTP request processed successfully in 1...           0   \n",
       "9   ERROR: Authentication failed for user admin - ...           0   \n",
       "10  WARNING: High CPU usage detected - 95% utiliza...           0   \n",
       "11      INFO: Scheduled backup completed successfully           0   \n",
       "12     CRITICAL: Out of memory error in worker thread           0   \n",
       "13  ERROR: Failed to parse configuration file - in...           0   \n",
       "14                  INFO: Service health check passed           0   \n",
       "\n",
       "   Prediction_Label  Anomaly_Probability  Confidence  \n",
       "0            normal             0.476469    0.523531  \n",
       "1            normal             0.462726    0.537274  \n",
       "2            normal             0.473793    0.526207  \n",
       "3            normal             0.470870    0.529130  \n",
       "4            normal             0.471968    0.528032  \n",
       "5            normal             0.463803    0.536197  \n",
       "6            normal             0.465281    0.534719  \n",
       "7            normal             0.472367    0.527632  \n",
       "8            normal             0.466476    0.533524  \n",
       "9            normal             0.472155    0.527845  \n",
       "10           normal             0.473395    0.526605  \n",
       "11           normal             0.466191    0.533809  \n",
       "12           normal             0.463861    0.536139  \n",
       "13           normal             0.462446    0.537554  \n",
       "14           normal             0.470473    0.529527  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
