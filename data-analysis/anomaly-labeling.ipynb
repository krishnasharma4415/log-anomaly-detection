{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7b2ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from rapidfuzz import fuzz, process\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37ff199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path(r\"C:\\Computer Science\\AIMLDL\\log-anomaly-detection\")\n",
    "DATA_PATH = PROJECT_ROOT / \"dataset\" / \"structured_data\"\n",
    "OUTPUT_PATH = PROJECT_ROOT / \"dataset\" / \"labeled_data\"\n",
    "OUTPUT_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "LOG_SOURCES = [\n",
    "    'Android_2k', 'Apache_2k', 'BGL_2k', 'Hadoop_2k', 'HDFS_2k',\n",
    "    'HealthApp_2k', 'HPC_2k', 'Linux_2k', 'Mac_2k', 'OpenSSH_2k',\n",
    "    'OpenStack_2k', 'Proxifier_2k', 'Spark_2k', 'Thunderbird_2k',\n",
    "    'Windows_2k', 'Zookeeper_2k'\n",
    "]\n",
    "\n",
    "LABELS = {\n",
    "    0: \"normal\",\n",
    "    1: \"security_anomaly\",\n",
    "    2: \"system_failure\",\n",
    "    3: \"performance_issue\",\n",
    "    4: \"network_anomaly\",\n",
    "    5: \"config_error\",\n",
    "    6: \"hardware_issue\",\n",
    "    7: \"unknown_anomaly\"\n",
    "}\n",
    "\n",
    "RAW_PATTERNS = {\n",
    "    'security': ['authentication failure', 'invalid user', 'break-in attempt',\n",
    "                 'failed password', 'unauthorized', 'access denied', 'login failed',\n",
    "                 'permission denied', 'security violation', 'intrusion'],\n",
    "    'system': ['error', 'critical', 'fatal', 'exception', 'crash', 'abort',\n",
    "               'segmentation fault', 'core dump', 'kernel panic', 'died'],\n",
    "    'performance': ['timeout', 'slow', 'overload', 'resource exhausted',\n",
    "                    'quota exceeded', 'memory pressure', 'cpu spike', 'bottleneck',\n",
    "                    'high latency', 'response time'],\n",
    "    'network': ['connection refused', 'host unreachable', 'network unreachable',\n",
    "                'connection timeout', 'socket error', 'dns error', 'connection lost',\n",
    "                'network down', 'packet loss'],\n",
    "    'config': ['configuration error', 'config invalid', 'parameter error',\n",
    "               'setting invalid', 'option unknown', 'syntax error', 'parse error',\n",
    "               'invalid configuration', 'config mismatch'],\n",
    "    'hardware': ['hardware error', 'disk error', 'i/o error', 'device error',\n",
    "                 'sensor error', 'temperature', 'voltage', 'power failure',\n",
    "                 'component failure', 'device timeout']\n",
    "}\n",
    "\n",
    "CATEGORY_TO_LABEL = {\n",
    "    'security': 1,\n",
    "    'system': 2,\n",
    "    'performance': 3,\n",
    "    'network': 4,\n",
    "    'config': 5,\n",
    "    'hardware': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7c1ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '<num>', text)\n",
    "    text = re.sub(r'\\b(ip|addr|address)\\b.*?\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b', '<ip>', text)\n",
    "    text = re.sub(r'[\\W_]+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def expand_keywords(keywords):\n",
    "    expanded = set()\n",
    "    for kw in keywords:\n",
    "        expanded.add(kw)\n",
    "        try:\n",
    "            for syn in wordnet.synsets(kw.replace(' ', '_')):\n",
    "                for lemma in syn.lemmas():\n",
    "                    expanded.add(lemma.name().replace('_', ' '))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return list(expanded)\n",
    "\n",
    "def fuzzy_match(text, keywords, threshold=80):\n",
    "    for kw in keywords:\n",
    "        if fuzz.partial_ratio(text, kw) >= threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def build_expanded_patterns(raw_patterns):\n",
    "    \"\"\"Expand, normalize, and dedupe patterns using WordNet.\"\"\"\n",
    "    expanded = {}\n",
    "    for cat, kws in raw_patterns.items():\n",
    "        base = set()\n",
    "        for k in kws:\n",
    "            base.add(normalize_text(k))\n",
    "        # \n",
    "        big = set()\n",
    "        for k in base:\n",
    "            big.update(normalize_text(x) for x in expand_keywords([k]))\n",
    "        # keep originals too\n",
    "        big.update(base)\n",
    "        expanded[cat] = sorted(big)\n",
    "    return expanded\n",
    "\n",
    "PATTERNS = build_expanded_patterns(RAW_PATTERNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b4d47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_datasets():\n",
    "    datasets = {}\n",
    "    failed = []\n",
    "\n",
    "    print(\"Loading datasets...\")\n",
    "    for source in LOG_SOURCES:\n",
    "        try:\n",
    "            file_path = DATA_PATH / f\"{source}.log_structured.csv\"\n",
    "            df = pd.read_csv(file_path)\n",
    "            datasets[source] = df\n",
    "            print(f\"✓ {source}: {len(df):,} logs, {df.shape[1]} columns\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ {source}: {e}\")\n",
    "            failed.append(source)\n",
    "\n",
    "    total = sum(len(df) for df in datasets.values())\n",
    "    print(f\"\\nLoaded: {len(datasets)}/{len(LOG_SOURCES)} sources\")\n",
    "    print(f\"Total logs: {total:,}\")\n",
    "    if failed:\n",
    "        print(f\"Failed to load: {failed}\")\n",
    "\n",
    "    return datasets, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b157ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_EMB_MODEL = None\n",
    "\n",
    "def get_embedding_model(model_name='all-MiniLM-L6-v2'):\n",
    "    global _EMB_MODEL\n",
    "    if _EMB_MODEL is None:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        try:\n",
    "            _EMB_MODEL = SentenceTransformer(model_name, device='cuda')\n",
    "        except Exception:\n",
    "            # fallback to CPU\n",
    "            _EMB_MODEL = SentenceTransformer(model_name)\n",
    "    return _EMB_MODEL\n",
    "\n",
    "def cosine_sim_max(query_emb, corpus_embs):\n",
    "    # corpus_embs: list of torch tensors\n",
    "    if not corpus_embs:\n",
    "        return 0.0\n",
    "    from sentence_transformers import util\n",
    "    sims = [util.cos_sim(query_emb, emb).item() for emb in corpus_embs]\n",
    "    return float(np.max(sims)) if len(sims) else 0.0\n",
    "\n",
    "class MLLabeler:\n",
    "    \"\"\"Lightweight TF-IDF + LogisticRegression classifier.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.vectorizer = None\n",
    "        self.model = None\n",
    "        self.is_trained = False\n",
    "\n",
    "    def train(self, texts, labels):\n",
    "        self.vectorizer = TfidfVectorizer(ngram_range=(1,3), min_df=2, max_features=100000)\n",
    "        X = self.vectorizer.fit_transform(texts)\n",
    "        self.model = LogisticRegression(max_iter=200, n_jobs=None, class_weight='balanced')\n",
    "        self.model.fit(X, labels)\n",
    "        self.is_trained = True\n",
    "\n",
    "    def predict_proba(self, texts):\n",
    "        if not self.is_trained:\n",
    "            return None\n",
    "        X = self.vectorizer.transform(texts)\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def predict(self, texts):\n",
    "        if not self.is_trained:\n",
    "            return None\n",
    "        X = self.vectorizer.transform(texts)\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "851ba61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_datasets(datasets):\n",
    "    stats = {}\n",
    "\n",
    "    print(\"Analyzing datasets with expanded patterns & fuzzy matching...\")\n",
    "    for source, df in datasets.items():\n",
    "        if 'EventTemplate' not in df.columns:\n",
    "            print(f\"Warning: {source} missing EventTemplate column\")\n",
    "            continue\n",
    "\n",
    "        templates = df['EventTemplate'].value_counts()\n",
    "\n",
    "        anomaly_count = 0\n",
    "        if 'Content' in df.columns:\n",
    "            content_lower = df['Content'].astype(str).apply(normalize_text)\n",
    "            # fuzzy match across categories\n",
    "            for category, keywords in PATTERNS.items():\n",
    "                # vectorized approx: quick substring filter then fuzzy refine (lightweight)\n",
    "                # For speed, we use simple contains for prefilter\n",
    "                pre = content_lower.str.contains('|'.join(map(re.escape, keywords)), na=False)\n",
    "                # add sum; fuzzy pass can be expensive, so we keep it simple here\n",
    "                anomaly_count += pre.sum()\n",
    "\n",
    "        stats[source] = {\n",
    "            'logs': len(df),\n",
    "            'templates': len(templates),\n",
    "            'efficiency': len(df) / max(len(templates), 1),\n",
    "            'anomaly_rate': (anomaly_count / max(len(df),1)) * 100,\n",
    "            'top_templates': templates.head(3).to_dict()\n",
    "        }\n",
    "\n",
    "    return stats\n",
    "\n",
    "def rank_sources_by_priority(stats, completed_sources=None):\n",
    "    if completed_sources is None:\n",
    "        completed_sources = []\n",
    "\n",
    "    rankings = []\n",
    "    for source, data in stats.items():\n",
    "        if source in completed_sources:\n",
    "            continue\n",
    "        anomaly_score = data['anomaly_rate']\n",
    "        template_score = max(0, 100 - (data['templates'] / 20))\n",
    "        efficiency_score = min(100, data['efficiency'] / 10)\n",
    "        priority = (anomaly_score * 0.4 + template_score * 0.3 + efficiency_score * 0.3)\n",
    "        rankings.append({\n",
    "            'source': source,\n",
    "            'priority': priority,\n",
    "            'anomaly_rate': data['anomaly_rate'],\n",
    "            'templates': data['templates'],\n",
    "            'efficiency': data['efficiency']\n",
    "        })\n",
    "\n",
    "    return sorted(rankings, key=lambda x: x['priority'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97a45a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartPatternLibrary:\n",
    "    \"\"\"\n",
    "    Hybrid label suggester:\n",
    "    - Keyword/phrase word-scores + TF-IDF idf weighting (1-3 grams)\n",
    "    - Feedback reweighting for corrections\n",
    "    - Semantic embeddings similarity per-label corpus\n",
    "    - Optional ML classifier trained on accumulated labeled exports\n",
    "    \"\"\"\n",
    "    def __init__(self, save_path=None):\n",
    "        self.save_path = save_path or (OUTPUT_PATH / \"smart_patterns.json\")\n",
    "        self.label_patterns = defaultdict(lambda: {\n",
    "            'keywords': defaultdict(int),\n",
    "            'templates': [],\n",
    "            'sources': set(),\n",
    "            'total_logs': 0\n",
    "        })\n",
    "        self.word_scores = defaultdict(lambda: defaultdict(float))\n",
    "        self.positive_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.negative_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        # TF-IDF\n",
    "        self.idf_scores = {}\n",
    "        self.tfidf_vectorizer = None\n",
    "\n",
    "        # Embeddings store\n",
    "        self.template_embeddings = defaultdict(list)  # label -> [tensor, ...]\n",
    "        self._emb_model_name = 'all-MiniLM-L6-v2'\n",
    "\n",
    "        # ML Classifier\n",
    "        self.ml = MLLabeler()\n",
    "\n",
    "        # Confidence calibration cache\n",
    "        self.calibration_stats = {'high': [], 'medium': [], 'low': []}\n",
    "\n",
    "    # ---------- Internal helpers ----------\n",
    "    def _update_tfidf(self):\n",
    "        all_templates = []\n",
    "        for label, data in self.label_patterns.items():\n",
    "            all_templates += data['templates']\n",
    "        if len(all_templates) < 3:\n",
    "            return\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,3), min_df=1)\n",
    "        self.tfidf_vectorizer.fit(all_templates)\n",
    "        # idf dictionary for quick lookup\n",
    "        self.idf_scores = dict(zip(self.tfidf_vectorizer.get_feature_names_out(),\n",
    "                                   self.tfidf_vectorizer.idf_))\n",
    "\n",
    "    def _template_to_embedding(self, text):\n",
    "        model = get_embedding_model(self._emb_model_name)\n",
    "        from torch import Tensor\n",
    "        emb = model.encode(normalize_text(text), convert_to_tensor=True)\n",
    "        return emb\n",
    "\n",
    "    # ---------- Public API ----------\n",
    "    def add_source_data(self, labeling_data, source_name, alpha=1.0, beta=0.2):\n",
    "        \"\"\"Learn from labeled templates and build embeddings/TF-IDF.\"\"\"\n",
    "        print(f\"Learning patterns from {source_name}...\")\n",
    "        count_added = 0\n",
    "\n",
    "        for item in labeling_data:\n",
    "            if item.get('label') is None:\n",
    "                continue\n",
    "\n",
    "            label = int(item['label'])\n",
    "            template = normalize_text(item['template'])\n",
    "            samples = [normalize_text(s) for s in item.get('samples', [])]\n",
    "            full_text = ' '.join([template] + samples)\n",
    "            log_count = int(item.get('count', 1))\n",
    "\n",
    "            self.label_patterns[label]['sources'].add(source_name)\n",
    "            self.label_patterns[label]['templates'].append(template)\n",
    "            self.label_patterns[label]['total_logs'] += log_count\n",
    "\n",
    "            # update word scores with feedback weighting\n",
    "            words = set(re.findall(r'\\b[a-zA-Z]{3,}\\b', full_text))\n",
    "            common_words = {'the', 'and', 'for', 'are', 'with', 'this', 'that', 'from', 'was', 'not'}\n",
    "            words = words - common_words\n",
    "            for w in words:\n",
    "                self.label_patterns[label]['keywords'][w] += log_count\n",
    "                self.word_scores[w][label] += alpha * log_count\n",
    "                for other_label in list(self.word_scores[w].keys()):\n",
    "                    if other_label != label:\n",
    "                        self.word_scores[w][other_label] *= (1 - beta)\n",
    "\n",
    "            # add embedding\n",
    "            try:\n",
    "                emb = self._template_to_embedding(template)\n",
    "                self.template_embeddings[label].append(emb)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            count_added += 1\n",
    "\n",
    "        self._update_tfidf()\n",
    "        self.save_library()\n",
    "        print(f\"Updated pattern library with {count_added} labeled templates from {source_name}\")\n",
    "\n",
    "    def suggest_label(self, template, samples):\n",
    "        \"\"\"Ensemble scoring: keywords/TF-IDF + contextual + embeddings + ML classifier.\"\"\"\n",
    "        template_n = normalize_text(template)\n",
    "        samples_n = [normalize_text(s) for s in samples]\n",
    "        full_text = ' '.join([template_n] + samples_n)\n",
    "\n",
    "        # 1) Keyword/word_scores with IDF weighting\n",
    "        words = set(re.findall(r'\\b[a-zA-Z]{3,}\\b', full_text))\n",
    "        label_scores = defaultdict(float)\n",
    "        for w in words:\n",
    "            if w in self.word_scores:\n",
    "                total_w = sum(self.word_scores[w].values())\n",
    "                if total_w <= 0:\n",
    "                    continue\n",
    "                idf = self.idf_scores.get(w, 1.0)\n",
    "                for label, score in self.word_scores[w].items():\n",
    "                    label_scores[label] += (score / total_w) * idf\n",
    "\n",
    "        # 2) Contextual boost: matches in both template & content\n",
    "        for w in words:\n",
    "            if w in template_n:\n",
    "                for label in list(label_scores.keys()):\n",
    "                    label_scores[label] *= 1.1  # +10% boost\n",
    "\n",
    "        # 3) Embedding similarity (fallback or additively mixed)\n",
    "        # If weak keyword evidence, rely on embeddings; else blend\n",
    "        use_embeddings = (not label_scores) or (max(label_scores.values()) < 1.0)\n",
    "        if use_embeddings:\n",
    "            try:\n",
    "                q_emb = self._template_to_embedding(template_n)\n",
    "                emb_sims = {}\n",
    "                for label, embs in self.template_embeddings.items():\n",
    "                    if embs:\n",
    "                        sim = cosine_sim_max(q_emb, embs)\n",
    "                        if sim > 0:\n",
    "                            emb_sims[label] = sim\n",
    "                # blend or fallback\n",
    "                if emb_sims:\n",
    "                    if not label_scores:\n",
    "                        label_scores = defaultdict(float, emb_sims)\n",
    "                    else:\n",
    "                        # blend with small weight\n",
    "                        for k, v in emb_sims.items():\n",
    "                            label_scores[k] += 0.75 * v\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        # 4) ML classifier probability (if trained)\n",
    "        if self.ml.is_trained:\n",
    "            try:\n",
    "                proba = self.ml.predict_proba([full_text])\n",
    "                if proba is not None:\n",
    "                    # ensure mapping to labels 0..7\n",
    "                    # Handle missing classes in training by aligning columns\n",
    "                    classes = list(self.ml.model.classes_)\n",
    "                    # fill label_scores with calibrated probs\n",
    "                    for idx, c in enumerate(classes):\n",
    "                        label_scores[int(c)] += float(proba[0, idx]) * 1.25  # weighted blend\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if not label_scores:\n",
    "            # No evidence: default to normal\n",
    "            return 0, 'low'\n",
    "\n",
    "        # pick best label\n",
    "        best_label = max(label_scores, key=label_scores.get)\n",
    "        best_score = label_scores[best_label]\n",
    "\n",
    "        # Confidence calibration using relative margin\n",
    "        scores_sorted = sorted(label_scores.values(), reverse=True)\n",
    "        margin = (scores_sorted[0] - scores_sorted[1]) if len(scores_sorted) > 1 else scores_sorted[0]\n",
    "        # empirical thresholds:\n",
    "        if best_score >= 2.0 and margin >= 0.5:\n",
    "            conf = 'high'\n",
    "        elif best_score >= 1.0 and margin >= 0.2:\n",
    "            conf = 'medium'\n",
    "        else:\n",
    "            conf = 'low'\n",
    "\n",
    "        return int(best_label), conf\n",
    "\n",
    "    def register_feedback(self, template, samples, chosen_label, alpha=1.0, beta=0.2):\n",
    "        \"\"\"When user corrects a label, reweight word_scores.\"\"\"\n",
    "        template_n = normalize_text(template)\n",
    "        samples_n = [normalize_text(s) for s in samples]\n",
    "        full_text = ' '.join([template_n] + samples_n)\n",
    "        words = set(re.findall(r'\\b[a-zA-Z]{3,}\\b', full_text))\n",
    "        for w in words:\n",
    "            self.positive_counts[w][chosen_label] += 1\n",
    "            self.word_scores[w][chosen_label] += alpha\n",
    "            for other in self.word_scores[w]:\n",
    "                if other != chosen_label:\n",
    "                    self.negative_counts[w][other] += 1\n",
    "                    self.word_scores[w][other] *= (1 - beta)\n",
    "\n",
    "    def save_library(self):\n",
    "        data = {\n",
    "            'label_patterns': {},\n",
    "            'word_scores': {},\n",
    "            'positive_counts': {},\n",
    "            'negative_counts': {},\n",
    "            'emb_model': self._emb_model_name\n",
    "        }\n",
    "        for label, patterns in self.label_patterns.items():\n",
    "            data['label_patterns'][str(label)] = {\n",
    "                'keywords': dict(patterns['keywords']),\n",
    "                'templates': patterns['templates'],\n",
    "                'sources': list(patterns['sources']),\n",
    "                'total_logs': patterns['total_logs']\n",
    "            }\n",
    "        for word, scores in self.word_scores.items():\n",
    "            data['word_scores'][word] = {str(int(k)): float(v) for k, v in scores.items()}\n",
    "\n",
    "        # counts\n",
    "        data['positive_counts'] = {w: {str(int(k)): int(v) for k, v in d.items()} for w, d in self.positive_counts.items()}\n",
    "        data['negative_counts'] = {w: {str(int(k)): int(v) for k, v in d.items()} for w, d in self.negative_counts.items()}\n",
    "\n",
    "        with open(self.save_path, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "    def load_library(self):\n",
    "        if not self.save_path.exists():\n",
    "            return False\n",
    "        try:\n",
    "            with open(self.save_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            self._emb_model_name = data.get('emb_model', 'all-MiniLM-L6-v2')\n",
    "\n",
    "            for label_str, patterns in data.get('label_patterns', {}).items():\n",
    "                label = int(label_str)\n",
    "                self.label_patterns[label]['keywords'] = defaultdict(int, patterns['keywords'])\n",
    "                self.label_patterns[label]['templates'] = patterns['templates']\n",
    "                self.label_patterns[label]['sources'] = set(patterns.get('sources', []))\n",
    "                self.label_patterns[label]['total_logs'] = patterns.get('total_logs', 0)\n",
    "\n",
    "            # Restore word scores\n",
    "            self.word_scores.clear()\n",
    "            for word, scores in data.get('word_scores', {}).items():\n",
    "                self.word_scores[word] = defaultdict(float, {int(k): float(v) for k, v in scores.items()})\n",
    "\n",
    "            # Restore counts\n",
    "            self.positive_counts.clear()\n",
    "            for w, d in data.get('positive_counts', {}).items():\n",
    "                self.positive_counts[w] = defaultdict(int, {int(k): int(v) for k, v in d.items()})\n",
    "\n",
    "            self.negative_counts.clear()\n",
    "            for w, d in data.get('negative_counts', {}).items():\n",
    "                self.negative_counts[w] = defaultdict(int, {int(k): int(v) for k, v in d.items()})\n",
    "\n",
    "            # Rebuild embeddings from templates\n",
    "            for label, pat in self.label_patterns.items():\n",
    "                self.template_embeddings[label] = []\n",
    "                for t in pat['templates']:\n",
    "                    try:\n",
    "                        emb = self._template_to_embedding(t)\n",
    "                        self.template_embeddings[label].append(emb)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "            self._update_tfidf()\n",
    "            print(\"Smart pattern library loaded.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading pattern library: {e}\")\n",
    "            return False\n",
    "\n",
    "    def get_statistics(self):\n",
    "        stats = {}\n",
    "        for label in LABELS.keys():\n",
    "            if self.label_patterns[label]['templates']:\n",
    "                sources = self.label_patterns[label]['sources']\n",
    "                stats[label] = {\n",
    "                    'label_name': LABELS[label],\n",
    "                    'templates': len(self.label_patterns[label]['templates']),\n",
    "                    'keywords': len(self.label_patterns[label]['keywords']),\n",
    "                    'sources': len(sources) if isinstance(sources, (list, set)) else 0,\n",
    "                    'total_logs': self.label_patterns[label]['total_logs']\n",
    "                }\n",
    "        return stats\n",
    "\n",
    "    # ---- ML training on combined labeled CSVs ----\n",
    "    def train_ml_from_exports(self):\n",
    "        \"\"\"Train lightweight classifier from all *_labeled.csv in OUTPUT_PATH.\"\"\"\n",
    "        csvs = list(OUTPUT_PATH.glob(\"*_labeled.csv\"))\n",
    "        if not csvs:\n",
    "            print(\"No labeled exports found for ML training.\")\n",
    "            return False\n",
    "\n",
    "        texts, labels = [], []\n",
    "        for fp in csvs:\n",
    "            try:\n",
    "                df = pd.read_csv(fp)\n",
    "                df = df[df['AnomalyLabel'] >= 0].copy()\n",
    "                if df.empty:\n",
    "                    continue\n",
    "                # combine template + content\n",
    "                t = df['EventTemplate'].astype(str).apply(normalize_text)\n",
    "                c = df['Content'].astype(str).apply(normalize_text)\n",
    "                combo = (t + \" \" + c).tolist()\n",
    "                texts.extend(combo)\n",
    "                labels.extend(df['AnomalyLabel'].astype(int).tolist())\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {fp.name}: {e}\")\n",
    "\n",
    "        if len(texts) < 100:\n",
    "            print(\"Not enough data to train ML classifier yet.\")\n",
    "            return False\n",
    "\n",
    "        print(f\"Training ML classifier on {len(texts):,} labeled logs...\")\n",
    "        self.ml.train(texts, labels)\n",
    "        print(\"ML classifier trained.\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1790b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_templates_for_labeling(df, source_name, pattern_library: SmartPatternLibrary):\n",
    "    if 'EventTemplate' not in df.columns or 'Content' not in df.columns:\n",
    "        print(f\"Error: Missing required columns in {source_name}\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        return []\n",
    "\n",
    "    templates = df['EventTemplate'].value_counts()\n",
    "    labeling_data = []\n",
    "\n",
    "    print(f\"Processing {len(templates)} unique templates with semantic suggestions...\")\n",
    "\n",
    "    for template, count in templates.items():\n",
    "        matching_rows = df[df['EventTemplate'] == template]\n",
    "        samples = matching_rows['Content'].astype(str).head(3).tolist()\n",
    "        samples = [s if s else 'Empty content' for s in samples]\n",
    "\n",
    "        try:\n",
    "            suggested_label, confidence = pattern_library.suggest_label(template, samples)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Pattern suggestion failed for {template[:50]}: {e}\")\n",
    "            suggested_label, confidence = 0, \"low\"\n",
    "\n",
    "        labeling_data.append({\n",
    "            'template': template,\n",
    "            'count': int(count),\n",
    "            'percentage': (count / len(df)) * 100,\n",
    "            'samples': samples,\n",
    "            'suggested': int(suggested_label),\n",
    "            'confidence': confidence,\n",
    "            'label': None,\n",
    "            'notes': ''\n",
    "        })\n",
    "\n",
    "    return sorted(labeling_data, key=lambda x: x['count'], reverse=True)\n",
    "\n",
    "def auto_label_high_confidence(labeling_data):\n",
    "    auto_count = 0\n",
    "    for item in labeling_data:\n",
    "        if item['confidence'] == 'high' and item['label'] is None:\n",
    "            item['label'] = item['suggested']\n",
    "            item['notes'] = 'Auto-labeled (high confidence)'\n",
    "            auto_count += 1\n",
    "    print(f\"Auto-labeled {auto_count} templates\")\n",
    "    return auto_count\n",
    "\n",
    "def interactive_labeling_session(data, source_name, start=0, count=10):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"LABELING SESSION: {source_name}\")\n",
    "    print(\"Labels:\", \", \".join(f\"{k}:{v}\" for k, v in LABELS.items()))\n",
    "    print(\"Commands: 0-7 (label), 'skip', 'quit', 'save', 'info'\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    end = min(start + count, len(data))\n",
    "    labeled = 0\n",
    "\n",
    "    for i in range(start, end):\n",
    "        item = data[i]\n",
    "        print(f\"\\n[{i+1}/{len(data)}] Template\")\n",
    "        print(f\"Frequency: {item['count']:,} logs ({item['percentage']:.1f}%)\")\n",
    "        print(f\"Template: {item['template']}\")\n",
    "        print(\"Sample logs:\")\n",
    "        for j, sample in enumerate(item['samples'][:3], 1):\n",
    "            display = sample[:120] + \"...\" if len(sample) > 120 else sample\n",
    "            print(f\"  {j}. {display}\")\n",
    "        print(f\"Suggested: {item['suggested']} ({LABELS[item['suggested']]}) - {item['confidence']}\")\n",
    "\n",
    "        while True:\n",
    "            response = input(f\"\\nLabel (suggested {item['suggested']}): \").strip()\n",
    "            if response.lower() == 'quit':\n",
    "                return i, labeled\n",
    "            elif response.lower() == 'skip':\n",
    "                break\n",
    "            elif response.lower() == 'save':\n",
    "                save_labeling_progress(data, source_name)\n",
    "                continue\n",
    "            elif response.lower() == 'info':\n",
    "                print(f\"\\nAdditional info:\")\n",
    "                print(f\"Template pattern: {item['template']}\")\n",
    "                df = datasets.get(source_name)\n",
    "                if df is not None:\n",
    "                    more_samples = df[df['EventTemplate'] == item['template']]['Content'].astype(str).head(5).tolist()\n",
    "                    for k, sample in enumerate(more_samples, 1):\n",
    "                        print(f\"  Extra {k}: {str(sample)[:100]}...\")\n",
    "                continue\n",
    "            elif response.isdigit() and 0 <= int(response) < len(LABELS):\n",
    "                item['label'] = int(response)\n",
    "                notes = input(\"Optional notes: \").strip()\n",
    "                if notes:\n",
    "                    item['notes'] = notes\n",
    "                labeled += 1\n",
    "                # feedback into library\n",
    "                pattern_library.register_feedback(item['template'], item['samples'], item['label'])\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Enter a number 0-{len(LABELS)-1}, 'skip', 'save', 'info', or 'quit'\")\n",
    "\n",
    "    print(f\"\\nLabeled {labeled} templates in this session\")\n",
    "    return end, labeled\n",
    "\n",
    "def bulk_label_by_suggestion(labeling_data):\n",
    "    groups = defaultdict(list)\n",
    "    for item in labeling_data:\n",
    "        if item['label'] is None:\n",
    "            groups[item['suggested']].append(item)\n",
    "\n",
    "    total_labeled = 0\n",
    "    print(\"Bulk labeling by pattern suggestions:\")\n",
    "    for suggested_label, items in groups.items():\n",
    "        if len(items) == 0:\n",
    "            continue\n",
    "        print(f\"\\n{LABELS[suggested_label]}: {len(items)} templates\")\n",
    "        for i, item in enumerate(items[:3], 1):\n",
    "            print(f\"  {i}. [{item['count']:4,}] {item['template'][:60]}...\")\n",
    "        if len(items) > 3:\n",
    "            print(f\"  ... and {len(items)-3} more\")\n",
    "        choice = input(f\"Label all as {LABELS[suggested_label]}? (y/n/s=skip): \").strip().lower()\n",
    "        if choice == 'y':\n",
    "            for item in items:\n",
    "                item['label'] = suggested_label\n",
    "                item['notes'] = 'Bulk labeled by suggestion'\n",
    "            total_labeled += len(items)\n",
    "            print(f\"Labeled {len(items)} templates\")\n",
    "    print(f\"\\nBulk labeled {total_labeled} templates total\")\n",
    "    return total_labeled\n",
    "\n",
    "def save_labeling_progress(data, source_name):\n",
    "    save_data = []\n",
    "    for item in data:\n",
    "        item_copy = dict(item)\n",
    "        if 'samples' in item_copy and not isinstance(item_copy['samples'], str):\n",
    "            item_copy['samples'] = json.dumps(item_copy['samples'])\n",
    "        save_data.append(item_copy)\n",
    "    df = pd.DataFrame(save_data)\n",
    "    progress_file = OUTPUT_PATH / f\"{source_name}_progress.csv\"\n",
    "    df.to_csv(progress_file, index=False)\n",
    "    labeled = sum(1 for item in data if item['label'] is not None)\n",
    "    print(f\"Progress saved: {labeled}/{len(data)} templates for {source_name}\")\n",
    "\n",
    "def load_labeling_progress(source_name):\n",
    "    progress_file = OUTPUT_PATH / f\"{source_name}_progress.csv\"\n",
    "    if not progress_file.exists():\n",
    "        return None\n",
    "    try:\n",
    "        df = pd.read_csv(progress_file).where(pd.notna, None)\n",
    "        data = df.to_dict('records')\n",
    "        for item in data:\n",
    "            if 'samples' in item and isinstance(item['samples'], str):\n",
    "                try:\n",
    "                    item['samples'] = json.loads(item['samples'])\n",
    "                except:\n",
    "                    item['samples'] = ['Error loading samples']\n",
    "        labeled = sum(1 for item in data if item.get('label') is not None)\n",
    "        print(f\"Loaded progress: {labeled}/{len(data)} templates for {source_name}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading progress for {source_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def show_labeling_progress(data, source_name=None):\n",
    "    total = len(data)\n",
    "    labeled = sum(1 for item in data if item['label'] is not None)\n",
    "    if source_name:\n",
    "        print(f\"\\nProgress for {source_name}:\")\n",
    "    else:\n",
    "        print(f\"\\nLabeling Progress:\")\n",
    "    print(f\"Templates: {labeled}/{total} ({labeled/total*100:.1f}%)\")\n",
    "\n",
    "    if labeled > 0:\n",
    "        total_logs = sum(item['count'] for item in data)\n",
    "        labeled_logs = sum(item['count'] for item in data if item['label'] is not None)\n",
    "        print(f\"Log coverage: {labeled_logs:,}/{total_logs:,} ({labeled_logs/total_logs*100:.1f}%)\")\n",
    "        dist = defaultdict(int)\n",
    "        for item in data:\n",
    "            if item['label'] is not None:\n",
    "                dist[int(item['label'])] += item['count']\n",
    "        print(\"Label distribution:\")\n",
    "        for label in sorted(dist.keys()):\n",
    "            count = dist[label]\n",
    "            print(f\"  {label} ({LABELS[label]}): {count:,} logs\")\n",
    "    return labeled, total\n",
    "\n",
    "def export_labeled_dataset(df, labeling_data, source_name):\n",
    "    template_labels = {item['template']: item['label']\n",
    "                       for item in labeling_data if item['label'] is not None}\n",
    "    result_df = df.copy()\n",
    "    result_df['AnomalyLabel'] = result_df['EventTemplate'].map(template_labels).fillna(-1).astype(int)\n",
    "    result_df['AnomalyLabelName'] = result_df['AnomalyLabel'].map(lambda x: LABELS.get(x, 'unlabeled'))\n",
    "    result_df['Source'] = source_name\n",
    "\n",
    "    output_file = OUTPUT_PATH / f\"{source_name}_labeled.csv\"\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "\n",
    "    total = len(result_df)\n",
    "    labeled_count = (result_df['AnomalyLabel'] >= 0).sum()\n",
    "    anomaly_count = (result_df['AnomalyLabel'] > 0).sum()\n",
    "\n",
    "    print(f\"\\nExported labeled dataset: {output_file}\")\n",
    "    print(f\"Total logs: {total:,}\")\n",
    "    print(f\"Labeled logs: {labeled_count:,} ({labeled_count/total*100:.1f}%)\")\n",
    "    if labeled_count > 0:\n",
    "        print(f\"Anomaly logs: {anomaly_count:,} ({anomaly_count/labeled_count*100:.1f}% of labeled)\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40f3dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_labeling_quality(labeling_data):\n",
    "    issues = []\n",
    "    for i, item in enumerate(labeling_data):\n",
    "        if item.get('label') is None:\n",
    "            continue\n",
    "        content = ' '.join(str(s) for s in item['samples']).lower()\n",
    "        label = int(item['label'])\n",
    "        if label == 1:\n",
    "            security_words = ['auth', 'login', 'password', 'user', 'invalid', 'fail', 'denied', 'unauthorized']\n",
    "            if not any(w in content for w in security_words):\n",
    "                issues.append(f\"Template {i}: Security label without security keywords\")\n",
    "        elif label == 0:\n",
    "            error_words = ['error', 'fail', 'critical', 'exception', 'crash', 'fatal']\n",
    "            if any(w in content for w in error_words):\n",
    "                issues.append(f\"Template {i}: Normal label with error keywords\")\n",
    "        # heuristic: high-frequency anomalies deserve review\n",
    "        if label > 0 and item['percentage'] > 15:\n",
    "            issues.append(f\"Template {i}: High-frequency anomaly ({item['percentage']:.1f}%)\")\n",
    "    if issues:\n",
    "        print(f\"\\nFound {len(issues)} potential issues:\")\n",
    "        for issue in issues[:10]:\n",
    "            print(f\"  {issue}\")\n",
    "    else:\n",
    "        print(\"\\nNo validation issues found - labeling quality looks good!\")\n",
    "    return issues\n",
    "\n",
    "def analyze_cross_source_patterns(completed_sources_data):\n",
    "    if len(completed_sources_data) < 2:\n",
    "        print(\"Need at least 2 completed sources for cross-analysis\")\n",
    "        return\n",
    "    print(\"\\nCROSS-SOURCE PATTERN ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    source_distributions = {}\n",
    "    for source_name, data in completed_sources_data.items():\n",
    "        dist = defaultdict(int)\n",
    "        total_logs = 0\n",
    "        for item in data:\n",
    "            if item['label'] is not None:\n",
    "                dist[int(item['label'])] += int(item['count'])\n",
    "                total_logs += int(item['count'])\n",
    "        if total_logs > 0:\n",
    "            source_distributions[source_name] = {label: (count/total_logs)*100 for label, count in dist.items()}\n",
    "\n",
    "    print(f\"{'Source':<15}\", end=\"\")\n",
    "    for label_id in sorted(LABELS.keys()):\n",
    "        print(f\"{LABELS[label_id][:8]:<10}\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * (15 + 10 * len(LABELS)))\n",
    "    for source, dist in source_distributions.items():\n",
    "        print(f\"{source:<15}\", end=\"\")\n",
    "        for label_id in sorted(LABELS.keys()):\n",
    "            pct = dist.get(label_id, 0)\n",
    "            print(f\"{pct:>8.1f}% \", end=\"\")\n",
    "        print()\n",
    "\n",
    "def transfer_labels_across_sources(source_mgr, threshold=90):\n",
    "    \"\"\"Propagate labels between similar templates via fuzzy matching.\"\"\"\n",
    "    print(\"\\nTemplate transfer learning across sources...\")\n",
    "    # Build map: template -> label from completed\n",
    "    known = {}\n",
    "    for src in source_mgr.completed:\n",
    "        progress = load_labeling_progress(src)\n",
    "        if progress:\n",
    "            for item in progress:\n",
    "                if item.get('label') is not None:\n",
    "                    known[item['template']] = int(item['label'])\n",
    "\n",
    "    # For current source, fill suggestions if fuzzy match > threshold\n",
    "    if source_mgr.current_data:\n",
    "        templates = [it['template'] for it in source_mgr.current_data if it['label'] is None]\n",
    "        for t in templates:\n",
    "            if not known:\n",
    "                continue  \n",
    "            result = process.extractOne(t, list(known.keys()))\n",
    "            if not result:\n",
    "                continue\n",
    "            match, score, _ = result\n",
    "            if score >= threshold:\n",
    "                inferred = known.get(match)\n",
    "                for it in source_mgr.current_data:\n",
    "                    if it['template'] == t and it['label'] is None:\n",
    "                        it['suggested'] = inferred\n",
    "                        if it['confidence'] == 'low':\n",
    "                            it['confidence'] = 'medium'\n",
    "        print(\"Transfer suggestions updated where high-similarity templates were found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16e40c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_dataset(completed_sources):\n",
    "    if not completed_sources:\n",
    "        print(\"No completed sources found\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Creating combined dataset from {len(completed_sources)} sources...\")\n",
    "    combined_dfs = []\n",
    "    for source in completed_sources:\n",
    "        labeled_file = OUTPUT_PATH / f\"{source}_labeled.csv\"\n",
    "        if labeled_file.exists():\n",
    "            df = pd.read_csv(labeled_file)\n",
    "            combined_dfs.append(df)\n",
    "            print(f\"Added {source}: {len(df):,} logs\")\n",
    "    if not combined_dfs:\n",
    "        print(\"No labeled datasets found\")\n",
    "        return None\n",
    "\n",
    "    combined = pd.concat(combined_dfs, ignore_index=True)\n",
    "    combined_file = OUTPUT_PATH / \"combined_labeled_dataset.csv\"\n",
    "    combined.to_csv(combined_file, index=False)\n",
    "\n",
    "    total = len(combined)\n",
    "    labeled = (combined['AnomalyLabel'] >= 0).sum()\n",
    "    anomalies = (combined['AnomalyLabel'] > 0).sum()\n",
    "\n",
    "    print(f\"\\nCombined dataset saved: {combined_file}\")\n",
    "    print(f\"Total logs: {total:,}\")\n",
    "    print(f\"Labeled logs: {labeled:,} ({labeled/total*100:.1f}%)\")\n",
    "    if labeled > 0:\n",
    "        print(f\"Anomaly logs: {anomalies:,} ({anomalies/labeled*100:.1f}% of labeled)\")\n",
    "\n",
    "    print(f\"\\nPer-source breakdown:\")\n",
    "    for source in combined['Source'].unique():\n",
    "        source_data = combined[combined['Source'] == source]\n",
    "        s_total = len(source_data)\n",
    "        s_labeled = (source_data['AnomalyLabel'] >= 0).sum()\n",
    "        s_anomalies = (source_data['AnomalyLabel'] > 0).sum()\n",
    "        print(f\"  {source}: {s_total:,} logs, {s_labeled:,} labeled, {s_anomalies:,} anomalies\")\n",
    "    return combined\n",
    "\n",
    "def export_ml_ready_data(dataset, output_name=\"combined\"):\n",
    "    labeled_data = dataset[dataset['AnomalyLabel'] >= 0].copy()\n",
    "    if len(labeled_data) == 0:\n",
    "        print(\"No labeled data to export for ML\")\n",
    "        return\n",
    "    print(f\"Preparing ML data from {len(labeled_data):,} labeled logs...\")\n",
    "\n",
    "    labeled_data['Content'] = labeled_data['Content'].astype(str)\n",
    "    labeled_data['EventTemplate'] = labeled_data['EventTemplate'].astype(str)\n",
    "\n",
    "    labeled_data['ContentLength'] = labeled_data['Content'].str.len()\n",
    "    labeled_data['TemplateLength'] = labeled_data['EventTemplate'].str.len()\n",
    "    labeled_data['HasError'] = labeled_data['Content'].str.lower().str.contains('error|fail|critical|exception')\n",
    "    labeled_data['HasAuth'] = labeled_data['Content'].str.lower().str.contains('auth|login|user|password')\n",
    "    labeled_data['HasNetwork'] = labeled_data['Content'].str.lower().str.contains('connection|network|timeout')\n",
    "    labeled_data['HasSystem'] = labeled_data['Content'].str.lower().str.contains('system|kernel|process')\n",
    "    labeled_data['HasNumbers'] = labeled_data['Content'].str.contains(r'\\d+')\n",
    "    labeled_data['HasIPAddress'] = labeled_data['Content'].str.contains(r'\\b\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\b')\n",
    "\n",
    "    feature_cols = ['Content', 'EventTemplate', 'ContentLength', 'TemplateLength',\n",
    "                    'HasError', 'HasAuth', 'HasNetwork', 'HasSystem', 'HasNumbers',\n",
    "                    'HasIPAddress', 'Source']\n",
    "\n",
    "    X = labeled_data[feature_cols]\n",
    "    y = labeled_data['AnomalyLabel']\n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "    except ValueError:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "    train_file = OUTPUT_PATH / f\"{output_name}_train.csv\"\n",
    "    test_file = OUTPUT_PATH / f\"{output_name}_test.csv\"\n",
    "\n",
    "    pd.concat([X_train, y_train], axis=1).to_csv(train_file, index=False)\n",
    "    pd.concat([X_test, y_test], axis=1).to_csv(test_file, index=False)\n",
    "\n",
    "    print(f\"\\nML data exported:\")\n",
    "    print(f\"Training set: {len(X_train):,} samples -> {train_file}\")\n",
    "    print(f\"Test set:    {len(X_test):,} samples -> {test_file}\")\n",
    "\n",
    "    print(f\"\\nTraining set label distribution:\")\n",
    "    for label, count in y_train.value_counts().sort_index().items():\n",
    "        pct = count/len(y_train)*100\n",
    "        print(f\"  {label} ({LABELS[label]}): {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "    return train_file, test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7ffeaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SourceManager:\n",
    "    def __init__(self, datasets, stats, pattern_library: SmartPatternLibrary):\n",
    "        self.datasets = datasets\n",
    "        self.stats = stats\n",
    "        self.pattern_library = pattern_library\n",
    "        self.completed = []\n",
    "        self.current_data = None\n",
    "        self.current_source = None\n",
    "        self.load_completed_sources()\n",
    "\n",
    "    def load_completed_sources(self):\n",
    "        completed_file = OUTPUT_PATH / \"completed_sources.json\"\n",
    "        if completed_file.exists():\n",
    "            try:\n",
    "                with open(completed_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    self.completed = data.get('completed', [])\n",
    "                    print(f\"Loaded {len(self.completed)} completed sources from disk\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def save_completed_sources(self):\n",
    "        completed_file = OUTPUT_PATH / \"completed_sources.json\"\n",
    "        with open(completed_file, 'w') as f:\n",
    "            json.dump({\n",
    "                'completed': self.completed,\n",
    "                'last_updated': datetime.now().isoformat()\n",
    "            }, f, indent=2)\n",
    "\n",
    "    def get_next_recommended_source(self):\n",
    "        rankings = rank_sources_by_priority(self.stats, self.completed)\n",
    "        if not rankings:\n",
    "            return None\n",
    "        return rankings[0]['source']\n",
    "\n",
    "    def start_new_source(self, source):\n",
    "        print(f\"\\nStarting source: {source}\")\n",
    "        existing = load_labeling_progress(source)\n",
    "        if existing:\n",
    "            self.current_data = existing\n",
    "            print(\"Resumed from saved progress\")\n",
    "        else:\n",
    "            self.current_data = prepare_templates_for_labeling(\n",
    "                self.datasets[source], source, self.pattern_library)\n",
    "            auto_label_high_confidence(self.current_data)\n",
    "\n",
    "        self.current_source = source\n",
    "        show_labeling_progress(self.current_data, source)\n",
    "\n",
    "        # transfer learning: propagate labels from completed sources if similar\n",
    "        transfer_labels_across_sources(self, threshold=90)\n",
    "        return self.current_data\n",
    "\n",
    "    def complete_current_source(self):\n",
    "        if not self.current_source or not self.current_data:\n",
    "            print(\"No active source to complete\")\n",
    "            return None\n",
    "\n",
    "        final_df = export_labeled_dataset(\n",
    "            self.datasets[self.current_source],\n",
    "            self.current_data,\n",
    "            self.current_source\n",
    "        )\n",
    "\n",
    "        # Feed back to pattern library\n",
    "        self.pattern_library.add_source_data(self.current_data, self.current_source)\n",
    "\n",
    "        if self.current_source not in self.completed:\n",
    "            self.completed.append(self.current_source)\n",
    "            self.save_completed_sources()\n",
    "\n",
    "        print(f\"✓ Completed {self.current_source}\")\n",
    "        print(f\"Total completed sources: {len(self.completed)}/{len(LOG_SOURCES)}\")\n",
    "\n",
    "        completed_source = self.current_source\n",
    "        self.current_source = None\n",
    "        self.current_data = None\n",
    "\n",
    "        # Try (re)training ML with new data\n",
    "        self.pattern_library.train_ml_from_exports()\n",
    "\n",
    "        return final_df, completed_source\n",
    "\n",
    "    def get_overall_status(self):\n",
    "        print(f\"\\nOVERALL STATUS\")\n",
    "        print(f\"{'='*40}\")\n",
    "        print(f\"Total sources: {len(LOG_SOURCES)}\")\n",
    "        print(f\"Completed sources: {len(self.completed)}\")\n",
    "        print(f\"Remaining sources: {len(LOG_SOURCES) - len(self.completed)}\")\n",
    "        print(f\"Progress: {len(self.completed)/len(LOG_SOURCES)*100:.1f}%\")\n",
    "\n",
    "        if self.completed:\n",
    "            print(f\"\\nCompleted: {', '.join(self.completed)}\")\n",
    "\n",
    "        try:\n",
    "            lib_stats = self.pattern_library.get_statistics()\n",
    "            if lib_stats:\n",
    "                total_templates = sum(s.get('templates', 0) for s in lib_stats.values())\n",
    "                all_sources = set()\n",
    "                for label_data in lib_stats.values():\n",
    "                    # label_data['sources'] is int count in get_statistics, not a set\n",
    "                    pass\n",
    "                print(f\"\\nPattern library: {total_templates} templates (embeddings + TF-IDF ready)\")\n",
    "            else:\n",
    "                print(f\"\\nPattern library: Empty (no patterns learned yet)\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nPattern library: Error reading stats - {e}\")\n",
    "\n",
    "        if self.current_source:\n",
    "            print(f\"\\nCurrent source: {self.current_source}\")\n",
    "            if self.current_data:\n",
    "                show_labeling_progress(self.current_data, self.current_source)\n",
    "        else:\n",
    "            next_source = self.get_next_recommended_source()\n",
    "            if next_source:\n",
    "                print(f\"\\nNext recommended: {next_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c30f616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamlined_workflow():\n",
    "    print(\"STREAMLINED MULTI-SOURCE LOG ANOMALY LABELING WORKFLOW\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    source_mgr.get_overall_status()\n",
    "\n",
    "    if source_mgr.current_source and source_mgr.current_data:\n",
    "        print(f\"\\nActive source: {source_mgr.current_source}\")\n",
    "        labeled, total = show_labeling_progress(source_mgr.current_data, source_mgr.current_source)\n",
    "\n",
    "        if labeled < total:\n",
    "            print(f\"\\nOptions:\")\n",
    "            print(f\"1. Continue labeling current source\")\n",
    "            print(f\"2. Bulk label remaining templates\")\n",
    "            print(f\"3. Complete source with current progress\")\n",
    "            print(f\"4. Switch to different source\")\n",
    "\n",
    "            choice = input(\"Choose option (1-4): \").strip()\n",
    "\n",
    "            if choice == '1':\n",
    "                return continue_labeling_current_source()\n",
    "            elif choice == '2':\n",
    "                return bulk_label_remaining_templates()\n",
    "            elif choice == '3':\n",
    "                return complete_current_source()\n",
    "            elif choice == '4':\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Invalid choice\")\n",
    "                return\n",
    "        else:\n",
    "            print(\"\\nCurrent source fully labeled!\")\n",
    "            choice = input(\"Complete this source? (y/n): \").strip().lower()\n",
    "            if choice == 'y':\n",
    "                return complete_current_source()\n",
    "\n",
    "    next_source = source_mgr.get_next_recommended_source()\n",
    "    if next_source:\n",
    "        print(f\"\\nNext recommended source: {next_source}\")\n",
    "        source_stats = source_mgr.stats[next_source]\n",
    "        print(f\"  Templates: {source_stats['templates']}\")\n",
    "        print(f\"  Estimated anomaly rate: {source_stats['anomaly_rate']:.1f}%\")\n",
    "        print(f\"  Efficiency: {source_stats['efficiency']:.1f} logs/template\")\n",
    "\n",
    "        choice = input(\"\\nStart this source? (y/n): \").strip().lower()\n",
    "        if choice == 'y':\n",
    "            source_mgr.start_new_source(next_source)\n",
    "            return 'source_started'\n",
    "\n",
    "    if len(source_mgr.completed) >= len(LOG_SOURCES):\n",
    "        print(\"\\n🎉 All sources completed!\")\n",
    "        print(\"Run create_combined_dataset() and export_ml_ready_data() for final export\")\n",
    "        return 'all_completed'\n",
    "    else:\n",
    "        print(\"\\nNo more recommended sources or user declined.\")\n",
    "        print(\"Use manual commands if needed.\")\n",
    "        return 'manual_needed'\n",
    "\n",
    "def continue_labeling_current_source(batch_size=10):\n",
    "    if not source_mgr.current_source or not source_mgr.current_data:\n",
    "        print(\"No active source. Run streamlined_workflow() first.\")\n",
    "        return\n",
    "\n",
    "    unlabeled_indices = [i for i, item in enumerate(source_mgr.current_data)\n",
    "                         if item['label'] is None]\n",
    "    if not unlabeled_indices:\n",
    "        print(\"All templates labeled! Run complete_current_source() to finish.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nContinuing labeling: {source_mgr.current_source}\")\n",
    "    print(f\"Remaining templates: {len(unlabeled_indices)}\")\n",
    "    start_idx = unlabeled_indices[0]\n",
    "\n",
    "    pos, labeled = interactive_labeling_session(\n",
    "        source_mgr.current_data, source_mgr.current_source, start_idx, batch_size\n",
    "    )\n",
    "\n",
    "    save_labeling_progress(source_mgr.current_data, source_mgr.current_source)\n",
    "\n",
    "    print(f\"\\nSession complete. Progress automatically saved.\")\n",
    "    show_labeling_progress(source_mgr.current_data, source_mgr.current_source)\n",
    "\n",
    "    return pos, labeled\n",
    "\n",
    "def bulk_label_remaining_templates():\n",
    "    if not source_mgr.current_source or not source_mgr.current_data:\n",
    "        print(\"No active source\")\n",
    "        return\n",
    "\n",
    "    unlabeled_count = sum(1 for item in source_mgr.current_data if item['label'] is None)\n",
    "    if unlabeled_count == 0:\n",
    "        print(\"All templates already labeled\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nBulk labeling {unlabeled_count} remaining templates...\")\n",
    "\n",
    "    high_conf_count = 0\n",
    "    for item in source_mgr.current_data:\n",
    "        if item['label'] is None and item['confidence'] == 'high':\n",
    "            item['label'] = item['suggested']\n",
    "            item['notes'] = 'Bulk: Auto-accepted high confidence'\n",
    "            high_conf_count += 1\n",
    "    print(f\"Auto-accepted {high_conf_count} high confidence suggestions\")\n",
    "\n",
    "    remaining_unlabeled = [item for item in source_mgr.current_data if item['label'] is None]\n",
    "    if remaining_unlabeled:\n",
    "        total_bulk_labeled = bulk_label_by_suggestion(remaining_unlabeled)\n",
    "        print(f\"Bulk labeled {total_bulk_labeled} additional templates\")\n",
    "\n",
    "    still_unlabeled = [item for item in source_mgr.current_data if item['label'] is None]\n",
    "    if still_unlabeled:\n",
    "        print(f\"\\nRemaining {len(still_unlabeled)} templates - options:\")\n",
    "        print(\"1. Label all as 'normal' (conservative)\")\n",
    "        print(\"2. Label all as 'unknown_anomaly' (liberal)\")\n",
    "        print(\"3. Skip (leave unlabeled)\")\n",
    "\n",
    "        choice = input(\"Choose (1-3): \").strip()\n",
    "        if choice == '1':\n",
    "            for item in still_unlabeled:\n",
    "                item['label'] = 0\n",
    "                item['notes'] = 'Bulk: Default normal'\n",
    "            print(f\"Labeled {len(still_unlabeled)} templates as normal\")\n",
    "        elif choice == '2':\n",
    "            for item in still_unlabeled:\n",
    "                item['label'] = 7\n",
    "                item['notes'] = 'Bulk: Default unknown anomaly'\n",
    "            print(f\"Labeled {len(still_unlabeled)} templates as unknown anomaly\")\n",
    "\n",
    "    save_labeling_progress(source_mgr.current_data, source_mgr.current_source)\n",
    "    show_labeling_progress(source_mgr.current_data, source_mgr.current_source)\n",
    "\n",
    "    return True\n",
    "\n",
    "def complete_current_source():\n",
    "    if not source_mgr.current_source or not source_mgr.current_data:\n",
    "        print(\"No active source to complete\")\n",
    "        return None\n",
    "\n",
    "    labeled_count = sum(1 for item in source_mgr.current_data if item['label'] is not None)\n",
    "    total_count = len(source_mgr.current_data)\n",
    "    completion_rate = labeled_count / total_count if total_count > 0 else 0\n",
    "\n",
    "    print(f\"\\nCompleting source: {source_mgr.current_source}\")\n",
    "    print(f\"Template completion: {labeled_count}/{total_count} ({completion_rate*100:.1f}%)\")\n",
    "\n",
    "    total_logs = sum(item['count'] for item in source_mgr.current_data)\n",
    "    labeled_logs = sum(item['count'] for item in source_mgr.current_data if item['label'] is not None)\n",
    "    log_coverage = labeled_logs / total_logs if total_logs > 0 else 0\n",
    "    print(f\"Log coverage: {labeled_logs:,}/{total_logs:,} ({log_coverage*100:.1f}%)\")\n",
    "\n",
    "    if completion_rate < 0.7:\n",
    "        print(\"Warning: Less than 70% of templates labeled\")\n",
    "        choice = input(\"Continue with completion anyway? (y/n): \").strip().lower()\n",
    "        if choice != 'y':\n",
    "            print(\"Completion cancelled. Continue labeling or use bulk labeling.\")\n",
    "            return None\n",
    "\n",
    "    print(\"\\nValidating labeling quality...\")\n",
    "    issues = validate_labeling_quality(source_mgr.current_data)\n",
    "    if len(issues) > 5:\n",
    "        print(f\"Found {len(issues)} potential issues. Review recommended.\")\n",
    "        choice = input(\"Continue with completion anyway? (y/n): \").strip().lower()\n",
    "        if choice != 'y':\n",
    "            print(\"Completion cancelled. Review labels first.\")\n",
    "            return None\n",
    "\n",
    "    final_dataset, completed_source = source_mgr.complete_current_source()\n",
    "\n",
    "    print(f\"\\n✅ Successfully completed {completed_source}!\")\n",
    "    print(f\"Pattern library updated with new knowledge\")\n",
    "\n",
    "    next_source = source_mgr.get_next_recommended_source()\n",
    "    if next_source:\n",
    "        print(f\"\\nNext recommended source: {next_source}\")\n",
    "        print(\"Run streamlined_workflow() to continue\")\n",
    "    else:\n",
    "        print(\"\\n🎉 All prioritized sources completed!\")\n",
    "        print(\"Consider creating combined dataset and ML exports\")\n",
    "\n",
    "    return final_dataset\n",
    "\n",
    "def quick_completion_statistics():\n",
    "    print(\"\\nQUICK COMPLETION STATISTICS\")\n",
    "    print(\"=\"*45)\n",
    "\n",
    "    completed_count = len(source_mgr.completed)\n",
    "    remaining_count = len(LOG_SOURCES) - completed_count\n",
    "    print(f\"Progress: {completed_count}/{len(LOG_SOURCES)} sources ({completed_count/len(LOG_SOURCES)*100:.1f}%)\")\n",
    "\n",
    "    if source_mgr.completed:\n",
    "        print(f\"\\nCompleted sources:\")\n",
    "        total_logs_processed = 0\n",
    "        total_anomalies_found = 0\n",
    "\n",
    "        for source in source_mgr.completed:\n",
    "            labeled_file = OUTPUT_PATH / f\"{source}_labeled.csv\"\n",
    "            if labeled_file.exists():\n",
    "                df = pd.read_csv(labeled_file)\n",
    "                logs = len(df)\n",
    "                anomalies = (df['AnomalyLabel'] > 0).sum()\n",
    "                total_logs_processed += logs\n",
    "                total_anomalies_found += anomalies\n",
    "                print(f\"  {source}: {logs:,} logs, {anomalies:,} anomalies ({anomalies/logs*100:.1f}%)\")\n",
    "\n",
    "        print(f\"\\nTotals: {total_logs_processed:,} logs, {total_anomalies_found:,} anomalies\")\n",
    "        if total_logs_processed > 0:\n",
    "            print(f\"Overall anomaly rate: {total_anomalies_found/total_logs_processed*100:.1f}%\")\n",
    "\n",
    "    if remaining_count > 0:\n",
    "        print(f\"\\nRemaining sources: {remaining_count}\")\n",
    "        next_source = source_mgr.get_next_recommended_source()\n",
    "        if next_source:\n",
    "            print(f\"Next recommended: {next_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c69192f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_system():\n",
    "    global datasets, stats, pattern_library, source_mgr\n",
    "\n",
    "    print(\"INITIALIZING LOG ANOMALY DETECTION SYSTEM (Enhanced)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Ensure NLTK resources (WordNet) are available for synonyms\n",
    "    try:\n",
    "        _ = wordnet.synsets(\"test\")\n",
    "    except LookupError:\n",
    "        print(\"Downloading NLTK WordNet data...\")\n",
    "        nltk.download('wordnet')\n",
    "        nltk.download('omw-1.4')\n",
    "\n",
    "    print(\"1. Loading datasets...\")\n",
    "    datasets, failed_sources = load_all_datasets()\n",
    "    if not datasets:\n",
    "        print(\"ERROR: No datasets loaded successfully\")\n",
    "        return False\n",
    "\n",
    "    print(\"2. Analyzing datasets...\")\n",
    "    stats = analyze_datasets(datasets)\n",
    "\n",
    "    print(\"3. Initializing pattern library...\")\n",
    "    pattern_library = SmartPatternLibrary()\n",
    "    pattern_library.load_library()\n",
    "\n",
    "    print(\"4. Setting up source manager...\")\n",
    "    source_mgr = SourceManager(datasets, stats, pattern_library)\n",
    "\n",
    "    print(\"5. Showing initial rankings...\")\n",
    "    rankings = rank_sources_by_priority(stats, source_mgr.completed)\n",
    "    print(f\"\\nTop 5 recommended sources:\")\n",
    "    for i, rank in enumerate(rankings[:5], 1):\n",
    "        print(f\"{i}. {rank['source']}: priority={rank['priority']:.1f}, \"\n",
    "              f\"anomalies={rank['anomaly_rate']:.1f}%, templates={rank['templates']}\")\n",
    "\n",
    "    print(\"\\n✅ System initialization complete!\")\n",
    "    return True\n",
    "\n",
    "def show_available_commands():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"AVAILABLE COMMANDS\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(\"\\n🚀 MAIN WORKFLOW:\")\n",
    "    print(\"  streamlined_workflow()                - Main entry point (start here)\")\n",
    "    print(\"  continue_labeling_current_source()    - Continue current labeling session\")\n",
    "    print(\"  complete_current_source()             - Finish and export current source\")\n",
    "\n",
    "    print(\"\\n⚡ BULK OPERATIONS:\")\n",
    "    print(\"  bulk_label_remaining_templates()      - Auto-label remaining templates\")\n",
    "\n",
    "    print(\"\\n📊 STATUS & ANALYSIS:\")\n",
    "    print(\"  source_mgr.get_overall_status()       - Show complete progress\")\n",
    "    print(\"  quick_completion_statistics()         - Quick stats overview\")\n",
    "\n",
    "    print(\"\\n🧪 MODEL & TRANSFER:\")\n",
    "    print(\"  pattern_library.train_ml_from_exports() - Train TF-IDF+LR classifier from labeled CSVs\")\n",
    "    print(\"  transfer_labels_across_sources(source_mgr, threshold=90) - Cross-source label propagation\")\n",
    "\n",
    "    print(\"\\n💾 DATA MANAGEMENT & EXPORT:\")\n",
    "    print(\"  create_combined_dataset(source_mgr.completed) - Combine completed sources\")\n",
    "    print(\"  export_ml_ready_data(combined_df)     - Export for ML training (use output of previous command)\")\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"🎯 TO GET STARTED:\")\n",
    "    print(\"1. Run the initialization cell below.\")\n",
    "    print(\"2. Run: streamlined_workflow()\")\n",
    "    print(\"3. Follow the guided prompts!\")\n",
    "    print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54ccd501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZING LOG ANOMALY DETECTION SYSTEM (Enhanced)\n",
      "============================================================\n",
      "1. Loading datasets...\n",
      "Loading datasets...\n",
      "✓ Android_2k: 2,000 logs, 10 columns\n",
      "✓ Apache_2k: 2,000 logs, 6 columns\n",
      "✓ BGL_2k: 2,000 logs, 13 columns\n",
      "✓ Hadoop_2k: 2,000 logs, 9 columns\n",
      "✓ HDFS_2k: 2,000 logs, 9 columns\n",
      "✓ HealthApp_2k: 2,000 logs, 7 columns\n",
      "✓ HPC_2k: 2,000 logs, 10 columns\n",
      "✓ Linux_2k: 2,000 logs, 10 columns\n",
      "✓ Mac_2k: 2,000 logs, 11 columns\n",
      "✓ OpenSSH_2k: 2,000 logs, 9 columns\n",
      "✓ OpenStack_2k: 2,000 logs, 11 columns\n",
      "✓ Proxifier_2k: 2,000 logs, 6 columns\n",
      "✓ Spark_2k: 2,000 logs, 8 columns\n",
      "✓ Thunderbird_2k: 2,000 logs, 14 columns\n",
      "✓ Windows_2k: 2,000 logs, 8 columns\n",
      "✓ Zookeeper_2k: 2,000 logs, 10 columns\n",
      "\n",
      "Loaded: 16/16 sources\n",
      "Total logs: 32,000\n",
      "2. Analyzing datasets...\n",
      "Analyzing datasets with expanded patterns & fuzzy matching...\n",
      "3. Initializing pattern library...\n",
      "4. Setting up source manager...\n",
      "5. Showing initial rankings...\n",
      "\n",
      "Top 5 recommended sources:\n",
      "1. OpenSSH_2k: priority=84.7, anomalies=132.2%, templates=27\n",
      "2. Linux_2k: priority=53.0, anomalies=60.6%, templates=118\n",
      "3. Apache_2k: priority=50.7, anomalies=27.0%, templates=6\n",
      "4. Proxifier_2k: priority=46.3, anomalies=22.2%, templates=8\n",
      "5. Thunderbird_2k: priority=45.7, anomalies=44.0%, templates=149\n",
      "\n",
      "✅ System initialization complete!\n",
      "\n",
      "======================================================================\n",
      "AVAILABLE COMMANDS\n",
      "======================================================================\n",
      "\n",
      "🚀 MAIN WORKFLOW:\n",
      "  streamlined_workflow()                - Main entry point (start here)\n",
      "  continue_labeling_current_source()    - Continue current labeling session\n",
      "  complete_current_source()             - Finish and export current source\n",
      "\n",
      "⚡ BULK OPERATIONS:\n",
      "  bulk_label_remaining_templates()      - Auto-label remaining templates\n",
      "\n",
      "📊 STATUS & ANALYSIS:\n",
      "  source_mgr.get_overall_status()       - Show complete progress\n",
      "  quick_completion_statistics()         - Quick stats overview\n",
      "\n",
      "🧪 MODEL & TRANSFER:\n",
      "  pattern_library.train_ml_from_exports() - Train TF-IDF+LR classifier from labeled CSVs\n",
      "  transfer_labels_across_sources(source_mgr, threshold=90) - Cross-source label propagation\n",
      "\n",
      "💾 DATA MANAGEMENT & EXPORT:\n",
      "  create_combined_dataset(source_mgr.completed) - Combine completed sources\n",
      "  export_ml_ready_data(combined_df)     - Export for ML training (use output of previous command)\n",
      "\n",
      "======================================================================\n",
      "🎯 TO GET STARTED:\n",
      "1. Run the initialization cell below.\n",
      "2. Run: streamlined_workflow()\n",
      "3. Follow the guided prompts!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    success = initialize_system()\n",
    "    if success:\n",
    "        show_available_commands()\n",
    "        # Optional auto-start:\n",
    "        # streamlined_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2c213207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STREAMLINED MULTI-SOURCE LOG ANOMALY LABELING WORKFLOW\n",
      "======================================================================\n",
      "\n",
      "OVERALL STATUS\n",
      "========================================\n",
      "Total sources: 16\n",
      "Completed sources: 16\n",
      "Remaining sources: 0\n",
      "Progress: 100.0%\n",
      "\n",
      "Completed: OpenSSH_2k, Linux_2k, Apache_2k, Proxifier_2k, Thunderbird_2k, BGL_2k, Hadoop_2k, HPC_2k, Zookeeper_2k, Spark_2k, HDFS_2k, Windows_2k, Mac_2k, OpenStack_2k, Android_2k, HealthApp_2k\n",
      "\n",
      "Pattern library: 1363 templates (embeddings + TF-IDF ready)\n",
      "\n",
      "🎉 All sources completed!\n",
      "Run create_combined_dataset() and export_ml_ready_data() for final export\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'all_completed'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamlined_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a7571",
   "metadata": {},
   "source": [
    "1360 templates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
